\documentclass[12pt,titlepage]{article}

\usepackage[all]{xy}

% The special comments below are processed by latex2html.
% Everything between them will be skipped by latex2html.
%begin{latexonly}
  \usepackage{ifpdf}
  \ifpdf
    \usepackage{pdfsync}
    % The 'html' package will re-define
    % 'hyperref' and complain, if we don't load it first.
    \usepackage[
      bookmarks,
      bookmarksopen=false,
      bookmarksnumbered=true,
      pdfpagemode=UseOutlines,
      colorlinks=true]{hyperref}
  \fi
%end{latexonly}
\usepackage{html}
\usepackage{makeidx}

\setcounter{secnumdepth}{4}

\newcounter{parnum}
\makeatletter
\@addtoreset{parnum}{section}
\@addtoreset{parnum}{subsection}
\@addtoreset{parnum}{subsubsection}
\@addtoreset{parnum}{paragraph}
\makeatother

% Not really a tab, but something like it for HTML
% output.  If we want real tabs, we'll probably need to use CSS.
\newcommand{\tab}{\textt{~~~~~~}}
\newcommand{\np}{
  \addtocounter{parnum}{1}
  \latex{\hspace{-2em}\makebox[2em][l]{\arabic{parnum}}}
  \html{{\bf {\arabic{parnum}}}\tab}}


\newcommand{\npf}{\setcounter{parnum}{0}\np}

\newcommand{\sterm}[1]{
\subsection{\html{#1}}
\index{#1}
\npf {\bf #1}\\}

\newcommand{\ssterm}[1]{
\subsubsection{\html{#1}}
\index{#1}
\npf {\bf #1}\\}

\newcommand{\pterm}[1]{
\paragraph{\html{#1}}
\index{#1}
\npf {\bf #1}\\}

\setlength{\parindent}{0pt}
\setlength {\parskip}{1.3ex}

\makeindex

\let\theoriginalindex\theindex
\def\theindex{\theoriginalindex\phantomsection\addcontentsline{toc}{section}{Index}}

\title{UPC Language Specifications\\
V1.2 }

\author{A publication of the UPC Consortium}

\date {May 31, 2005}

\begin{document}

\maketitle

\setcounter{page}{2}
\section*{Acknowledgments}
                                             
\npf Many have contributed to the ideas and concepts behind
    these specifications.  William Carlson, Jesse Draper,  David Culler, 
Katherine Yelick,
Eugene Brooks, and Karen Warren are the authors of the initial
UPC language concepts and specifications. Tarek El-Ghazawi, 
William Carlson, and Jesse Draper are the authors of the first formal
version of the specifications.  Because of the numerous contributions
to the specifications, no explicit authors are currently mentioned.
We also would like to
acknowledge the role of the participants in the first UPC workshop:
the support and participation of Compaq, Cray, HP, Sun,
and CSC; the abundant input of
Kevin Harris and S\'{e}bastien Chauvin and the efforts of Lauren
Smith; and the efforts of Brian Wibecan and Greg Fischer were
invaluable in bringing these specifications to version 1.0.

\np Version 1.1 is the result of the contributions of many in the UPC
community.  In addition to the
continued support of all those mentioned above, the efforts of Dan
Bonachea were invaluable in this effort.

\np Version 1.2 is also the result of many contributors.  Worthy of special
note (in addition to the
continued support of those mentioned above) are the substantial 
contributions to many aspects of the specifications by Jason Duell;
Many have contributed to the ideas and concepts behind the
UPC collectives specifications.
Elizabeth Wiebel and David Greenberg are the authors of the first draft of
that specification.  Steve Seidel organized the effort to
refine it into its current form.
Thanks go to many in the UPC community for their interest and helpful
comments, particularly Dan Bonachea, Bill Carlson, Jason Duell and
Brian Wibecan.
Version 1.2 also includes the UPC I/O specification which is the result of
efforts by Tarek El Ghazawi, Francois Cantonnet, Proshanta Saha, Rajeev Thakur,
Rob Ross, and Dan Bonachea.
Finally, it also includes the substantial contributions to the UPC memory consistency
model by Kathy Yelick, Dan Bonachea, and Charles Wallace.

\np Members of the UPC consortium may be contacted via the world wide
web at
http://www.upcworld.org or http://upc.gwu.edu, where an archived mailing list
may be joined.  Comments on these specifications are always welcome.
\newpage

\setlength {\parskip}{0ex}

\tableofcontents                                             

\setlength {\parskip}{1.3ex}

\newpage

%\addcontentsline{toc}{section}{Introduction}
\section*{Introduction}

\npf UPC is a parallel extension to the C Standard.  UPC follows the
    partitioned global address space [CAG93] programming model.
    The first version
    of UPC, known as version 0.9, was published in May of 1999 as
    technical report [CDC99] at the Institute for Defense Analyses
    Center for Computing Sciences.

\np Version 1.0 of UPC was initially discussed at the
    UPC workshop, held in Bowie, Maryland, 18-19 May, 2000.  The
    workshop had about 50 participants from industry, government, and
    academia. This version was adopted with modifications in the UPC
    mini workshop meeting held during Supercomputing 2000, in November
    2000, in Dallas, and finalized in February 2001.

\np Version 1.1 of UPC was initially discussed at the UPC
    workshop, held in Washington, DC, 3-5 March, 2002, and finalized
    in October 2003.
    
\np Version 1.2 of UPC was initially discussed at the UPC
   workshop held in Phoenix, AZ, 20 November 2003, and finalized
   in May 2005.
   
\section{Scope}

\npf This document focuses only on the UPC specifications
    that extend the C Standard to an explicit parallel C based on the
    partitioned global address space model. All C specifications as per
    ISO/IEC 9899 [ISO/IEC00] are considered a part of these UPC
    specifications, and therefore will not be addressed in this
    document.
\index{ISO C}
\index{UPC}
\index{global address space}

\np Small parts of the C Standard [ISO/IEC00] may be repeated for
    self-containment and clarity of a subsequent UPC extension
    definition.

\section{Normative references}

\np The following document and its identified normative
    references constitute provisions of these UPC specifications.

\index{ISO C}
\np ISO/IEC 9899: 1999(E), Programming languages - C
    [ISO/IEC00]

\np The relationship between the section numbering used in
    the C Standard [ISO/IEC00] and that used in this document is given
    in Appendix C and noted at the beginning of each corresponding section.

\hypersetup{bookmarksdepth=2}  % Disable bookmarks below section level
\section{Terms, definitions and symbols}
\npf For the purpose of these specifications the following
    definitions apply.

\np Other terms are defined where they appear in {\em
    italic} type or on the left hand side of a syntactical rule.


\sterm{thread} an instance of execution initiated by the execution
  environment at program startup.

\sterm{object} region of data storage in the execution environment
  which can represent values.

\ssterm{shared object} an object allocated using a shared-qualified
  declarator or by a library function defined to create shared objects.
    
\np NOTE \hspace{5pt}  All threads may access shared 
   objects.\footnote{The file scope declaration
   {\tt shared int x;} creates a single object which any thread may access.}
   
\ssterm{private object} any object which is not a shared object.

\np NOTE \hspace{5pt} Each thread declares and creates its own 
    private objects which no other thread can access.
    \footnote{The file scope declaration
    {\tt int y;} creates a separate object for each thread to access.}

\ssterm{shared array} an array with elements that have shared qualified type.
  
\sterm{affinity} logical association between shared
  objects and threads.  Each element of data storage that contains
  shared objects has affinity to exactly one thread.
 
\sterm{pointer-to-shared} a pointer whose referenced type is shared-qualified.

\sterm{pointer-to-local} a pointer whose referenced type is not
  shared-qualified.

\label{def-access}
\sterm{access} $<$execution-time action$>$ to read or
  modify the value of an object by a thread.

\ssterm{shared access} an access using an expression whose type
  is shared-qualified.

\pterm{strict shared read} a shared read access which is determined to be
  strict according to section \ref{type_qualifiers} of this specification.

\pterm{strict shared write} a shared modify access which is determined to be
  strict according to section \ref{type_qualifiers} of this specification.

\pterm{relaxed shared read} a shared read access which is determined to be
  relaxed according to section \ref{type_qualifiers} of this specification.

\pterm{relaxed shared write} a shared modify access which is determined to be
  relaxed according to section \ref{type_qualifiers} of this specification.

\ssterm{local access} an access using an expression whose type
  is not shared-qualified.

\index{synchronization}
\sterm{collective} constraint placed on some language 
  operations which requires evaluation of such operations to be
  matched\footnote{A collective operation need not provide any
  actual synchronization between threads, unless otherwise noted.
  The collective requirement simply states a relative ordering property
  of calls to collective operations that must be maintained in the
  parallel execution trace for all executions of any legal program.
  Some implementations may include unspecified synchronization between
  threads within collective operations, but programs must not rely upon
  such unspecified synchronization for correctness.} across all threads.
  The behavior of collective operations is undefined unless all threads
  execute the same sequence of collective operations.

\ssterm{single-valued} an operand to a collective operation, which has
  the same value on every thread.  The behavior of the operation
  is otherwise undefined.

\ssterm{phase} an unsigned integer value associated with a
 pointer-to-shared which indicates the element-offset within an
 affinity block; used in pointer-to-shared arithmetic
 to determine affinity boundaries.

\hypersetup{bookmarksdepth=4}  % Re-enable bookmarks to the sub-section level

\section{Conformance}

\np In this document, ``shall'' is to be interpreted as a
   requirement on a UPC implementation; conversely, ``shall not'' is to
   be interpreted as a prohibition.

\np If a ``shall'' or ``shall not'' requirement 
   is violated, the behavior is undefined. Undefined behavior is
   indicated by ``undefined behavior'' or by the omission of any
   explicit definition of behavior from the UPC specification.

\pagebreak
\section{Environment}

\subsection{Conceptual models}
\subsubsection{Translation environment}

\paragraph{Threads environment}\ \\
\index{static THREADS environment}
\index{dynamic THREADS environment}
\npf A UPC program is translated under either a {\em static
      THREADS} environment or a {\em dynamic THREADS} environment. Under
      the static THREADS environment, the number of threads to be
      used in execution is indicated to the translator in an
      implementation-defined manner. If the actual execution
      environment differs from this number of threads, the behavior of
      the program is undefined.
       
\subsubsection{Execution environment}

\npf This subsection provides the UPC parallel extensions of
   [ISO/IEC00 Sec. 5.1.2]
   
\index{thread creation}
\np A UPC program consists of a set of threads which may
      allocate both shared and private objects.  
      Accesses to these objects are defined as either
      local or shared, based on the type of the access.  Each thread's local
      accesses behave independently and exactly as described in 
      [ISO/IEC00].  All shared accesses behave as described herein.

\index{implicit barriers}
\np There is an implicit {\tt upc\_barrier} at program startup
     and termination.  Except as explicitly specified by {\tt upc\_barrier} operations
     or by certain library functions (all of which are explicitly documented), there
     are no other barrier synchronization guarantees among the threads.

       {\bf Forward references:} {\tt upc\_barrier} (\ref{upc_barrier}).  

\paragraph{Program startup}\ \\

\index{program startup}
\index{main}
\npf In the execution environment of a UPC program, derived
      from the hosted environment as defined in the C Standard [ISO/IEC00],
      each thread calls the UPC program's {\tt main()}
      function\footnote {e.g., in the program {\tt main()\{
      printf("hello"); \} }, each thread prints {\tt hello}.}.

\paragraph{Program termination}\ \\

\index{program termination}
\index{upc\_global\_exit}
\index{exit}
\npf A program is terminated by the termination of all the
      threads\footnote{A barrier is automatically inserted at thread termination.} or a call
      to the function {\tt upc\_global\_exit()}.

\np Thread termination follows the C Standard definition of
    program termination in [ISO/IEC00 Sec. 5.1.2.2.3]. A thread is
    terminated by reaching the \}  that terminates the main
    function, by a call to the exit function, or by a return from the
    initial main. Note that thread termination does not imply the
    completion of all I/O and that shared data allocated by a thread
    either statically or dynamically shall not be freed before UPC
    program termination.

     {\bf Forward references:} {\tt upc\_global\_exit} (\ref{upc_global_exit}).  

\paragraph{Program execution}\ \\
\label{strict_relaxed}

\index{memory consistency}
\index{shared access}
\index{strict shared read}
\index{strict shared write}
\index{relaxed shared read}
\index{relaxed shared write}
\index{sequential consistency}
\index{program order}
\index{data races}
\npf Thread execution follows the C Standard definition of
  program execution in [ISO/IEC00 Sec. 5.1.2.3].  This section describes
  the additional operational semantics users can expect from accesses to shared
  objects.  In a shared memory model such as UPC, operational
  descriptions of semantics are insufficient to completely
  and definitively describe a memory consistency model.  Therefore
  Appendix \ref{mem-semantics} presents the formal memory
  semantics of UPC.  The information presented in this section is consistent with
  the formal semantic description, but not complete.  Therefore, implementations
  of UPC based on this section alone may be non-compliant.
  
\np All shared accesses are classified as being either strict or relaxed,
  as described in sections \ref{type_qualifiers} and \ref{pragmas}.
  Accesses to shared objects via
  pointers-to-local behave as relaxed shared accesses with respect to memory
  consistency. Most synchronization-related language operations and library
  functions (notably {\it upc\_fence}, {\it upc\_notify}, {\it upc\_wait}, and
  {\it upc\_lock}/{\it upc\_unlock}) imply the consistency effects of a strict
  access.

\np In general, any sequence of purely relaxed shared accesses
  issued by a given
  thread in an execution may appear to be arbitrarily reordered relative to
  program order by the implementation, and different threads need not agree upon
  the order in which such accesses appeared to have taken place. The only
  exception to the previous statement is that two relaxed accesses issued by a
  given thread to the same memory location where at least one is a write will
  always appear to all threads to have executed in program order. Consequently,
  relaxed shared accesses should never be used to perform deterministic
  inter-thread synchronization - synchronization should be performed using
  language/library operations whenever possible, or otherwise using only strict
  shared reads and strict shared writes.

\np Strict accesses always appear (to all threads) to have executed
  in program
  order with respect to other strict accesses, and in a given execution all
  threads observe the effects of strict accesses in a manner consistent with a
  single, global total order over the strict operations. Consequently, an
  execution of a program whose only accesses to shared objects are strict 
  is guaranteed to behave in a sequentially consistent [Lam79] manner.

\np When a thread's program order dictates a set of relaxed
  operations followed by
  a strict operation, all threads will observe the effects of the prior relaxed
  operations made by the issuing thread (in some order) before observing the
  strict operation. Similarly, when a thread's program order dictates a strict
  access followed by a set of relaxed accesses, the strict access will be
  observed by all threads before any of the subsequent relaxed accesses by the
  issuing thread. Consequently, strict operations can be used to synchronize the
  execution of different threads, and to prevent the apparent reordering of
  surrounding relaxed operations across a strict operation.

\np NOTE: It is anticipated that most programs will use the strict 
  synchronization facilities provided by the
  language and library (e.g. barriers, locks, etc) to synchronize threads and
  prevent non-determinism arising from data races. A data race may occur whenever
  two or more relaxed operations from different threads access the same location
  with no intervening strict synchronization, and at least one such access is a
  write. Programs which produce executions that are always free of data races (as
  formally defined in Appendix \ref{mem-semantics}), are guaranteed to behave in
  a sequentially consistent manner.

   {\bf Forward references:} {\tt upc\_fence}, {\tt upc\_notify}, 
    {\tt upc\_wait}, {\tt upc\_barrier} (\ref{upc_barrier}). {\tt upc\_lock},
    {\tt upc\_unlock} (\ref{upc_lock}).
    
\pagebreak
\section{Language}
\subsection{Notations} 

\npf In the syntax notation used in this section, syntactic
    categories (nonterminals) are indicated by {\em italic type}, and
    literal words and character set members (terminals) by {\bf bold
    type}. A colon (:) following a nonterminal introduces its
    definition.  An optional symbol is
    indicated by the subscript ``opt'', so that

\begin{center}
          \{ $expression_{opt}$ \}
\end{center}

    indicates an optional expression enclosed in braces. 

\np When syntactic categories are referred to in the main
    text, they are not italicized and words are separated by spaces
    instead of hyphens.
    
\subsection {Keywords}

\index{keywords}
\index{tokens}
\index{MYTHREAD}
\index{upc\_barrier}
\index{upc\_localsizeof}
\index{relaxed}
\index{upc\_blocksizeof}
\index{UPC\_MAX\_BLOCK\_SIZE}
\index{shared}
\index{upc\_elemsizeof}
\index{upc\_notify}
\index{strict}
\index{upc\_fence}
\index{upc\_wait}
\index{THREADS}
\index{upc\_forall}
\npf This subsection provides the UPC extensions of [ISO/IEC00 Sec 6.4.1].

{\bf Syntax}

\np{\em upc\_keyword:}

\begin{center}
{\tt\bf 
\begin{tabular}{lll}
MYTHREAD & upc\_barrier & upc\_localsizeof  \\ 
relaxed & upc\_blocksizeof & UPC\_MAX\_BLOCKSIZE \\
shared &  upc\_elemsizeof & upc\_notify \\
strict &   upc\_fence  & upc\_wait \\
THREADS & upc\_forall  \\
\end{tabular}
}
\end{center}


{\bf Semantics}

\np In addition to the keywords defined in [ISO/IEC00 Sec 6.4.1], the above
tokens (case sensitive) are reserved (in translation phases 7 and 8) for use
as keywords and shall not be otherwise used.

 
\subsection{Predefined identifiers}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec. 6.4.2.2].

\subsubsection{{\tt THREADS}}
\label{threads}
\index{THREADS}
\npf {\tt THREADS} is an expression with a value of type int; it specifies the number of
     threads and has the same value on every
     thread.   Under the static THREADS translation environment, {\tt THREADS}
     is an integer constant suitable for use in {\tt \#if} preprocessing directives.

\subsubsection{{\tt MYTHREAD}}
\index{MYTHREAD}
\npf {\tt MYTHREAD} is an expression with a value of type int; it specifies the
     unique thread index. The range of possible values is {\tt
     0..THREADS-1}\footnote {e.g., the program {\tt main()\{
     printf("\%d ",MYTHREAD); \} }, prints the numbers 0 through
     THREADS-1, in some order.}.

\subsubsection{{\tt UPC\_MAX\_BLOCK\_SIZE}}
\label{max_block_size}
\index{UPC\_MAX\_BLOCK\_SIZE}      
\index{block size}
\npf {\tt UPC\_MAX\_BLOCK\_SIZE} is a predefined integer
     constant value.  It indicates the maximum value\footnote{
     e.g. {\tt shared [UPC\_MAX\_BLOCK\_SIZE+1] char
     x[UPC\_MAX\_BLOCK\_SIZE+1]} and {\tt shared [*] char
     x[(UPC\_MAX\_BLOCK\_SIZE+1)*THREADS]} are translation errors.} allowed
     in a layout qualifier for shared data.  It shall be suitable for use in 
     {\tt \#if} preprocessing directives.

\subsection{Expressions}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec. 6.5].  In particular, the unary operator expressions
    in [ISO/IEC00 Sec. 6.5.3] are extended with new syntax.

\subsubsection{Unary Operators}

{\bf Syntax}

\npf{\em unary-expression}

\hspace{3em}{\em ...}

\hspace{3em}{\tt {\bf sizeof} {\em unary-expression}}

\hspace{3em}{\tt {\bf sizeof} ( {\em type-name} )}

\hspace{3em}{\tt {\bf upc\_localsizeof} {\em unary-expression}}

\hspace{3em}{\tt {\bf upc\_localsizeof} ( {\em type-name} )}

\hspace{3em}{\tt {\bf upc\_blocksizeof} {\em unary-expression}}

\hspace{3em}{\tt {\bf upc\_blocksizeof} ( {\em type-name} )}

\hspace{3em}{\tt {\bf upc\_elemsizeof} {\em unary-expression}}

\hspace{3em}{\tt {\bf upc\_elemsizeof} ( {\em type-name} )}


\paragraph{The {\tt\bf sizeof} operator}\ \\

{\bf Semantics} 

\index{sizeof}
\npf The {\tt sizeof} operator will result in an
    integer value which is not constant when 
    applied to a definitely blocked shared array under
    the {\em dynamic THREADS} environment.

\paragraph{The {\tt\bf upc\_localsizeof} operator}\ \\\
 
{\bf Constraints} 

\index{upc\_localsizeof}
\npf The {\tt upc\_localsizeof} operator shall apply only to
     shared-qualified expressions or
     shared-qualified types.  All constraints on the {\tt sizeof} operator
     [ISO/IEC00 Sec. 6.5.3.4] also apply to this operator.

{\bf Semantics} 

\np The {\tt upc\_localsizeof} operator returns the size, in
     bytes, of the local portion of its operand, which may be a shared
     object or a shared-qualified type. It returns the same value on
     all threads; the value is an upper bound of the size allocated with
     affinity to any single thread and may include an unspecified amount of
     padding.  The result of {\tt upc\_localsizeof} is an integer constant.

\np The type of the result is {\tt size\_t}. 

\np If the the operand is an expression, that expression
     is not evaluated.

\paragraph{The {\tt\bf upc\_blocksizeof} operator}\ \\
 

{\bf Constraints} 

\index{upc\_blocksizeof}
\npf The {\tt upc\_blocksizeof} operator shall apply only to shared-qualified
     expressions or shared-qualified types.    All constraints on the {\tt sizeof} operator
     [ISO/IEC00 Sec. 6.5.3.4] also apply to this operator.

{\bf Semantics} 

\np The {\tt upc\_blocksizeof} operator returns the block
     size of the operand, which may be a shared object or a
     shared-qualified type.  The block size is the value specified in
     the layout qualifier of the type declaration. If there is no
     layout qualifier, the block size is 1.  The result of {\tt
     upc\_blocksizeof } is an integer constant.

\np If the operand of {\tt upc\_blocksizeof} has indefinite
     block size, the value of {\tt upc\_blocksizeof} is 0.

\np The type of the result is {\tt size\_t}. 

\np If the the operand is an expression, that expression
     is not evaluated.

      {\bf Forward references:} indefinite block size (\ref{indefinite_block_size}).  
      

\paragraph{The {\tt\bf upc\_elemsizeof} operator}\ \\

{\bf Constraints} 

\index{upc\_elemsizeof}
\npf The {\tt upc\_elemsizeof} operator shall apply only to shared-qualified
     expressions or shared-qualified types.  All constraints on the {\tt sizeof} operator
     [ISO/IEC00 Sec. 6.5.3.4] also apply to this operator.

{\bf Semantics} 

\np The {\tt upc\_elemsizeof} operator returns the size, in bytes,
     of the highest-level (leftmost) type that is not an array. For
     non-array objects, {\tt upc\_elemsizeof} returns the same value as
     sizeof. The result of {\tt upc\_elemsizeof} is an integer constant.

\np The type of the result is {\tt size\_t}. 

\np If the the operand is an expression, that expression
     is not evaluated.

\subsubsection{Pointer-to-shared arithmetic}
\label{pointer-arithmetic}
\index{pointer-to-shared}
\index{pointer-to-local}
\index{pointer addition}
\index{upc\_phaseof}
\index{upc\_threadof}
\index{upc\_addrfield}
\index{pointer equality}
\index{pointer subtraction}
\index{affinity}
\index{phase}
{\bf Constraints} 

\npf No binary operators shall be applied to one pointer-to-shared
    and one pointer-to-local.

{\bf Semantics} 

\np When an expression that has integer type is added to or
     subtracted from a pointer-to-shared, the result has the type of the
     pointer-to-shared operand.  If the pointer-to-shared operand points to
     an element of a shared array object, and the shared array is
     large enough, the result points to an element of the shared
     array.  If the shared array is declared with indefinite block
     size, the result of the pointer-to-shared arithmetic is identical to
     that described for normal C pointers in [ISO/IEC00 Sec. 6.5.6],
     except that the thread of the new pointer shall be the same as
     that of the original pointer and the phase component is defined to
     always be zero.  If the shared array has a definite block size,
     then the following example describes pointer arithmetic:

      
\begin{verbatim}
    shared [B] int *p, *p1;  /* B a positive integer */ 
    int i;  

    p1 = p + i;  
\end{verbatim}
    
\np After this assignment the following equations must hold
   in any UPC implementation.  In each case the {\tt div} operator
   indicates integer division rounding towards negative infinity and
   the {\tt mod} operator returns the nonnegative
   remainder:\footnote{The C ``{\tt \%}'' and ``{\tt /}''
   operators do not have the necessary properties}

    
\begin{verbatim}
    upc_phaseof(p1) == (upc_phaseof(p) + i) mod B 
    upc_threadof(p1) == (upc_threadof(p) 
                         + (upc_phaseof(p) + i) div B) mod THREADS 
\end{verbatim}    

\np In addition, the correspondence between shared and
   local addresses and arithmetic is defined using the following
   constructs:

\begin{verbatim}
    T *P1, *P2;  
    shared T *S1, *S2;  

    P1 = (T*) S1;  /* allowed if S1 has affinity to MYTHREAD */ 
    P2 = (T*) S2;  /* allowed if S2 has affinity to MYTHREAD */ 
\end{verbatim}    
    

\np For all S1 and S2 that point to two distinct elements of
   the same shared array object which have affinity to the same
   thread:

\begin{itemize}
\item S1 and P1 shall point to the same object. 
\item S2 and P2 shall point to the same object. 
\item The expression (({\tt (ptrdiff\_t) upc\_addrfield} (S2) -  {\tt (ptrdiff\_t) upc\_addrfield(S1))} shall 
   evaluate to the same value as ((P2 - P1) * sizeof(T)).  
\end{itemize}

\np Two compatible pointers-to-shared which point to the same
    object (i.e. having the same address and thread components) shall
    compare as equal according to == and !=, regardless of whether the 
    phase components match.

\np When two pointers-to-shared are subtracted, as described in
    [ISO/IEC00 Sec. 6.5.6], the result is undefined unless there exists
    an integer x, representable as a {\tt ptrdiff\_t}, such that (pts1 + x) == pts2
    AND {\tt upc\_phaseof(pts1 + x) == upc\_phaseof(pts2)}.
    In this case (pts2 - pts1) evaluates to x.


{\bf Forward references:}  {\tt upc\_threadof} (\ref{upc_threadof}),
          {\tt upc\_phaseof} (\ref{upc_phaseof}), {\tt upc\_addrfield} (\ref{upc_addrfield}). 

\subsubsection{Cast and assignment expressions}

\index{pointer-to-shared, casts}
\index{pointer-to-shared, conversion}
\index{pointer-to-shared, null}
\index{pointer-to-shared, generic}
\index{block size, conversion}
{\bf Constraints} 

\npf A shared type qualifier shall not appear in a type cast
    where the corresponding pointer component of the type of the expression
    being cast is not shared-qualified.\footnote{i.e., pointers-to-local
    cannot be cast to pointers-to-shared.}  An exception is made when the constant
    expression 0 is cast, the result is called the {\em null 
    pointer-to-shared}.\footnote{[ISO/IEC00 Sec.
    6.3.2.3/6.5.16.1] imply that an implicit cast is allowed for zero
    and that all null pointers-to-shared compare equal.}

{\bf Semantics} 

\np The casting or assignment from one pointer-to-shared 
    to another in which either the type size or block size differs results  in 
    a pointer with a zero phase, unless one of the types is a qualified or
    unqualified version of {\tt shared void*}, the {\em generic pointer-to-shared},
    in which case the phase is preserved unchanged in the resulting
    pointer value.
    
\np If a generic pointer-to-shared is cast to a non-generic 
     pointer-to-shared type with indefinite block size or with block size of 
     one, the result is a pointer with a phase of zero.  Otherwise, if the
     phase of the former pointer value is not within the range of possible
     phases of the latter pointer type, the result is undefined.
  
\np If a non-null pointer-to-shared is cast\footnote{As such pointers
     are not type compatible, explicit casts are required.} to a
     pointer-to-local\footnote{Accesses through such cast pointers are
     local accesses and behave accordingly.} and the affinity
     of the pointed-to shared object is not to the current thread, the result is
     undefined.
     
\np If a null pointer-to-shared is cast to a pointer-to-local,
     the result is a null pointer.    
       
\np Shared objects with affinity to a given thread can be
    accessed by either pointers-to-shared or pointers-to-local of
    that thread.

\np EXAMPLE 1: 
\begin{verbatim}
    int i, *p; 
    shared int *q; 
    q = (shared int *)p;         /* is not allowed */ 
    if (upc_threadof(q) == MYTHREAD)
        p = (int *) q;          /* is allowed */ 
\end{verbatim}

\subsubsection{Address operators}

\index{struct field, address-of}
{\bf Semantics} 

\npf When the unary {\tt \&} is applied to a shared structure
    element of type {\tt T}, the result has type {\tt shared [] T *}.

\subsection{Declarations}

\npf UPC extends the declaration ability of C to allow shared
     types, shared data layout across threads, and ordering constraint
     specifications.

{\bf Constraints} 

\index{strict}
\index{relaxed}
\index{block size}
\np The declaration specifiers in a given declaration shall
     not include, either directly or through one or more typedefs,
     both {\tt strict} and {\tt relaxed}.

 
\np The declaration specifiers in a given declaration shall
     not specify more than one block size, either directly or
     indirectly through one or more typedefs.

{\bf Syntax} 

\np The following is the declaration definition as per
    [ISO/IEC00 Sec. 6.7], repeated here for self-containment and
    clarity of the subsequent UPC extension specifications.

\np {\em declaration:}

\hspace{3em}{\em declaration-specifiers init-declarator-list$_{opt}$} {\bf ;}

\np{\em declaration-specifiers:}

\hspace{3em}{\em storage-class-specifier declaration-specifiers$_{opt}$}

\hspace{3em}{\em type-specifier declaration-specifiers$_{opt}$}

\hspace{3em}{\em type-qualifier declaration-specifiers$_{opt}$}

\hspace{3em}{\em function-specifier declaration-specifiers$_{opt}$}

\np {\em init-declarator-list:}

\hspace{3em}{\em init-declarator}

\hspace{3em}{\em init-declarator-list {\bf ,} init-declarator}

\np {\em init-declarator:}

\hspace{3em}{\em declarator}

\hspace{3em}{\em declarator {\bf =} initializer}

 {\bf Forward references:} strict and relaxed type qualifiers (\ref{type_qualifiers}). 

\subsubsection{Type qualifiers}
\index{strict}
\index{relaxed}
\index{shared layout qualifier}
\npf This subsection provides the UPC parallel extensions of
    in [ISO/IEC00 Sec 6.7.3].

{\bf Syntax} 

\np {\em type-qualifier:} 

\hspace{3em}{\bf const}

\hspace{3em}{\bf restrict}

\hspace{3em}{\bf volatile}

\hspace{3em}{\em shared-type-qualifier}

\hspace{3em}{\em reference-type-qualifier}

\paragraph{The shared and reference type qualifiers}\ \\
\label{type_qualifiers}
\label{indefinite_block_size}

{\bf Syntax} 

\npf {\em shared-type-qualifier:}

\hspace{3em}{\bf shared} {\em layout-qualifier$_{opt}$}

\np {\em reference-type-qualifier:}

\hspace{3em}{\bf relaxed}

\hspace{3em}{\bf strict}

\np{\em layout-qualifier:}

\hspace{3em}{\bf [}{\em constant-expression$_{opt}$}{\bf ]}

\hspace{3em}{\bf [ {\em *}  ]}

{\bf Constraints} 

\np A reference type qualifier shall appear in a qualifier
    list only when the list also contains a shared type qualifier.

\np A shared type qualifier can appear anywhere a type qualifier can appear
    except that it shall not appear in the {\em specifier-qualifier-list} of a structure
    declaration unless it qualifies a pointer's referenced type, nor shall it appear 
    in any declarator where prohibited by section \ref{declarator}.%
    \footnote{E.g., {\tt struct S1 \{ shared char * p1; \};} is allowed,
    while {\tt struct S2 \{ char * shared p2; \};} is not.}

\np A layout qualifier of [*] shall not appear in the
    declaration specifiers of a pointer type.

\np A layout qualifier shall not appear in the type
    qualifiers for the referenced type in a pointer to void type.

{\bf Semantics} 

\np Shared accesses shall be either strict or relaxed.
    Strict and relaxed shared accesses behave as described in section
    \ref{strict_relaxed} of this document.

\np An access shall be determined to be strict or relaxed
    as follows.  If the referenced type is strict-qualified or
    relaxed-qualified, the access shall be strict or relaxed,
    respectively.  Otherwise the access shall be determined to be
    strict or relaxed by the UPC pragma rules, as described in section
    6.6.1 of this document.

\index{block size, indefinite}
\index{block size, definite}
\index{block size, default}
\index{block size, automatically-computed}
\index{indefinite block size}
\index{definite block size}
\index{blocking factor}
\np The layout qualifier dictates the blocking factor for
    the type being shared qualified. This factor is the nonnegative
    number of consecutive elements (when evaluating pointer-to-shared
    arithmetic and array declarations) which have affinity to the
    same thread. If the optional constant expression is 0 or is not
    specified (i.e. {\tt[]}), this indicates an {\em indefinite blocking factor}\index{indefinite}
    where all elements have affinity to the same thread.  If there
    is no layout qualifier, the blocking factor has the default value
    (1). The blocking factor is also referred to as the block size.

\np A layout qualifier which does not specify an indefinite
    block size is said to specify a {\em definite block size} \index{definite block size}.

\index{pointer-to-shared, type compatibility}
\np The block size is a part of the type
    compatibility\footnote{This is a powerful statement which allows,
    for example, that in an implementation {\tt sizeof(shared int *)}
    may differ from {\tt sizeof (shared [10] int *)} and if T and S
    are pointer-to-shared types with different block sizes, then T* and S*
    cannot be aliases.}

\np For purposes of assignment compatibility, generic pointers-to-shared
    behave as if they always have a compatible block size.
        
\np If the layout qualifier is of the form `{\bf [ * ]}',
    the shared object is distributed as if it had a block size of

\begin{verbatim}
    ( sizeof(a) / upc_elemsizeof(a) + THREADS - 1 ) / THREADS, 
\end{verbatim}

    where `a' is the array being distributed. 

\index{shared declarations, examples}
\np EXAMPLE 1: declaration of a shared scalar 

\begin{verbatim}
    strict shared int y;
\end{verbatim}

    {\tt strict shared} is the type qualifier.

\np EXAMPLE 2: automatic storage duration 

\begin{verbatim}
    void foo (void) { 
    shared int x;  /* a shared automatic variable is not allowed  */ 
    shared int* y; /* a pointer-to-shared is allowed  */ 
    int * shared z; /*a shared automatic variable is not allowed*/ 
    ... } 
\end{verbatim}

\np EXAMPLE 3: inside a structure  

\begin{verbatim}
    struct foo { 
    shared int x;  /* this is not allowed  */ 
    shared int* y; /* a pointer-to-shared is allowed  */ 
    }; 
\end{verbatim}

{\bf Forward references:} shared array (\ref{shared_array})
\subsubsection{Declarators}
\label{declarator}

{\bf Syntax} 

\index{block size, declaration}
\npf The following is the declarator definition as per
    [ISO/IEC00 Sec. 6.7.5], repeated here for self-containment and
    clarity of the subsequent UPC extension specifications.

\np {\em declarator:}

\hspace{3em}{\em pointer$_{opt}$ direct-declarator}

\np {\em direct-declarator:}

\hspace{3em}{\em identifier }

\hspace{3em}{\em ( declarator )}

\hspace{3em}{\em direct-declarator {\bf [} type-qualifier-list$_{opt}$
                 assignment-expression$_{opt}$}{\bf ]}

\hspace{3em}{\em direct-declarator {\bf [ static} type-qualifier-list$_{opt}$
assignment-expression }{\bf ]}

\hspace{3em}{\em direct-declarator {\bf [} type-qualifier-list {\bf static}
                 assignment-expression }{\bf ]}

\hspace{3em}{\em direct-declarator {\bf [} type-qualifier-list$_{opt}$ }
                 {\bf * ]}

\hspace{3em}{\em direct-declarator {\bf (} parameter-type-list {\bf )}}

\hspace{3em}{\em direct-declarator {\bf (} identifier-list$_{opt}$ {\bf )}}

\np {\em pointer:}

\hspace{3em}{\em {\bf *} type-qualifier-list$_{opt}$}

\hspace{3em}{\em {\bf *} type-qualifier-list$_{opt}$  pointer}

\np{\em type-qualifier-list:}

\hspace{3em}{\em type-qualifier}

\hspace{3em}{\em type-qualifier-list type-qualifier}

{\bf Constraints} 

\index{shared declarations, restrictions}
\np No type qualifier list shall specify more than one block
    size, either directly or indirectly through one or more
    typedefs.\footnote{While layout qualifiers are most often seen in
    array or pointer declarators, they are allowed in all declarators.  For
    example, {\tt shared [3] int y} is allowed.}

\np No type qualifier list shall include both {\tt strict}
    and {\tt relaxed} either directly or indirectly through one or
    more typedefs.

\np No object with automatic storage duration shall have a type
    that is shared-qualified and no array object with automatic
    storage duration shall have an element type that is shared-qualified.

{\bf Semantics} 

\index{shared declarations, scalar}
\np All shared objects created by non-array static declarators have
    affinity with thread zero.

\paragraph{Array declarators}\ \\
\label{shared_array}
\index{shared declarations, array}
\index{dynamic THREADS environment}
\index{static THREADS environment}
\npf This subsection provides the UPC parallel extensions of
     [ISO/IEC00 Sec. 6.7.5.2].

{\bf Constraints} 

\np When a UPC program is translated in the {\em dynamic
    THREADS} environment and an array with shared-qualified elements
    is declared with definite blocksize, the THREADS expression shall
    occur exactly once in one dimension of the array declarator
    (including through typedefs).  Further, the THREADS expression
    shall only occur either alone or when multiplied by an integer
    constant expression.\footnote{In the {\em static THREADS} environment
    THREADS is an integer constant expression, and is therefore valid in
    all dimensions.} \footnote{This implies the THREADS expression
    shall not appear anywhere in the declarator of a shared array with
    indefinite blocksize under the {\em dynamic THREADS} environment.}


{\bf Semantics} 

\np Elements of shared arrays are distributed in a round
    robin fashion, by chunks of block-size elements, such that the
    i-th element has affinity with thread (floor (i/block\_size) {\tt
    mod THREADS}).

\np In an array declaration, the type qualifier applies to
    the elements.

\index{upc\_phaseof}
\np For any shared array, {\tt a}, {\tt upc\_phaseof (\&a)} is
    zero.

\index{shared declarations, examples}
\np EXAMPLE 1: declarations allowed in either {\em static THREADS} or
    {\em dynamic THREADS} translation environments:

\begin{verbatim}
    shared int x [10*THREADS];  
    shared [] int x [10]; 
\end{verbatim}

\np EXAMPLE 2: declarations allowed only in {\em static THREADS} translation
    environment:

\begin{verbatim}
    shared int x [10+THREADS];  
    shared [] int x [THREADS];  
    shared int x [10]; 
\end{verbatim}

\np EXAMPLE 3: declaration of a shared array 

\begin{verbatim}
    shared [3] int x [10];
\end{verbatim}

   {\tt shared [3]} is the type qualifier of an array, {\tt x}, of 10
   integers. {\tt [3]} is the layout qualifier.

\np EXAMPLE 4: 

\begin{verbatim}
    typedef int S[10]; 
    shared [3] S T[3*THREADS]; 
\end{verbatim}
   

   {\tt shared [3]} applies to the underlying type of T, which is int,
   regardless of the typedef.  The array is blocked as if it were
   declared:

\begin{verbatim}
    shared [3] int T[3*THREADS][10]; 
\end{verbatim}

\np EXAMPLE 5: 

\begin{verbatim}
    shared [] double D[100]; 
\end{verbatim}
    

   All elements of the array D have affinity to thread 0.  No {\tt
   THREADS} dimension is allowed in the declaration of D.

\np EXAMPLE 6: 

\begin{verbatim}
    shared [] long *p;
\end{verbatim}
    

   All elements accessed by subscripting or otherwise dereferencing
   p have affinity to the same thread.  That thread is determined by
   the assignment which sets p.

\subsection{Statements and blocks}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec. 6.8].

{\bf Syntax} 

\np {\em statement:}

\hspace{3em}{\em labeled-statement}

\hspace{3em}{\em compound-statement}

\hspace{3em}{\em expression-statement}

\hspace{3em}{\em selection-statement}

\hspace{3em}{\em iteration-statement}

\hspace{3em}{\em jump-statement}

\hspace{3em}{\em synchronization-statement}

\subsubsection{Barrier statements}
\label{upc_barrier}

{\bf Syntax} 

\npf {\em synchronization-statement:}

\hspace{3em}{\bf upc\_notify} {\em expression$_{opt}$} {\bf ;}

\hspace{3em}{\bf upc\_wait} {\em expression$_{opt}$} {\bf ;}

\hspace{3em}{\bf upc\_barrier} {\em expression$_{opt}$} {\bf ;}

\hspace{3em}{\bf upc\_fence ;}

{\bf Constraints} 

\np {\em expression} shall have type {\tt int}. 


{\bf Semantics} 

\index{synchronization}
\index{barriers}
\index{upc\_barrier}
\index{upc\_notify}
\index{upc\_wait}
\index{synchronization phase}
\index{memory consistency}
\index{collective}
\index{implicit barriers}

\np Each thread shall execute an alternating sequence of
     {\tt upc\_notify} and {\tt upc\_wait} statements, starting with a
     {\tt upc\_notify } and ending with a {\tt upc\_wait} statement.   After a
     thread executes {\tt upc\_notify} the next collective operation it executes
     must be a {\tt upc\_wait}.\footnote{This effectively prohibits issuing any
     collective operations between a {\tt upc\_notify} and  a {\tt upc\_wait}.}
     A synchronization phase consists of the execution of all statements
     between the completion of one {\tt upc\_wait} and the start of
     the next.

\np A {\tt upc\_wait} statement completes, and the
     thread enters the next synchronization phase, only after all
     threads have completed the {\tt upc\_notify} statement in the
     current synchronization phase.\footnote {Therefore,
     all threads are entering the same synchronization phase as they
     complete the {\tt upc\_wait} statement.}  {\tt upc\_wait}
     and {\tt upc\_notify} are {\em collective} operations.

\index{upc\_fence}
\np The {\tt upc\_fence} statement is equivalent to a {\em
    null} strict access.  This insures that all shared accesses
    issued before the fence are complete before any after it are
    issued.\footnote{One implementation of {\tt upc\_fence} 
    may be achieved by a null strict access:
     {\tt  \{ static shared strict int x; x = x;\}}} 

\index{null strict access}
\np A null strict access is implied before\footnote{After the evaluation 
    of {\em expression}, if present} a {\tt upc\_notify} statement and 
    after a {\tt upc\_wait} 
    statement.\footnote{This implies that shared accesses executed 
    after the {\tt upc\_notify} and before the {\tt upc\_wait} may occur in 
    either the synchronization phase containing the {\tt upc\_notify} or 
    the next on different threads.}

\np The {\tt upc\_wait} statement shall interrupt the execution of
    the program in an implementation defined manner
    if the value of its expression differs from the value of
    the expression on the {\tt upc\_notify} statement issued by any
    thread in the current
    synchronization phase.  After such an interruption, subsequent behavior
    is undefined. No "difference" exists if either statement is missing
    this optional expression.

%\np The {\tt upc\_wait} statement will generate a runtime
%    error if the value of its expression differs from any
%    expression on the {\tt upc\_wait} and {\tt upc\_notify}
%    statements issued by any thread in the current synchronization
%    phase.  No error will be generated from a ``difference'' involving
%    a statement for which no expression is given.

\np The {\tt upc\_barrier} statement is equivalent to the
    compound statement\footnote {This equivalence is explicit with
    respect to matching expressions in semantic 7 and collective
    status in semantic 3.}:

\begin{verbatim}
    { upc_notify barrier_value; upc_wait barrier_value; }
\end{verbatim}

    where {\tt barrier\_value} is the result of evaluating {\em expression}
    if present, otherwise omitted.

\np The barrier operations at thread
    startup and termination have a value of {\em expression} which is not in
    the range of the type {\tt int}.\footnote{These barriers are never expressed
    in a UPC source program and this semantic says these barrier values can
    never match one expressed in a user program.}

\np EXAMPLE 1:  The following will result in a runtime error:  
\begin{verbatim}
    { upc_notify; upc_barrier; upc_wait; }                 
\end{verbatim}

    as it is equivalent to 

\begin{verbatim}
    { upc_notify; upc_notify; upc_wait; upc_wait; } 
\end{verbatim}

\subsubsection{Iteration statements}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec. 6.8.5].

{\bf Syntax} 

\np {\em iteration-statement:}

\hspace{3em}{\bf while (} {\em expression} {\bf )} {\em statement}

\hspace{3em}{\bf do} {\em statement} {\bf while (} {\em expression} {\bf ) ;}

\hspace{3em}{\bf for (} {\em expression$_{opt}${\bf ;} 
                         expression$_{opt}${\bf ;}
expression$_{opt}${\bf )} statement}

\hspace{3em}{\bf for (} {\em declaration expression$_{opt}${\bf ;} 
                         expression$_{opt}${\bf )} statement}

\hspace{3em}{\bf upc\_forall (} {\em expression$_{opt}${\bf ;} 
expression$_{opt}${\bf ;}
expression$_{opt}${\bf ;}
affinity$_{opt}${\bf )}}
\makebox[5.4in][r] {\em statement}

\hspace{3em}{\bf upc\_forall (} {\em declaration expression$_{opt}${\bf ;} 
expression$_{opt}${\bf ;}}\\
\makebox[5.4in][r] {\em affinity$_{opt}${\bf )} statement}
                            

\np {\em affinity:}

\hspace{3em}{\em expression}

\hspace{3em}{\bf continue }

{\bf Constraints}: 

\np The {\em expression} for affinity shall have pointer-to-shared
    type or integer type.

{\bf Semantics}: 

\index{upc\_forall}
\index{continue}
\index{work sharing}
\index{parallel loop}
\np {\tt upc\_forall} is a {\em collective} operation in which, for each
    execution of the loop body, the controlling expression and
    affinity expression are {\em single-valued}.\footnote{Note that
    single-valued implies that all thread agree on the total number
    of iterations, their sequence, and which threads execute each
    iteration.}

\np The {\em affinity} field specifies the executions of the loop
    body which are to be performed by a thread.
    
\np When {\em affinity} is of pointer-to-shared type, the loop body of
    the {\tt upc\_forall} statement is executed for each iteration in
    which the value of {\tt MYTHREAD} equals the value of {\tt
    upc\_threadof(}{\em affinity}{\tt )}.  Each iteration of the  loop body is executed by
    precisely one thread.

\np When {\em affinity} is an integer expression, the loop body of
    the {\tt upc\_forall} statement is executed for each iteration in which
    the value of {\tt MYTHREAD} equals the value {\em affinity }{\tt mod THREADS}.

\np When {\em affinity} is {\tt continue} or not specified, each loop
    body of the {\tt upc\_forall} statement is performed by every thread and
    semantic 1 does not apply.

\np If the loop body of a {\tt upc\_forall} statement
    contains one or more {\tt upc\_forall} statements, either directly
    or through one or more function calls, the construct is called a
    {\em nested upc\_forall} statement.  In a {\em nested upc\_forall},
    the outermost {\tt upc\_forall} statement that has an {\em
    affinity} expression which is not {\tt continue} is called the
    {\em controlling upc\_forall} statement.  All {\tt upc\_forall}
    statements which are not controlling in a {\em nested
    upc\_forall} behave as if their {\em affinity} expressions were
    {\tt continue}.

\np Every thread evaluates the first three clauses of a 
    {\tt upc\_forall} statement in accordance with the semantics of
    the corresponding clauses for the {\tt for} statement, as defined in
    [ISO/IEC00 Sec. 6.8.5.3].  Every thread evaluates the fourth
    clause of every iteration.

\np If the execution of any loop body of a {\tt upc\_forall} statement
    produces a side-effect which affects the execution of another loop
    body of the same {\tt upc\_forall} statement which is executed by a different
    thread\footnote{This semantic implies that side effects on the same thread 
    have defined behavior, just like in the {\tt for} statement.}, the behavior is
    undefined.

\np If any thread terminates or executes a collective operation
   within the dynamic scope of a {\tt upc\_forall}
   statement, the result is undefined. If any thread terminates
   a  {\tt upc\_forall}  statement using a {\tt break},
   {\tt goto} , or {\tt return} statement, or the {\tt longjmp} function,
   the result is undefined.
   If any thread enters the body of a {\tt upc\_forall} statement
   using a {\tt goto} statement, the result is undefined.\footnote{The
   {\tt continue} statement behaves as defined in [ISO/IEC00 Sec. 
   6.8.6.2]; equivalent to a {\tt goto} the end of the loop body.}

\np EXAMPLE 1: Nested {\tt upc\_forall}: 

\begin{verbatim}
    main () { 
       int i,j,k; 
       shared float *a, *b, *c; 
    
       upc_forall(i=0; i<N; i++; continue) 
           upc_forall(j=0; j<N; j++; &a[j]) 
               upc_forall (k=0; k<N; k++; &b[k]) 
                   a[j] = b[k] * c[i]; 
    } 
\end{verbatim}

   This example executes all iterations of the ``i'' and ``k'' loops
   on every thread, and executes iterations of the ``j'' loop on those
   threads where {\tt upc\_threadof (\&a[j])} equals the value of {\tt
   MYTHREAD}.
   
\np EXAMPLE 2: Evaluation of upc\_forall arguments:

\begin{verbatim}
    int i;
    upc_forall((foo1(), i=0); (foo2(), i<10); (foo3(), i++); i) {
         foo4(i);
    }
\end{verbatim}
   Each thread evaluates foo1() exactly once, before any further action on that
   thread. Each thread will execute foo2() and foo3() in alternating sequence, 
   10 times on each thread. Assuming there is no enclosing upc\_forall loop, 
   foo4() will be evaluated exactly 10 times total before the last thread exits the 
   loop, once with each of i=0..9. Evaluations of foo4() may occur on different 
   threads (as determined by the affinity clause) with no implied synchronization 
   or serialization between foo4() evaluations or controlling expressions on 
   different threads. The final value of i is 10 on all threads.


\subsection{Preprocessing directives}

\npf This subsection provides the UPC parallel extensions of
   [ISO/IEC00 Sec. 6.10].

\subsubsection{UPC pragmas}
\label{pragmas}
{\bf Semantics} 
\index{pragmas}
\index{strict}
\index{relaxed}
\index{shared access}
\index{strict shared read}
\index{strict shared write}
\index{relaxed shared read}
\index{relaxed shared write}
\npf If the preprocessing token {\tt upc} immediately follows
    the {\tt pragma}, then no macro replacement is performed and the
    directive shall have one of the following forms:

\begin{verbatim}
     #pragma upc strict

     #pragma upc relaxed 
\end{verbatim}
 

\np These pragmas affect the strict or relaxed
    categorization of shared accesses where the
    referenced type is neither strict-qualified nor
    relaxed-qualified. Such accesses shall be strict if a strict
    pragma is in effect, or relaxed if a relaxed pragma is in effect.

\np Shared accesses which are not categorized by either
    referenced type or by these pragmas behave in an implementation
    defined manner in which either all such accesses are strict or
    all are relaxed.  Users wishing portable programs are strongly
    encouraged to categorize all shared accesses either by using
    type qualifiers, these directives, or by including {\tt <upc\_strict.h>}
    or {\tt <upc\_relaxed.h>}.

\np The pragmas shall occur either outside external
    declarations or preceding all explicit declarations and statements
    inside a compound statement.  When they are outside external
    declarations, they apply until another such pragma or the end of
    the translation unit.  When inside a compound statement, they
    apply until the end of the compound statement; at the end of the
    compound statement the state of the pragmas is restored to that
    preceding the compound statement.  If these pragmas are used in
    any other context, their behavior is undefined.

\subsubsection{Predefined macro names}

\index{predefined macros}
\npf The following macro names shall be defined by the
    implementation\footnote{In addition to these macro names,
    the semantics of [ISO/IEC00 Sec. 6.10.8] apply to the identifier MYTHREAD.}

\begin{description}
\item {\tt \_\_UPC\_\_} 
\index{\_\_UPC\_\_}
The integer constant 1, indicating a conforming implementation.

\item{\tt \_\_UPC\_VERSION\_\_}
\index{\_\_UPC\_VERSION\_\_}
The integer constant 200505L.

\item{\tt UPC\_MAX\_BLOCK\_SIZE}
\index{UPC\_MAX\_BLOCK\_SIZE}
The integer constant as defined in section \ref{max_block_size}.
\end{description}

\np The following macro names are conditionally defined 
    by the implementation:

\begin{description}
\item {\tt \_\_UPC\_DYNAMIC\_THREADS\_\_} 
\index{\_\_UPC\_DYNAMIC\_THREADS\_\_} 
\index{dynamic THREADS environment}
The integer constant 1 in the {\em dynamic THREADS} translation environment,
otherwise undefined.

\item{\tt \_\_UPC\_STATIC\_THREADS\_\_} 
\index{\_\_UPC\_STATIC\_THREADS\_\_} 
\index{static THREADS environment}
The integer constant 1 in the {\em static THREADS} translation environment,
otherwise undefined.

\item{\tt THREADS}
\index{THREADS}
\index{MYTHREAD}
The integer constant as defined in section \ref{threads} in the
{\em static THREADS} translation environment.

\end{description}

\pagebreak
\section{Library}
\subsection{Standard headers}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec 7.1.2].


\np The standard headers are 

\begin{verbatim}
    <upc_strict.h> 
    <upc_relaxed.h>
    <upc_collective.h>
    <upc.h> 
\end{verbatim}

\index{upc\_strict.h}
\np Every inclusion of {\tt <upc\_strict.h>} asserts the upc 
    strict pragma and has the effect of including {\tt <upc.h>}.

\index{upc\_relaxed.h}
\np Every inclusion of {\tt <upc\_relaxed.h>} asserts the upc 
    relaxed pragma and has the effect of including {\tt <upc.h>}.

\index{collective}
\np By convention, all UPC standard library functions are  named
    using the prefix {\tt upc\_}.  Those which are collective have
    prefix {\tt upc\_all\_}. 

\pagebreak
\subsection{UPC utilities \tt{<upc.h>}}

\npf This subsection provides the UPC parallel extensions of
    [ISO/IEC00 Sec 7.20].  All of the characteristics of library functions
    described in [ISO/IEC00 Sec 7.1.4] apply to these as well.

\subsubsection{Termination of all threads}
\label{upc_global_exit}

{\bf Synopsis} 

\index{upc\_global\_exit}
\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
     void upc_global_exit(int status);
\end{verbatim}

{\bf Description}

\np {\tt upc\_global\_exit()} flushes all I/O, releases all
      storage, and terminates the execution for all active threads.

\subsubsection{Shared memory allocation functions}
\index{shared object, allocation}
\index{memory allocation}

\npf The UPC memory allocation functions return, if successful,
    a pointer-to-shared which is suitably aligned so that it may be assigned 
    to a pointer-to-shared of any type.  The pointer has zero phase and points
    to the start of the allocated space.  If the space cannot be allocated, a null
    pointer-to-shared is returned.
    
\paragraph{The {\tt upc\_global\_alloc} function}\ \\

{\bf Synopsis} 

\index{upc\_global\_alloc}
\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    shared void *upc_global_alloc(size_t nblocks, size_t nbytes); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_global\_alloc} allocates shared space
     compatible with the declaration:

\begin{verbatim}
        shared [nbytes] char[nblocks * nbytes]. 
\end{verbatim}

\np The {\tt upc\_global\_alloc} function is not a {\em
    collective} function. If called by multiple threads,
    all threads which make the call get different allocations.
    If {\tt nblocks*nbytes} is zero, the result is a null pointer-to-shared.
    
\paragraph{The {\tt upc\_all\_alloc} function}\ \\

{\bf Synopsis} 
\index{upc\_all\_alloc}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    shared void *upc_all_alloc(size_t nblocks, size_t nbytes); 
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_alloc} is a {\em collective} function with
    {\em single-valued} arguments.

\np The {\tt upc\_all\_alloc} function allocates  shared 
      space compatible with the following declaration:

\begin{verbatim}
    shared [nbytes] char[nblocks * nbytes].  
\end{verbatim}

\np The {\tt upc\_all\_alloc} function returns the same pointer
   value on all threads. 
   If {\tt nblocks*nbytes} is zero, the result is a null pointer-to-shared.
   
\np The dynamic lifetime of an allocated object extends from
   the time any thread completes the call to {\tt upc\_all\_alloc}
   until any thread has deallocated the object.

\paragraph{The {\tt upc\_alloc} function}\ \\

{\bf Synopsis} 
\index{upc\_alloc}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    shared void *upc_alloc(size_t nbytes); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_alloc} function allocates shared space of at
    least {\tt nbytes} bytes with affinity to the calling thread. 

\np {\tt upc\_alloc} is similar to malloc() except that it
    returns a pointer-to-shared value. It is not a {\em collective} function.
    If {\tt nbytes} is zero, the result is a null pointer-to-shared.

\paragraph{The {\tt upc\_local\_alloc} function {\em deprecated}}\ \\

{\bf Synopsis} 
\index{upc\_local\_alloc}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    shared void *upc_local_alloc(size_t nblocks, size_t nbytes); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_local\_alloc} function is deprecated and should not be used.
    UPC programs should use the {\tt upc\_alloc} function instead.
    Support may be removed in future versions of this specification.

\np The {\tt upc\_local\_alloc} function allocates shared space of at
    least {\tt nblocks * nbytes} bytes with affinity to the calling thread. 
    If {\tt nblocks*nbytes} is zero, the result is a null pointer-to-shared.

\np {\tt upc\_local\_alloc} is similar to malloc() except that it
    returns a pointer-to-shared value. It is not a {\em collective} function.

\paragraph{The {\tt upc\_free} function}\ \\

{\bf Synopsis} 
\index{upc\_free}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_free(shared void *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_free} function frees the dynamically
    allocated shared storage pointed to by {\tt ptr}.  If {\tt ptr} is
    a null pointer, no action occurs.  Otherwise, if the argument does
    not match a pointer earlier returned by the {\tt upc\_alloc, } 
    {\tt upc\_global\_alloc,}  {\tt upc\_all\_alloc,}  or {\tt upc\_local\_alloc,} function,
    or if the space has been deallocated by a previous call, by any 
    thread,\footnote {i.e., only one thread may call {\tt upc\_free} for
     each allocation} to {\tt upc\_free,} the behavior is undefined.

\subsubsection{Pointer-to-shared manipulation functions}

\paragraph{The {\tt upc\_threadof} function}\ \\
\label{upc_threadof}

{\bf Synopsis} 
\index{upc\_threadof}
\index{affinity}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    size_t upc_threadof(shared void *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_threadof} function returns the index of the
   thread that has affinity to the shared object pointed to by {\tt ptr}.\footnote{%
   This function is used in defining the semantics of pointer-to-shared
   arithmetic in Section \ref{pointer-arithmetic}}

\np If {\tt ptr} is a null pointer-to-shared, the function returns 0.


\paragraph{The {\tt upc\_phaseof} function}\ \\
\label{upc_phaseof}

{\bf Synopsis} 
\index{upc\_threadof}
\index{phase}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    size_t upc_phaseof(shared void *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_phaseof} function returns the phase component of the
    pointer-to-shared argument.\footnote{%
   This function is used in defining the semantics of pointer-to-shared
   arithmetic in Section \ref{pointer-arithmetic}}

    
\np If {\tt ptr} is a null pointer-to-shared, the function returns 0.

\paragraph{The {\tt upc\_resetphase} function}\ \\

{\bf Synopsis} 
\index{upc\_resetphase}
\index{phase}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    shared void *upc_resetphase(shared void *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_resetphase} function returns a pointer-to-shared
    which is identical to its input except that it has zero phase. 

\paragraph{The {\tt upc\_addrfield} function}\ \\
\label{upc_addrfield}

{\bf Synopsis} 
\index{upc\_addrfield}

\npf\vspace{-2.5em}

\begin{verbatim}
    #include <upc.h> 
    size_t upc_addrfield(shared void *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_addrfield} function returns an
   implementation-defined value reflecting the ``local address'' of the
   object pointed to by the pointer-to-shared argument.\footnote{%
   This function is used in defining the semantics of pointer-to-shared
   arithmetic in Section \ref{pointer-arithmetic}}

   
\paragraph{The {\tt upc\_affinitysize} function}\ \\

{\bf Synopsis} 
\index{upc\_affinitysize}
\index{upc\_localsizeof}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    size_t upc_affinitysize(size_t totalsize, size_t nbytes, 
         size_t threadid);
\end{verbatim}

{\bf Description}

\np {\tt upc\_affinitysize} is a convenience function which 
    calculates the exact size of the local portion of the data in a 
    shared object with affinity to {\tt threadid}.
    
\np In the case of a dynamically allocated shared object,
    the {\tt totalsize} argument shall be {\tt nbytes*nblocks} and the {\tt nbytes}
    argument shall be {\tt nbytes}, where {\tt nblocks} and {\tt nbytes} are exactly as
    passed to {\tt upc\_global\_alloc} or {\tt upc\_all\_alloc} when the 
    object was allocated.

\np In the case of a statically allocated shared object
    with declaration:

\begin{verbatim}
    shared [b] t d[s];
\end{verbatim}   

    the {\tt totalsize} argument shall be {\tt s * sizeof (t)} and the
    {\tt nbytes} argument shall be {\tt b * sizeof (t)}.  If the block
    size is indefinite, {\tt nbytes} shall be 0.
        
\np {\tt threadid} shall be a value in {\tt 0..(THREADS-1)}.

\subsubsection{Lock functions}
\label{upc_lock}
\index{locks}
\index{synchronization}
\index{mutual exclusion}

\paragraph{Type}\ \\

\npf The type declared is 
\index{upc\_lock\_t}

\begin{verbatim}
    upc_lock_t 
\end{verbatim}

\np The type {\tt upc\_lock\_t} is an opaque UPC type. {\tt
    upc\_lock\_t} is a shared datatype with incomplete type (as
    defined in [ISO/IEC00 Sec 6.2.5]).  Objects of type {\tt
    upc\_lock\_t} may therefore only be manipulated through pointers.
    Such objects have two states called {\em locked} and {\em unlocked}.

\np Two pointers to that reference the same lock object will
    compare as equal.  The results of applying {\tt upc\_phaseof()},
     {\tt upc\_threadof()}, and {\tt upc\_addrfield()} to such pointers
     are undefined.
\paragraph{The {\tt upc\_global\_lock\_alloc} function}\ \\

{\bf Synopsis} 
\index{upc\_global\_lock\_alloc}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    upc_lock_t *upc_global_lock_alloc(void); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_global\_lock\_alloc} function dynamically
    allocates a lock and returns a pointer to it.  The lock is created
    in an unlocked state.

\np The {\tt upc\_global\_lock\_alloc} function is not a {\em
    collective} function. If called by multiple threads,
    all threads which make the call get different allocations.
    
\paragraph{The {\tt upc\_all\_lock\_alloc} function}\ \\

{\bf Synopsis} 
\index{upc\_all\_lock\_alloc}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    upc_lock_t *upc_all_lock_alloc(void); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_all\_lock\_alloc} function dynamically
    allocates a lock and returns a pointer to it. The lock is created
    in an unlocked state.

\np The {\tt upc\_all\_lock\_alloc} is a {\em collective}
    function.  The return value on every thread points to the same
    lock object.

\paragraph{The {\tt upc\_lock\_free} function}\ \\

{\bf Synopsis} 
\index{upc\_lock\_free}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_lock_free(upc_lock_t *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_lock\_free} function frees all resources
    associated with the dynamically allocated {\tt upc\_lock\_t} pointed to
    by {\tt ptr}.  If {\tt ptr} is a null pointer, no action occurs.
    Otherwise, if the argument does not match a pointer earlier
    returned by the {\tt upc\_global\_lock\_alloc} or {\tt
    upc\_all\_lock\_alloc} function, or if the lock has been
    deallocated by a previous call to {\tt upc\_lock\_free,}\footnote
    {i.e., only one thread may call {\tt upc\_lock\_free} for each
    allocation} the behavior is undefined.

\np {\tt upc\_lock\_free} succeeds regardless of whether the
    referenced lock is currently unlocked or currently locked (by any
    thread).

\np Any subsequent calls to locking functions from any
    thread using {\tt ptr} have undefined effects. This also
    applies to any thread currently calling {\tt upc\_lock}.

\paragraph{The {\tt upc\_lock} function}\ \\

{\bf Synopsis} 
\index{upc\_lock}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_lock(upc_lock_t *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_lock} function sets the state of the lock
    pointed to by {\em ptr} to locked.

\np If the lock is already in locked state due to the calling thread setting it
    to locked state, the result is undefined.

\np If the lock is already in locked state, then the calling
    thread waits for some other thread to set the state to 
    unlocked.\footnote{If no other thread calls {\tt upc\_unlock} on {\em ptr}
    the calling thread will never return from this function.}

\np Once the lock is in state unlocked, a single calling thread
    sets the state to locked and the function returns.

\np A null strict access is implied after a call to {\tt
    upc\_lock()}.

\paragraph{The {\tt upc\_lock\_attempt} function}\ \\

{\bf Synopsis} 
\index{upc\_lock\_attempt}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    int upc_lock_attempt(upc_lock_t *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_lock\_attempt} function attempts to set the state of
   the lock pointed to by {\em ptr} to locked.

\np If the lock is already in locked state due to the calling thread setting it
    to locked state, the result is undefined.

\np If the lock is already in locked state the function returns 0.
    
\np If the lock is in state unlocked, a single calling thread
    sets the state to locked and the function returns 1.

\np A null strict access is implied after a call to {\tt
    upc\_lock\_attempt()} that returns 1.

\paragraph{The {\tt upc\_unlock} function}\ \\

{\bf Synopsis} 
\index{upc\_unlock}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_unlock(upc_lock_t *ptr); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_unlock} function sets the state of
   the lock pointed to by {\em ptr} to unlocked.

\np Unless the lock is in locked state and the calling
    thread is the locking thread, the result is undefined.

\np A null strict access is implied before a call to {\tt
    upc\_unlock()}.

\subsubsection{Shared string handling functions}
\index{shared object, copying}
\index{memory copy}

\paragraph{The {\tt upc\_memcpy} function}\ \\

{\bf Synopsis} 
\index{upc\_memcpy}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_memcpy(shared void * restrict dst, 
         shared const void * restrict src, size_t n); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_memcpy} function copies {\tt n} characters
  from a shared object having affinity with one thread to a shared object
  having affinity with the same or another thread.

\np The {\tt upc\_memcpy} function treats the {\tt dst} and
   {\tt src} pointers as if they had type:

\begin{verbatim}
    shared [] char[n] 
\end{verbatim}

   The effect is equivalent to copying the entire contents from one
   shared array object with this type (the {\tt src} array) to another shared
   array object with this type (the {\tt dst} array).

\paragraph{The {\tt upc\_memget} function}\ \\

{\bf Synopsis} 
\index{upc\_memget}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_memget(void * restrict dst, 
         shared const void * restrict src, size_t n); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_memget} function copies {\tt n} characters from a
   shared object with affinity to any single thread to an object on the calling thread.

\np The {\tt upc\_memget} function treats the {\tt src}
   pointer as if it had type:

\begin{verbatim}
    shared [] char[n] 
\end{verbatim}

   The effect is equivalent to copying the entire contents from one
   shared array object with this type (the {\tt src} array) to an array
   object (the {\tt dst} array) declared with the type

\begin{verbatim}
    char[n] 
\end{verbatim}

\paragraph{The {\tt upc\_memput} function}\ \\

{\bf Synopsis} 
\index{upc\_memput}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_memput(shared void * restrict dst,
         const void * restrict src, size_t n); 
\end{verbatim}

{\bf Description}
 
\np The {\tt upc\_memput} function copies {\tt n} characters from
   an object on the calling thread to a shared object with affinity
   to any single thread.
   
\np The {\tt upc\_memput} function is equivalent to copying the
   entire contents from an array object (the {\tt src} array) declared
   with the type

\begin{verbatim}
    char[n] 
\end{verbatim}

   to a shared array object (the {\tt dst} array) with the type 

\begin{verbatim}
    shared [] char[n] 
\end{verbatim}

\paragraph{The {\tt upc\_memset} function}\ \\

{\bf Synopsis}
\index{upc\_memset}
\index{shared object, clearing}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    void upc_memset(shared void *dst, int c, size_t n); 
\end{verbatim}

{\bf Description}

\np The {\tt upc\_memset} function copies the value of {\tt
   c}, converted to an {\tt unsigned char}, to a shared object with affinity
   to any single thread.  The number of bytes set is {\tt n}.

\np The {\tt upc\_memset} function treats the {\tt dst}
   pointer as if had type:

\begin{verbatim}
    shared [] char[n] 
\end{verbatim}

   The effect is equivalent to setting the entire contents of a shared
   array object with this type (the {\tt dst} array) to the value {\tt c}.


\subsubsection{Memory Semantics of Library Functions}
\label{upc-flag-t}
\index{memory consistency}
\index{UPC\_OUT\_ALLSYNC}
\index{UPC\_OUT\_MYSYNC}
\index{UPC\_OUT\_NOSYNC}
\index{UPC\_IN\_ALLSYNC}
\index{UPC\_IN\_MYSYNC}
\index{UPC\_IN\_NOSYNC}
\index{upc\_flag\_t}

\npf {\tt upc\_flag\_t} is an integral type defined in {\tt<upc.h>} which is used to
    control the data synchronization semantics of certain collective
    UPC library functions.  Values of function arguments
    having type {\tt upc\_flag\_t} are formed by or-ing together a
    constant of the form {\tt UPC\_IN\_{\em X}SYNC} and a constant of
    the form {\tt UPC\_OUT\_{\em Y}SYNC}, where {\tt {\em X}} and {\tt
    {\em Y}} may be {\tt NO}, {\tt MY}, or {\tt ALL}.

\np If an argument of type {\tt upc\_flag\_t} has value
    {\tt (UPC\_IN\_{\em X}SYNC}$\;|\;${\tt UPC\_OUT\_{\em Y}SYNC)},
    then if {\tt {\em X}} is

\begin{description}
    \item[{\tt NO}] the function may begin to read or write
    data when the first thread has entered the collective function call,

    \item[{\tt MY}] the function may begin to read or write only
    data which has affinity to threads that have entered the collective
    function call, and

    \item[{\tt ALL}] the function may begin to read or write
    data only after all threads have entered
    the function call\footnote{{\tt UPC\_IN\_ALLSYNC} requires the
    function to guarantee that
    after all threads have entered the function call all
    threads will read the same values of the input data.}
\end{description}

\np and if {\tt {\em Y}} is

\begin{description}
    \item[{\tt NO}] the function may read and write data until
    the last thread has returned from the collective function call,

    \item[{\tt MY}] the function call may return in a thread
    only after all reads and writes of data with affinity to the thread
    are complete\footnote{{\tt UPC\_OUT\_MYSYNC} requires the 
  function to guarantee that after a thread returns from the
  function call the thread will not read any earlier values of the
  output data with affinity to that thread.}, and

    \item[{\tt ALL}] the function call may return only after
  all reads and writes of data are complete.\footnote{{\tt UPC\_OUT\_ALLSYNC}
  requires the collective function to guarantee that after a thread returns
  from the function call the thread will not read any earlier
  values of the output data.

  {\tt UPC\_OUT\_ALLSYNC} is not required to provide an ``implied"
  barrier.  For example, if the entire operation has been
  completed by a certain thread before some other threads have reached
  their corresponding function calls, then that thread may exit its call.}
\end{description}

\np Passing {\tt UPC\_IN\_{\em X}SYNC} alone has the same effect as
   {\tt (UPC\_IN\_{\em X}SYNC}$\;|\;${\tt UPC\_OUT\_ALLSYNC)},
   passing {\tt UPC\_OUT\_{\em X}SYNC} alone has the same effect as
   {\tt (UPC\_IN\_ALLSYNC}$\;|\;${\tt UPC\_OUT\_{\em X}SYNC)},
   and passing 0 has the same effect as
   {\tt (UPC\_IN\_ALLSYNC}$\;|\;${\tt UPC\_OUT\_ALLSYNC)},
   where {\tt {\em X}} is {\tt NO}, {\tt MY}, or {\tt ALL}.
   
\np Each of the six flags {\tt UPC\_\{IN,OUT\}\_\{NO,MY,ALL\}SYNC} are
   macros which expand to integer constant expressions.  The expressions
   are defined such that bitwise ORs of all combinations of the macros result
   in distinct positive values less than 64.

\pagebreak
\subsection{UPC Collective Utilities {\tt <upc\_collective.h>}}
\label{upc-collective}
\index{collective libarary}
\index{\_\_UPC\_COLLECTIVE\_\_}
\index{upc\_collective.h}

\npf Implementations that support this interface shall predefine the
    feature macro {\tt \_\_UPC\_COLLECTIVE\_\_} to the value 1.

\np The following requirements apply to all of the functions defined
in this section.

\np All of the functions are collective.

\np All collective function arguments are single-valued.

\np Collective functions may not be called between {\tt upc\_notify}
and the corresponding {\tt upc\_wait}.

\np The standard header is

{\tt <upc\_collective.h>}

\subsubsection{Relocalization Operations}

\paragraph{The {\tt upc\_all\_broadcast} function}\ \\
\index{upc\_all\_broadcast}
\index{broadcast}

{\bf Synopsis} 

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_broadcast(shared void * restrict dst, 
         shared const void * restrict src, size_t nbytes, 
         upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np The {\tt upc\_all\_broadcast} function copies a block of memory with
affinity to a single thread to a block of shared memory on each thread.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np The {\tt upc\_all\_broadcast} function treats the {\tt src} pointer
as if it pointed to a shared memory area with the type:

\begin{verbatim}
    shared [] char[nbytes]
\end{verbatim}  

\np The effect is equivalent to copying the entire array pointed to by
{\tt src} to each block of {\tt nbytes} bytes of a shared
array {\tt dst} with the type:

\begin{verbatim}
    shared [nbytes] char[nbytes * THREADS]
\end{verbatim}  

\np The target of the {\tt dst} pointer must have affinity to
thread 0.

\np The {\tt dst} pointer is treated as if it has phase 0.

\np EXAMPLE 1 shows {\tt upc\_all\_broadcast}
\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  shared int A[THREADS];
  shared int B[THREADS];
  // Initialize A.
  upc_barrier;
  upc_all_broadcast( B, &A[1], sizeof(int),
                     UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\np EXAMPLE 2:
\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [] int A[NELEMS];
  shared [NELEMS] int B[NELEMS*THREADS];
  // Initialize A.
  upc_all_broadcast( B, A, sizeof(int)*NELEMS,
                     UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\np EXAMPLE 3 shows {\tt (A[3],A[4])} is broadcast to
{\tt (B[0],B[1])}, {\tt (B[10],B[11])}, \\
{\tt (B[20],B[21])}, ..., 
{\tt (B[NELEMS*(THREADS-1)],B[NELEMS*(THREADS-1)+1])}.
\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS];
  shared [NELEMS] int B[NELEMS*THREADS];
  // Initialize A.
  upc_barrier;
  upc_all_broadcast( B, &A[3], sizeof(int)*2,
                     UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\paragraph{The {\tt upc\_all\_scatter} function}\ \\

{\bf Synopsis} 
\index{upc\_all\_scatter}
\index{scatter}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_scatter(shared void * restrict dst, 
         shared const void * restrict src, size_t nbytes, 
         upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np The {\tt upc\_all\_scatter} function copies the $i$th block of an
area of shared memory with affinity to a single thread
to a block of shared memory with affinity to the $i$th thread.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np The {\tt upc\_all\_scatter} function treats the {\tt src} pointer
as if it pointed to a shared memory area with the type:

\begin{verbatim}
    shared [] char[nbytes * THREADS]
\end{verbatim}  

\np and it treats the {\tt dst} pointer as if it pointed to a shared
memory area with the type:

\begin{verbatim}
    shared [nbytes] char[nbytes * THREADS]
\end{verbatim}  

\np The target of the {\tt dst} pointer must have affinity to thread 0.

\np The {\tt dst} pointer is treated as if it has phase 0.

\np For each thread $i$, the effect is equivalent to copying
the $i$th block of {\tt nbytes} bytes pointed to by {\tt src} to
the block of {\tt nbytes} bytes 
pointed to by {\tt dst} that has affinity to thread $i$.

\np EXAMPLE 1 {\tt upc\_all\_scatter} for the {dynamic THREADS} translation
environment.
%This example corresponds to Figure \ref{fig2}.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NUMELEMS 10
  #define SRC_THREAD 1
  shared int *A;
  shared [] int *myA, *srcA;
  shared [NUMELEMS] int B[NUMELEMS*THREADS];

  // allocate and initialize an array distributed across all threads
  A = upc_all_alloc(THREADS, THREADS*NUMELEMS*sizeof(int));
  myA = (shared [] int *) &A[MYTHREAD];
  for (i=0; i<NUMELEMS*THREADS; i++)
      myA[i] = i + NUMELEMS*THREADS*MYTHREAD;   // (for example)
  // scatter the SRC_THREAD's row of the array
  srcA = (shared [] int *) &A[SRC_THREAD];
  upc_barrier;
  upc_all_scatter( B, srcA, sizeof(int)*NUMELEMS,
                   UPC_IN_NOSYNC | UPC_OUT_NOSYNC);
  upc_barrier;
\end{verbatim}

\np EXAMPLE 2 {\tt upc\_all\_scatter} for the {\em static THREADS} 
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [] int A[NELEMS*THREADS];
  shared [NELEMS] int B[NELEMS*THREADS];
  // Initialize A.
  upc_all_scatter( B, A, sizeof(int)*NELEMS,
                   UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\paragraph{The {\tt upc\_all\_gather} function}\ \\

{\bf Synopsis} 
\index{upc\_all\_gather}
\index{gather}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_gather(shared void * restrict dst,
         shared const void * restrict src, size_t nbytes,
         upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np The {\tt upc\_all\_gather} function copies a block of shared memory
that has affinity to the $i$th thread to the $i$th block
of a shared memory area that has affinity to a single thread.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np The {\tt upc\_all\_gather} function treats the {\tt src} pointer
as if it pointed to a shared memory area of {\tt nbytes} bytes on each
thread and therefore had type:

\begin{verbatim}
    shared [nbytes] char[nbytes * THREADS]
\end{verbatim}  

\np and it treats the {\tt dst} pointer as if it pointed to a shared
memory area with the type:

\begin{verbatim}
    shared [] char[nbytes * THREADS]
\end{verbatim} 

\np The target of the {\tt src} pointer must have affinity to thread 0.

\np The {\tt src} pointer is treated as if it has phase 0.

\np For each thread $i$, the effect is equivalent to copying
the block of {\tt nbytes} bytes
pointed to by {\tt src} that has affinity to thread $i$
to the $i$th block of {\tt nbytes} bytes pointed to by {\tt dst}.

\np EXAMPLE 1 {\tt upc\_all\_gather} for the {\em static THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS];
  shared [] int B[NELEMS*THREADS];
  // Initialize A.
  upc_all_gather( B, A, sizeof(int)*NELEMS,
                  UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\np EXAMPLE 2 {\tt upc\_all\_gather} for the {\em dynamic THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS];
  shared [] int *B;
  B = (shared [] int *) upc_all_alloc(1,NELEMS*THREADS*sizeof(int));
  // Initialize A.
  upc_barrier;
  upc_all_gather( B, A, sizeof(int)*NELEMS,
                  UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\paragraph{The {\tt upc\_all\_gather\_all} function}\ \\

{\bf Synopsis} 
\index{upc\_all\_gather\_all}
\index{gather, to all}

\npf\vspace{-2.5em} 
\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_gather_all(shared void * restrict dst,
         shared const void * restrict src, size_t nbytes,
         upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np
The {\tt upc\_all\_gather\_all} function copies a block of memory from one
shared memory area with affinity to the $i$th thread to the $i$th block
of a shared memory area on each thread.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np The {\tt upc\_all\_gather\_all} function treats the {\tt src} pointer
as if it pointed to a shared memory area of {\tt nbytes} bytes on each
thread and therefore had type:

\begin{verbatim}
    shared [nbytes] char[nbytes * THREADS]
\end{verbatim}  

\np and it treats the {\tt dst} pointer as if it pointed to a shared
memory area with the type:

\begin{verbatim}
    shared [nbytes * THREADS] char[nbytes * THREADS * THREADS]
\end{verbatim} 

\np The targets of the {\tt src} and {\tt dst} pointers
must have affinity to thread 0.

\np The {\tt src} and {\tt dst} pointers are treated as
if they have phase 0.

\np
The effect is equivalent to copying the
$i$th block of {\tt nbytes} bytes pointed to by {\tt src} to the
$i$th block of {\tt nbytes} bytes pointed to by {\tt dst} that
has affinity to each thread.

\np EXAMPLE 1 {\tt upc\_all\_gather\_all} for the {\em static THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS];
  shared [NELEMS*THREADS] int B[THREADS][NELEMS*THREADS];
  // Initialize A.
  upc_barrier;
  upc_all_gather_all( B, A, sizeof(int)*NELEMS,
                      UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\np EXAMPLE 2 {\tt upc\_all\_gather\_all} for the {\em dynamic THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS];
  shared int *Bdata;
  shared [] int *myB;

  Bdata = upc_all_alloc(THREADS*THREADS, NELEMS*sizeof(int));
  myB = (shared [] int *)&Bdata[MYTHREAD];

  // Bdata contains THREADS*THREADS*NELEMS elements.
  // myB is MYTHREAD's row of Bdata.
  // Initialize A.
  upc_all_gather_all( Bdata, A, NELEMS*sizeof(int),
                      UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\paragraph{The {\tt upc\_all\_exchange} function}\ \\
\index{upc\_all\_exchange}
\index{exchange}

{\bf Synopsis} 

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_exchange(shared void * restrict dst, 
         shared const void * restrict src, size_t nbytes,
         upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np The {\tt upc\_all\_exchange} function copies the $i$th block of memory
from a shared memory area that has affinity to thread $j$ to the $j$th block
of a shared memory area that has affinity to thread $i$.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np The {\tt upc\_all\_exchange} function treats the {\tt src} pointer
and the {\tt dst} pointer as if each
pointed to a shared memory area of {\tt nbytes}$*${\tt THREADS} bytes
on each thread and therefore had type:

\begin{verbatim}
    shared [nbytes * THREADS] char[nbytes * THREADS * THREADS]
\end{verbatim}  

\np The targets of the {\tt src} and {\tt dst} pointers
must have affinity to thread 0.

\np The {\tt src} and {\tt dst} pointers are treated as
if they have phase 0.

\np For each pair of threads $i$ and $j$, the effect is equivalent to copying
the $i$th block of {\tt nbytes} bytes that has affinity to thread $j$
pointed to by {\tt src}
to
the $j$th block of {\tt nbytes} bytes that has affinity to thread $i$ 
pointed to by {\tt dst}.

\np EXAMPLE 1 {\tt upc\_all\_exchange} for the {\em static THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS*THREADS] int A[THREADS][NELEMS*THREADS];
  shared [NELEMS*THREADS] int B[THREADS][NELEMS*THREADS];
  // Initialize A.
  upc_barrier;
  upc_all_exchange( B, A, NELEMS*sizeof(int),
                    UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\np EXAMPLE 2 {\tt upc\_all\_exchange} for the {\em dynamic THREADS}
translation environment.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared int *Adata, *Bdata;
  shared [] int *myA, *myB;
  int i;

  Adata = upc_all_alloc(THREADS*THREADS, NELEMS*sizeof(int));
  myA = (shared [] int *)&Adata[MYTHREAD];
  Bdata = upc_all_alloc(THREADS*THREADS, NELEMS*sizeof(int));
  myB = (shared [] int *)&Bdata[MYTHREAD];

  // Adata and Bdata contain THREADS*THREADS*NELEMS elements.
  // myA and myB are MYTHREAD's rows of Adata and Bdata, resp.

  // Initialize MYTHREAD's row of A.  For example,
  for (i=0; i<NELEMS*THREADS; i++)
      myA[i] = MYTHREAD*10 + i;

  upc_all_exchange( Bdata, Adata, NELEMS*sizeof(int),
                    UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\paragraph{The {\tt upc\_all\_permute} function}\ \\
\index{upc\_all\_permute}
\index{permute}

{\bf Synopsis} 

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_collective.h>
    void upc_all_permute(shared void * restrict dst,
        shared const void * restrict src, 
        shared const int * restrict perm,
        size_t nbytes, upc_flag_t flags);
\end{verbatim}

{\bf Description} 

\np The {\tt upc\_all\_permute} function copies a block of memory from a
shared memory area that has affinity to the $i$th thread to a block of a
shared memory that has affinity to thread {\tt perm[i]}.
The number of bytes in each block is {\tt nbytes}.

\np {\tt nbytes} must be strictly greater than 0.

\np {\tt perm[0..THREADS-1]} must contain {\tt THREADS} distinct
values: {\tt 0, 1, ...,  THREADS-1}.

\np The {\tt upc\_all\_permute} function treats the {\tt src} pointer
and the {\tt dst} pointer as if each pointed to a shared memory
area of {\tt nbytes} bytes on each thread and therefore had type:

\begin{verbatim}
    shared [nbytes] char[nbytes * THREADS]
\end{verbatim}  

\np The targets of the {\tt src}, {\tt perm}, and
{\tt dst} pointers must have affinity to thread 0.

\np The {\tt src} and {\tt dst} pointers are treated as
if they have phase 0.

\np The effect is equivalent to copying the block of {\tt nbytes} bytes
that has affinity to thread {\tt i} pointed to by {\tt src}
to the block of {\tt nbytes} bytes
that has affinity to thread {\tt perm}[$i$] pointed to by {\tt dst}.

\np EXAMPLE 1 {\tt upc\_all\_permute}.
\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define NELEMS 10
  shared [NELEMS] int A[NELEMS*THREADS], B[NELEMS*THREADS];
  shared int P[THREADS];
  // Initialize A and P.
  upc_barrier;
  upc_all_permute( B, A, P, sizeof(int)*NELEMS,
                   UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

\subsubsection{Computational Operations}
\label{upc-op-t-section}
\index{upc\_op\_t}
\index{UPC\_ADD}
\index{UPC\_MULT}
\index{UPC\_AND}
\index{UPC\_OR}
\index{UPC\_XOR}
\index{UPC\_LOGAND}
\index{UPC\_LOGOR}
\index{UPC\_MIN}
\index{UPC\_MAX}
\index{UPC\_FUNC}
\index{UPC\_NONCOMM\_FUNC}

\npf
\label{upc-op-t-item}
A variable of type {\tt upc\_op\_t} can have the following values:
\begin{description}
\item[{\tt UPC\_ADD}]
Addition.
\item[{\tt UPC\_MULT}]
Multiplication.
\item[{\tt UPC\_AND}]
Bitwise {\tt AND} for integer and character variables.
Results are undefined for floating point numbers.
\item[{\tt UPC\_OR}]
Bitwise {\tt OR} for integer and character variables.
Results are undefined for floating point numbers.
\item[{\tt UPC\_XOR}]
Bitwise {\tt XOR} for integer and character variables.
Results are undefined for floating point numbers.
\item[{\tt UPC\_LOGAND}]
Logical {\tt AND} for all variable types.
\item[{\tt UPC\_LOGOR}]
Logical {\tt OR} for all variable types.
\item[{\tt UPC\_MIN}]
For all data types, find the minimum value.
\item[{\tt UPC\_MAX}]
For all data types, find the maximum value.
\item[{\tt UPC\_FUNC}]
Use the specified commutative function {\tt func} to operate
on the data in the {\tt src} array at each step.
\item[{\tt UPC\_NONCOMM\_FUNC}]
Use the specified non-commutative function {\tt func} to
operate on the data in the {\tt src} array at each step.
\end{description}

\np The operations represented by a variable of type {\tt upc\_op\_t}
(including user-provided operators) are assumed to be associative.
A reduction or a prefix reduction whose result is dependent on the
order of operator evaluation will have undefined results.\footnote{
Implementations are not obligated to prevent failures that
might arise because of a lack of associativity of built-in functions
due to floating-point roundoff or overflow.}

\np The operations represented by a variable of type {\tt upc\_op\_t}
(except those provided using {\tt UPC\_NONCOMM\_FUNC}) are assumed
to be commutative.  A reduction or a prefix reduction (using operators
other than {\tt UPC\_NONCOMM\_FUNC}) whose result is dependent on
the order of the operands will have undefined results.

{\bf Forward references:} reduction, prefix reduction (\ref{reduction}).

\paragraph{The {\tt upc\_all\_reduce} and {\tt upc\_all\_prefix\_reduce} functions}\ \\
\label{reduction}

{\bf Synopsis} 
\index{upc\_all\_reduce}
\index{upc\_all\_reduce\_prefix}
\index{reduction}
\index{prefix reduction}

\npf 
\begin{verbatim}
#include <upc.h>
#include <upc_collective.h>
void upc_all_reduce_<<T>>(
        shared void * restrict dst,
        void shared const void * restrict src,
	upc_op_t op,
	size_t nelems,
        void size_t blk_size,
	<<TYPE>>(*func)(<<TYPE>>, <<TYPE>>),
        void upc_flag_t flags);
void upc_all_prefix_reduce<<T>>(
        shared void * restrict dst,
        void  shared const void * restrict src,
	upc_op_t op,
	size_t nelems,
        void size_t blk_size,
	<<TYPE>>(*func)(<<TYPE>>, <<TYPE>>),
        void upc_flag_t flags);
\end{verbatim}
        
{\bf Description} 

\np The function prototypes above represents the 22 variations of the
  {\tt upc\_all\_reduce{\em T}} and {\tt upc\_all\_prefix\_reduce{\em T}} 
  functions where {\tt {\em T}} and {\tt {\em TYPE}} have the following 
correspondences: \footnote{For example, if {\tt {\em T}} is {\tt C}, then 
{\tt {\em TYPE}} must be {\tt signed char}.}
\begin{center}
\begin{tabular}{ll|ll}
{\tt {\em T}} & {\tt {\em TYPE}} \hspace*{1.5in} &
{\tt {\em T}} & {\tt {\em TYPE}} \\ \hline
{\tt C} & {\tt signed char} &
{\tt L} & {\tt signed long} \\
{\tt UC} & {\tt unsigned char} &
{\tt UL} & {\tt unsigned long} \\
{\tt S} & {\tt signed short} &
{\tt F} & {\tt float} \\
{\tt US} & {\tt unsigned short} &
{\tt D} & {\tt double} \\
{\tt I} & {\tt signed int} &
{\tt LD} & {\tt long double} \\
{\tt UI} & {\tt unsigned int} &
\end{tabular}
\end{center}

\np On completion of the {\tt upc\_all\_reduce} variants, 
the value of the {\tt {\em TYPE}} shared object
referenced by {\tt dst} is
{\tt src[0]} $\oplus$ {\tt src[1]} $\oplus \cdots \oplus$
{\tt src[nelems-1]}
where ``$\oplus$'' is the operator specified by the variable {\tt op}.

\np On completion of the {\tt upc\_all\_prefix\_reduce} variants, 
the value of the {\tt {\em TYPE}} shared object
referenced by {\tt dst[i]} is
{\tt src[0]} $\oplus$ {\tt src[1]}
$\oplus \cdots \oplus$ {\tt src[i]}
for $0 \leq$ {\tt i} $\leq$ {\tt nelems-1} and
where ``$\oplus$'' is the operator specified by the variable {\tt op}.

\np
If the value of {\tt blk\_size} passed to these functions is
greater than 0 then they treat the {\tt src} pointer
as if it pointed to a shared memory area of {\tt nelems} elements of
type {\tt {\em TYPE}} and blocking factor {\tt blk\_size}, and therefore
had type:

\begin{verbatim}
    shared [blk_size] TYPE [nelems]
\end{verbatim}

\np
If the value of {\tt blk\_size} passed to these functions is
0 then they treat the {\tt src} pointer
as if it pointed to a shared memory area of {\tt nelems} elements of
type {\tt {\em TYPE}} with an indefinite layout qualifier, and
therefore had
type\footnote{Note that {\tt upc\_blocksize(src) == 0} if
{\tt src} has this type, so the argument value 0 has a natural
connection to the block size of {\tt src}.}:

\begin{verbatim}
    shared []  TYPE[nelems]
\end{verbatim}

\np The phase of the {\tt src} pointer is respected when
referencing array elements, as specified above.

\np {\tt upc\_all\_prefix\_reduce{\em T}} treats the {\tt dst} pointer
    equivalently to the {\tt src} pointer as described in the past 3
    paragraphs.
    
\np {\tt upc\_all\_prefix\_reduce{\em T}} requires the affinity and
phase of the {\tt src} and {\tt dst} pointers to match -- ie. 
{\tt upc\_threadof(src) == upc\_threadof(dst) \&\& upc\_phaseof(src) == upc\_phaseof(dst)}.
\np {\tt upc\_all\_reduce{\em T}} treats the {\tt dst} pointer as having type:

\begin{verbatim}
    shared TYPE *
\end{verbatim}

\np EXAMPLE 1 {\tt upc\_all\_reduce} of type {\tt long UPC\_ADD}.
\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define BLK_SIZE 3
  #define NELEMS 10
  shared [BLK_SIZE] long A[NELEMS*THREADS];
  shared long *B;
  long result;
  // Initialize A.  The result below is defined only on thread 0.
  upc_barrier;
  upc_all_reduceL( B, A, UPC_ADD, NELEMS*THREADS, BLK_SIZE,
                   NULL, UPC_IN_NOSYNC | UPC_OUT_NOSYNC );
  upc_barrier;
\end{verbatim}

%\paragraph{The {\tt upc\_all\_prefix\_reduce} function}\ \\
%\label{prefix-reduction}
%
% {\bf Synopsis} 
%
%1\hspace{1em}   {\tt \#include <upc.h>}\\
%        {\tt \#include <upc\_collective.h>}\\
%        {\tt void {upc\_all\_prefix\_reduce}{\em T}(restrict shared void *dst, \\
%         \phantom{void {upc\_all\_prefix\_reduce}{\em T}(}restrict shared const void *src,\\
%\phantom{void {upc\_all\_prefix\_reduce}{\em T}(}upc\_op\_t op, size\_t nelems, size\_t blk\_size,\\
%\phantom{void {upc\_all\_prefix\_reduce}{\em T}(}{\em TYPE} (*func)({\em TYPE}, {\em TYPE}), \\
%\phantom{void {upc\_all\_prefix\_reduce}{\em T}(}upc\_flag\_t flags);} \\
%
% {\bf Description} 
%
%1\hspace{1em} The function prototype above represents the 11 variations of the
%{\tt upc\_all\_reduce{\em T}} function where {\tt {\em T}} and {\tt {\em TYPE}} have the
%following correspondences:
%
%\begin{center}
%\begin{tabular}{ll|ll}
%{\tt {\em T}} & {\tt {\em TYPE}} \hspace*{1.5in} &
%{\tt {\em T}} & {\tt {\em TYPE}} \\ \hline
%{\tt C} & {\tt signed char} &
%{\tt L} & {\tt signed long} \\
%{\tt UC} & {\tt unsigned char} &
%{\tt UL} & {\tt unsigned long} \\
%{\tt S} & {\tt signed short} &
%{\tt F} & {\tt float} \\
%{\tt US} & {\tt unsigned short} &
%{\tt D} & {\tt double} \\
%{\tt I} & {\tt signed int} &
%{\tt LD} & {\tt long double} \\
%{\tt UI} & {\tt unsigned int} &
%\end{tabular}
%\end{center}
%
%2\hspace{1em} For example, if {\tt {\em T}} is {\tt C}, then {\tt {\em TYPE}} must be {\tt signed char}.
%
%3\hspace{1em}
%\label{prefix-reduce-blksize-gt-0}
%If the value of {\tt blk\_size} passed to {\tt upc\_all\_prefix\_reduce{\em T}} is
%greater than 0 then
%{\tt upc\_all\_prefix\_reduce{\em T}} treats the {\tt src} pointer and the
%{\tt dst} pointer
%as if each pointed to a shared memory area of {\tt nelems} elements of
%type {\tt {\em TYPE}} and blocking factor {\tt blk\_size}, and therefore
%had type:
%
%\begin{verbatim}
%    shared [blk_size}] TYPE[nelems]
%\end{verbatim}
%
%4\hspace{1em}
%\label{prefix-reduce-blksize-0}
%If the value of {\tt blk\_size} passed to {\tt upc\_all\_prefix\_reduce{\em T}} is
%0 then \\
%{\tt upc\_all\_prefix\_reduce{\em T}} treats the {\tt src} pointer and the
%{\tt dst} pointer
%as if each pointed to a shared memory area of {\tt nelems} elements of
%type {\tt {\em TYPE}} with an indefinite layout qualifier, and
%therefore had
%type\footnote{Note that {\tt upc\_blocksize(src) == 0} if
%{\tt src} has this type, so the argument value 0 has a natural
%connection to the block size of {\tt src}.}:
%
%\begin{verbatim}
%    shared [] TYPE [nelems]
%\end{verbatim}
%
%% 1\hspace{1em} The targets of the {\tt src} and {\tt dst} pointers
%% must have affinity to thread 0.
%
%5\hspace{1em} The phases of the {\tt src} and {\tt dst} pointers are
%respected when referencing array elements, as specified in items
%\ref{prefix-reduce-blksize-gt-0} and \ref{prefix-reduce-blksize-0} above.
%
%6\hspace{1em} At function exit
%{\tt dst[i]} = {\tt src[0]} $\oplus$ {\tt src[1]}
%$\oplus \cdots \oplus$ {\tt src[i]}
%for $0 \leq$ {\tt i} $\leq$ {\tt nelems-1} and
%where ``$\oplus$'' is the operator specified by the variable {\tt op}.
%
\np EXAMPLE 2 {\tt upc\_all\_prefix\_reduce} of type {\tt long UPC\_ADD}.

\begin{verbatim}
  #include <upc.h>
  #include <upc_collective.h>
  #define BLK_SIZE 3
  #define NELEMS 10
  shared [BLK_SIZE] long A[NELEMS*THREADS];
  shared [BLK_SIZE] long B[NELEMS*THREADS];
  // Initialize A.
  upc_all_prefix_reduceL( B, A, UPC_ADD, NELEMS*THREADS, BLK_SIZE,
                          NULL, UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC );
\end{verbatim}

\pagebreak
\appendix
\section{Proposed Additions and Extensions}
\index{proposed extensions}

\np This section contains proposed additions and extensions to the UPC
     specification.  Such proposals are included when stable enough for
     developers to implement and for users to study and experiment with them.
     However, their presence does not suggest long term support.  When fully
     stable and tested, they will be moved to the main body of the specification.

\np This section also describes the process used to add new items to the 
    specification, which starts with inclusion in this section.  Requirements
    for inclusion are:\footnote{These requirements ensure that most of the
    semantic issues that arise during initial implementation have been addressed
    and prevents the accumulation of interfaces that no one commits to
    implement. Nothing prevents the circulation of more informal {\em what if} 
    interface proposals from circulating in the community before an extension
    reaches this point.} 

\begin{enumerate}
\item A documented API which shall use the format and conventions of
    this specification and [ISO/IEC00].

\item Either a complete, publicly available, implementation of the API
    or a set of publicly available example programs which demonstrate
    the interface.
    
\item The concurrence of the UPC consortium that its inclusion would be
    in the best interest of the language.    
\end{enumerate}

\np If all implementations drop support for an extension and/or all interested parties
    no longer believe the extension is worth pursuing, then it may simply be dropped.
    Otherwise, the requirements for inclusion of an extension in the main body of the
    specification are:

\begin{enumerate}
\item Six months residence in this section.

\item The existence of either one (or more) publicly available "reference" implementation 
written in standard UPC OR at least two independent implementations (possibly specific 
to a given UPC implementation).

\item The existence of a significant base of experimental user experience
   which demonstrates positive results with a substantial portion of the
   proposed API.

\item The concurrence of the UPC consortium that its inclusion would be
    in the best interest of the language.
\end{enumerate}

\index{feature macros}
\np For each extension, there shall be a predefined {\em feature macro}
   beginning with {\tt \_\_UPC} which will be defined by an implementation
   to be the interface version of the extension if it is supported, otherwise
   undefined.

\pagebreak
\subsection{UPC Parallel I/O \texttt{<}upc\_io.h\texttt{>}}
\index{\_\_UPC\_IO\_\_}
\index{upc\_io.h}

\npf This subsection provides the UPC parallel extensions of [ISO/IEC00 
    Sec 7.19].  All the characteristics of library functions described
    in [ISO/IEC00 Sec 7.1.4] apply to these as well.  Implementations
    that support this interface shall predefine the feature macro {\tt
    \_\_UPC\_IO\_\_} to the value 1.

{\bf Common Constraints}

\index{upc\_flag\_t}
\np All UPC-IO functions are collective and must be called by all threads collectively.\footnote{Note that 
collective does not necessarily imply barrier synchronization.  The synchronization behavior of the 
UPC-IO data movement library functions is explicitly controlled by using the {\tt
flags} flag argument. See Section \ref{upc-flag-t} for details.}

\np If a program calls {\tt exit}, {\tt upc\_global\_exit}, or returns from {\tt main} with a
UPC file still open, the file will automatically be closed at program
termination, and the effect will be equivalent to {\tt upc\_all\_fclose} being
implicitly called on the file.

\index{end of file}
\np If a program attempts to read past the end of a file, the read function
will read data up to the end of file and return the number of bytes actually
read, which may be less than the amount requested.

\np Writing past the end of a file increases the file size.

\np If a program seeks to a location past the end of a file and writes
starting from that location, the data in the intermediate (unwritten)
portion of the file is undefined. For example, if a program opens a new file
(of size 0 bytes), seeks to offset 1024 and writes some data beginning from
that offset, the data at offsets 0--1023 is undefined. Seeking past the end
of file and performing a write causes the current file size to immediately
be extended up to the end of the write. However, just seeking past the end
of file or attempting to read past the end of file, without a write, does
not extend the file size.

\np All generic pointers-to-shared passed to the I/O functions (as function
arguments or indirectly through the list I/O arguments) are treated as if
they had a phase field of zero (that is, the input phase is ignored).

\np All UPC-IO read/write functions take an argument {\tt flags}
    of type {\tt upc\_flag\_t}. The semantics of this argument is
    defined in Section \ref{upc-flag-t}. These semantics apply only to
    memory locations in user-provided buffers, not to the read/write
    operations on the storage medium or any buffer memory internal to
    the library implementation.


\np The {\tt flags} flag is included even on the fread/fwrite\_local functions
(which take a pointer-to-local as the buffer argument) in order to provide
well-defined semantics for the case where one or more of the pointer-to-local
arguments references a shared object (with local affinity). In the case where
all of the pointer-to-local arguments in a given call reference only private
objects, the {\tt flags} flag provides no useful additional guarantees and is
recommended to be passed as {\tt UPC\_IN\_NOSYNC|UPC\_OUT\_NOSYNC} to maximize performance.

\np The arguments to all UPC-IO functions are single-valued except where 
    explicitly noted in the function description.

\index{file consistency}
\index{file atomicity}
\np UPC-IO, by default, supports weak consistency and atomicity semantics. The
default (weak) semantics are as follows. The data written to a file by a thread is
only guaranteed to be visible to another thread after all threads have
collectively closed or synchronized the file.

\np Writes to a file from a given thread are always guaranteed to be visible to
subsequent file reads by the \textit{same} thread, even without an intervening
call to collectively close or synchronize the file.

\np Byte-level data consistency is supported.

\np If concurrent writes from multiple threads overlap in the file, the
resulting data in the overlapping region is undefined with the weak
consistency and atomicity semantics

\np When reading data being concurrently written by another thread, the data
that gets read is undefined with the weak consistency and atomicity
semantics.

\np File reads into overlapping locations in a shared buffer in memory using individual file
pointers or list I/O functions leads to undefined data in the target buffer under the
weak consistency and atomicity semantics.

\np A given file must not be opened at same time by the POSIX I/O
and UPC-IO libraries.

\np Except where otherwise noted, all UPC-IO functions return
NON-single-valued errors; that is, the occurrence of an error need only be
reported to at least one thread, and the {\tt errno} value reported to each such
thread may differ. When an error is reported to ANY thread, the position of
ALL file pointers for the relevant file handle becomes undefined.

\np The error values that UPC-IO functions may set in {\tt errno} are
implementation-defined, however the {\tt perror()} and {\tt strerror()} functions are still
guaranteed to work properly with {\tt errno} values generated by UPC-IO.

\np UPC-IO functions can not be called between {\tt upc\_notify} and corresponding {\tt upc\_wait} statements.

\subsubsection{Background}

\paragraph{File Accessing and File Pointers}\ \\

%\begin{figure}[h]
%\includegraphics[bb=0 0 620 339, width=1\textwidth]{figure1.eps}
%\includegraphics[width=1\textwidth]{figure1}
%\caption{UPC-IO File Access Methods}
%\end{figure}

\index{file pointer}
\index{common file pointer}
\index{individual file pointer}

\npf Collective UPC-IO accesses can be done in and out of shared and private
buffers, thus local and shared reads and writes are generally supported.
In each of these cases, file pointers could be either common or individual.
Note that in UPC-IO, common file pointers cannot be used in conjunction with
pointer-to-local buffers. 
File pointer modes are specified by passing a flag to the collective
{\tt upc\_all\_fopen} function and can be changed using {\tt upc\_all\_fcntl}.
When a file is opened with the common file pointer flag, all threads share a
common file pointer. When a file is opened with the individual file pointer
flag, each thread gets its own file pointer.

\np UPC-IO also provides file-pointer-independent list file accesses by specifying
explicit offsets and sizes of data that is to be accessed. List IO can also
be used with either pointer-to-local buffers or pointer-to-shared buffers.

\np Examples 1-3 and their associated figures, Figures 2-4, give typical
instances of UPC-IO usage. Error checking is omitted for brevity.

\np EXAMPLE 1: collective read operation using individual file pointers
\begin{verbatim}
#include <upc.h>
#include <upc_io.h>
double buffer[10];  // and assuming a total of 4 THREADS
upc_file_t *fd; 

fd = upc_all_fopen( "file", UPC_RDONLY | UPC_INDIVIDUAL_FP, 0, NULL );
upc_all_fseek( fd, 5*MYTHREAD*sizeof(double), UPC_SEEK_SET );
upc_all_fread_local( fd, buffer, sizeof(double), 10, 
                          UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC);
upc_all_fclose(fd);
\end{verbatim}

%\begin{figure}[h]
%\includegraphics[bb=0 0 630 314, width=1\textwidth]{figure2.eps}
%\includegraphics[width=1\textwidth]{figure2}
%\caption{Collective read into private buffers can provide a canonical file-view}
%\end{figure}

 Each thread reads a block of data into a private buffer from a particular thread-specific offset.

\np EXAMPLE 2: a collective read operation using a common file pointer. 
The data read is stored into a shared buffer,
having a block size of 5 elements. The user selects the type of file pointer
at file-open time. The user can select either individual file pointers by
passing the flag {\tt UPC\_INDIVIDUAL\_FP} to the function {\tt upc\_all\_fopen}, or the
common file pointer by passing the flag {\tt UPC\_COMMON\_FP} to {\tt upc\_all\_fopen}.

\begin{verbatim}
#include <upc.h>
#include <upc_io.h>
shared [5] float buffer[20];  // and assuming a total of 4 static THREADS
upc_file_t *fd; 

fd = upc_all_fopen( "file", UPC_RDONLY | UPC_COMMON_FP, 0, NULL );
upc_all_fread_shared( fd, buffer, upc_blocksizeof(buffer), 
     upc_elemsizeof(buffer), 20, UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC);
/* or equivalently: 
 *  upc_all_fread_shared( fd, buffer, 5, sizeof(float), 20, 
                                 UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC); 
 */
\end{verbatim}
%\begin{figure}[h]
%\includegraphics[bb=0 0 604 146, width=1\textwidth]{figure3.eps}
%\includegraphics[width=1\textwidth]{figure3}
%\caption{Collective read into a blocked shared buffer can provide a partitioned file-view}
%\end{figure}

\paragraph{Synchronous and Asynchronous I/O}\ \\

\index{asynchronous I/O}
\npf I/O operations can be synchronous (blocking) or asynchronous (non-blocking).
While synchronous calls are quite simple and easy to use from a programming
point of view, asynchronous operations allow the overlapping of computation
and I/O to achieve improved performance. Synchronous calls block and wait
until the corresponding I/O operation is completed. On the other hand, an
asynchronous call starts an I/O operation and returns immediately. Thus, the
executing process can turn its attention to other processing needs while the
I/O is progressing.

\index{upc\_all\_ftest\_async}
\index{upc\_all\_fwait\_async}
\np UPC-IO supports both synchronous and asynchronous I/O functionality. The
asynchronous I/O functions have the same syntax and basic semantics as their synchronous
counterparts, with the addition of the {\tt async} suffix in their names. The
asynchronous I/O functions have the restriction that only one (collective)
asynchronous operation can be active at a time on a given file handle. That
is, an asynchronous I/O function must be completed by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async} before another asynchronous
I/O function can be called on the same file handle. This restriction is
similar to the restriction MPI-IO [MPI2] has on split-collective I/O functions:
only one split collective operation can be outstanding on an MPI-IO file
handle at any time.

\paragraph{Consistency and Atomicity Semantics}\ \\

\index{file consistency}
\index{file atomicity}
\npf The consistency semantics define when the data written
to a file by a thread is visible to other threads. The atomicity semantics
define the outcome of operations in which multiple threads write
concurrently to a file or shared buffer and some of the writes overlap each other. For
performance reasons, UPC-IO uses weak consistency and
atomicity semantics by default. The user can select stronger semantics either by
opening the file with the flag {\tt UPC\_STRONG\_CA} or by calling 
{\tt upc\_all\_fcntl} with the command 
{\tt UPC\_SET\_STRONG\_CA\_SEMANTICS}.

\index{upc\_all\_fsync}
\np The default (weak) semantics are as follows. The data written by a thread is
only guaranteed to be visible to another thread after all threads have
called {\tt upc\_all\_fclose} or {\tt upc\_all\_fsync}. (Note that the data \textit{%
may} be visible to other threads before the call to {\tt upc\_all\_fclose} or
{\tt upc\_all\_fsync} and that the data may become visible to different
threads at different times.) Writes from a given thread are always
guaranteed to be visible to subsequent reads by the \textit{same} thread,
even without an intervening call to {\tt upc\_all\_fclose} or {\tt upc\_all\_fsync}.
Byte-level data consistency is supported. So for example, if thread 0
writes one byte at offset 0 in the file and thread 1 writes one byte at
offset 1 in the file, the data from both threads will get written to the
file. If concurrent writes from multiple threads overlap in the file, the
resulting data in the overlapping region is undefined. Similarly, if one
thread tries to read the data being concurrently written by another thread,
the data that gets read is undefined. Concurrent in this context means any
two read/write operations to the same file handle with no intervening calls
to {\tt upc\_all\_fsync} or {\tt upc\_all\_fclose}.

\np For the functions that read into or write from a shared buffer using a
common file pointer, the weak consistency semantics are defined as follows.
Each call to {\tt upc\_all\_\{fread,fwrite\}\_shared[\_async]} with a common file
pointer behaves as if the read/write operations were performed by a single,
distinct, anonymous thread which is different from any compute thread (and
different for each operation). In other words, NO file reads are guaranteed to
see the results of file writes using the common file pointer until after a close
or sync under the default weak consistency semantics.

\index{UPC\_STRONG\_CA}
\index{UPC\_SET\_STRONG\_CA\_SEMANTICS}
\np By passing the {\tt UPC\_STRONG\_CA} flag to {\tt upc\_all\_fopen} or 
by calling {\tt upc\_all\_fcntl} with the command 
{\tt UPC\_SET\_STRONG\_CA\_SEMANTICS}, the user selects strong
consistency and atomicity semantics. In this case, the data written by a
thread is visible to other threads as soon as the file write on the calling
thread returns. In the case of writes from multiple threads to overlapping
regions in the file, the result would be as if the individual write function
from each thread occurred atomically in some (unspecified) order.
Overlapping writes to a file in a single (list I/O) write function on a
single thread are not permitted (see Section \ref{io-func-list}). While strong consistency
and atomicity semantics are selected on a given file handle, the {\tt
flags} argument to all fread/fwrite functions on that handle is ignored
and always treated as {\tt UPC\_IN\_ALLSYNC | UPC\_OUT\_ALLSYNC}.

\np The consistency semantics also define the outcome in the case of overlapping
reads into a shared buffer in memory when using individual file pointers or
list I/O functions. By default, the data in the overlapping space is
undefined. If the user selects strong consistency and atomicity, the result would be as
if the individual read functions from each thread occurred atomically in
some (unspecified) order. Overlapping reads into memory buffers in a single
(list I/O) read function on a single thread are not permitted (see Section
\ref{io-func-list}).

\np Note that in strong consistency and atomicity mode, atomicity is guaranteed at the UPC-IO function
level. The entire operation specified by a single function is performed
atomically, regardless of whether it represents a single, contiguous
read/write or multiple noncontiguous reads or writes as in a list I/O
function.

\np EXAMPLE 1:  three threads write data to a file
concurrently, each with a single list I/O function. The numbers indicate
file offsets and brackets indicate the boundaries of a listed vector. Each
thread writes its own thread id as the data values:

\begin{verbatim}
thread 0:    {1  2  3}   {5  6  7  8}
thread 1: {0  1  2}{3  4  5}
thread 2:             {4  5  6}   {8  9 10 11}
\end{verbatim}

\np With the default weak semantics, the results in the overlapping locations
are undefined. Therefore, the result in the file would be the following,
where x represents undefined data.

\begin{verbatim}
File:     1  x   x  x  x  x  x  0  x  2  2  2
\end{verbatim}
\np That is, the data from thread 1 is written at location 0, the data from
thread 0 is written at location 7, and the data from thread 2 is written at
locations 9, 10, and 11, because none of these locations had overlapping
writes. All other locations had overlapping writes, and consequently, the
result at those locations is undefined.

\np If the file were opened with the {\tt UPC\_STRONG\_CA} flag, strong
consistency and atomicity semantics would be
in effect. The result, then, would depend on the order in which the writes
from the three threads actually occurred. Since six different orderings are
possible, there can be six outcomes. Let us assume, for example, that the
ordering was the write from thread 0, followed by the write from thread 2,
and then the write from thread 1. The (list I/O) write from each thread
happens atomically. Therefore, for this ordering, the result would be:

\begin{verbatim}
File:     1  1  1  1  1  1  2  0  2  2  2  2
\end{verbatim}

\np We note that if instead of using a single list I/O function each thread used
a separate function to write each contiguous portion, there would be six
write functions, two from each thread, and the atomicity would be at the
granularity of the write operation specified by each of those functions.

\paragraph{File Interoperability}\ \\

\index{file interoperability}
\npf UPC-IO does not specify how an implementation may store the data in a file
on the storage device. Accordingly, it is implementation-defined whether or not 
a file created by UPC-IO can be directly accessed by using C/POSIX I/O functions.
However, the UPC-IO implementation must specify how
the user can retrieve the file from the storage system as a linear sequence
of bytes and vice versa. Similarly, the implementation must specify how
familiar operations, such as the equivalent of POSIX {\tt ls}, {\tt cp}, {\tt rm}, and {\tt mv} can
be performed on the file.

\subsubsection{Predefined Types}

\index{upc\_off\_t}
\npf The following types are defined in {\tt <upc\_io.h>}

\np {\tt upc\_off\_t} is a signed integral type that is capable of representing the size of the largest
file supported by the implementation.

\index{upc\_file\_t}
\np {\tt upc\_file\_t} is an opaque shared data type of incomplete type (as defined in [ISO/IEC00 Sec 6.2.5]) that represents an open file handle.

\np {\tt upc\_file\_t} objects are always manipulated via a pointer (that is,
{\tt upc\_file\_t *}).

\np {\tt upc\_file\_t} is a shared data type. It is allowed to pass a ({\tt upc\_file\_t
*}) across threads, and two pointers to {\tt upc\_file\_t} that reference the same
logical file handle will always compare equal.

{\bf Advice to implementors}

\np The definition of {\tt upc\_file\_t} does not restrict the implementation to
store all its metadata with affinity to one thread. Each thread can still
have local access to its metadata. For example, below is a simple approach
an implementation could use:

\begin{verbatim}
#include <upc.h>
#include <upc_io.h>
/* for a POSIX-based implementation */
typedef int my_internal_filehandle_t; 

#ifdef _UPC_INTERNAL
  typedef struct _local_upc_file_t  {
    my_internal_filehandle_t fd;
    ... other metadata ...
  } local_upc_file_t;
#else
  struct _local_upc_file_t;
#endif

typedef shared struct _local_upc_file_t upc_file_t;

upc_file_t *upc_all_fopen(...) {

   upc_file_t *handles = 
            upc_all_alloc(THREADS, sizeof(upc_file_t));

   /* get my handle */
   upc_file_t *myhandle = &(handles[MYTHREAD]); 
   
   /* cast to a pointer-to-local */
   local_upc_file_t* mylocalhandle = (local_upc_file_t*)myhandle;

   /* setup my metadata using pointer-to-local */
   mylocalhandle->fd = open(...);

   ...

   return handles;
}
\end{verbatim}

\np The basic idea is that the ``handle'' exposed to the user actually points to
a cyclic, distributed array. As a result, each thread has easy, local access
to its own internal handle metadata with no communication, while maintaining
the property that the handle that UPC-IO exposes to the client is a
single-valued pointer-to-shared. An additional advantage is that a thread
can directly access the metadata for other threads, which may occasionally
be desirable in the implementation.

\subsubsection{UPC File Operations}

{\bf Common Constraints}
\label{upc-io-common}

\index{file pointer}
\index{common file pointer}
\index{individual file pointer}
\npf When a file is opened with an individual file pointer, each thread will get
its own file pointer and advance through the file at its own pace.

\np When a common file pointer is used, all threads positioned in the file
will be aligned with that common file pointer.

\np Common file pointers cannot be used in conjunction with pointers-to-local 
(and hence cannot operate on private objects).

\np No function in this section may be called while an asynchronous
operation is pending on the file handle, except where otherwise noted.
% it is otherwise noted for upc_all_fcntl

\paragraph{The {\tt upc\_all\_fopen} function}\ \\
\label{io-func-open}

{\bf Synopsis}
\index{file open}
\index{upc\_all\_fopen}
\index{UPC\_RDONLY}
\index{UPC\_WRONLY}
\index{UPC\_RDWR}
\index{UPC\_COMMON\_FP}
\index{UPC\_INDIVIDUAL\_FP}
\index{UPC\_APPEND}
\index{UPC\_CREATE}
\index{UPC\_EXCL}
\index{UPC\_STRONG\_CA}
\index{UPC\_TRUNC}
\index{UPC\_DELETE\_ON\_CLOSE}

\npf\vspace{-2.5em}
 \begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_file_t *upc_all_fopen(const char *fname, int flags, 
         size_t numhints, struct upc_hint const *hints);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fopen} opens the file identified by the filename {\tt fname} for
input/output operations.

\np The flags parameter specifies the access mode. The valid flags and their
meanings are listed below. Of these flags, exactly one of {\tt UPC\_RDONLY},
{\tt UPC\_WRONLY}, or {\tt UPC\_RDWR}, and one of {\tt UPC\_COMMON\_FP} or {\tt UPC\_INDIVIDUAL\_FP},
must be used. Other flags are optional. Multiple flags can be combined by
using the bitwise OR operator ({\textbar}), and each flag has a unique
bitwise representation that can be unambiguously tested using the bitwise
AND operator(\&).
\begin{description}
\item{\tt UPC\_RDONLY}
Open the file in read-only mode
\item{\tt UPC\_WRONLY}
Open the file in write-only mode
\item{\tt UPC\_RDWR}
Open the file in read/write mode
\item{\tt UPC\_INDIVIDUAL\_FP}
Use an individual file pointer for all file accesses (other than 
list I/O)
\item{\tt UPC\_COMMON\_FP}
Use the common file pointer for all file accesses (other than 
list I/O)
\item{\tt UPC\_APPEND}
Set the \textit{initial} position of the file pointer to end of file. 
(The file pointer is not moved to the end of file after each 
read/write)
\item{\tt UPC\_CREATE}
Create the file if it does not already exist. If the named file does not exist and this flag is not passed, the function fails with an error.
\item{\tt UPC\_EXCL}
Must be used in conjunction with {\tt UPC\_CREATE}. The open will fail if the 
 file already exists.
\item{\tt UPC\_STRONG\_CA}
Set strong consistency and atomicity semantics
\item{\tt UPC\_TRUNC}
Open the file and truncate it to zero length.  The file must be opened before
writing.
\item{\tt UPC\_DELETE\_ON\_CLOSE} 
Delete the file automatically on close
\end{description}

\np The {\tt UPC\_COMMON\_FP} flag specifies that all accesses (except for the list
I/O operations) will use the common file pointer. The {\tt UPC\_INDIVIDUAL\_FP} flag
specifies that all accesses will use individual file pointers (except for the
list I/O operations). Either {\tt UPC\_COMMON\_FP} or {\tt UPC\_INDIVIDUAL\_FP} must be
specified or {\tt upc\_all\_fopen} will return an error.

\np The {\tt UPC\_STRONG\_CA} flag specifies strong consistency and atomicity semantics.
The data written by a thread is visible to other threads as soon as the
write on the calling thread returns. In the case of writes from multiple
threads to overlapping regions in the file, the result would be as if the
individual write function from each thread occurred atomically in some
(unspecified) order. In the case of overlapping reads into a shared buffer
in memory when using individual file pointers or list I/O functions, the result
would be as if the individual read functions from each thread occurred
atomically in some (unspecified) order.

\np If the flag {\tt UPC\_STRONG\_CA} is not specified, weak semantics are provided. The
data written by a thread is only guaranteed to be visible to another thread
after all threads have called {\tt upc\_all\_fclose} or {\tt upc\_all\_fsync}. (Note
that the data \textit{may} be visible to other threads before the call to
{\tt upc\_all\_fclose} or {\tt upc\_all\_fsync} and that the data may become visible
to different threads at different times.) Writes from a given thread are
always guaranteed to be visible to subsequent reads by the \textit{same}
thread, even without an intervening call to {\tt upc\_all\_fclose} or
{\tt upc\_all\_fsync}. Byte-level data consistency is supported. For the
purposes of atomicity and consistency semantics, each call to
{\tt upc\_all\_\{fread,fwrite\}\_shared[\_async]} with a common file pointer behaves
as if the read/write operations were performed by a single, distinct,
anonymous thread which is different from any compute thread (and different
for each operation).''\footnote{%
In other words, NO reads are guaranteed to see the results of writes using
the common file pointer until after a close or sync when {\tt UPC\_STRONG\_CA} is not
specified.}

\index{upc\_hint}
\index{file hints}
\np Hints can be passed to the UPC-IO library as an array of key-value pairs%
\footnote{%
The contents of the key/value pairs passed by all the threads must be single-valued.} 
of strings. {\tt numhints} specifies the number of hints in the {\tt hints}
array; if {\tt numhints} is zero, the {\tt hints} pointer is ignored. The user can free
the {\tt hints} array and associated character strings as soon as the open call returns.  The following type is defined in {\tt <upc\_io.h>}:

\begin{verbatim}
    struct upc_hint
\end{verbatim} 
holds each element of the {\tt hints} array and contain at least the following initial members, in this order.

\begin{verbatim}
    const char *key;
    const char *value;
\end{verbatim}

\np {\tt upc\_all\_fopen} defines a number hints.
An implementation is free to 
support additional hints. An implementation is free to ignore any hint
provided by the user. Implementations should \textit{silently} ignore any
hints they do not support or recognize. The predefined hints and their
meanings are defined below. An implementation is not required to interpret
these hint keys, but if it does interpret the hint key, it must provide
the functionality described.  All hints are single-valued character strings
(the content is single-valued, not the location).

\begin{description}
\item [{\tt access\_style}] (comma-separated list of strings): indicates the manner in
which the file is expected to be accessed. The hint value is a
comma-separated list of any the following: ``read\_once", ``write\_once",
``read\_mostly", ``write\_mostly", ``sequential", and ``random". Passing such a hint
does not place any constraints on how the file may actually be accessed by
the program, although accessing the file in a way that is different from the
specified hint may result in lower performance. 
\item [{\tt collective\_buffering}] (boolean): specifies whether the application may
benefit from collective buffering optimizations. Allowed values for this key
are ``true'' and ``false''. Collective buffering parameters can be further
directed via additional hints: cb\_buffer\_size, and cb\_nodes. 
\item [{\tt cb\_buffer\_size}] (decimal integer): specifies the total buffer space that the
implementation can use on each thread for collective buffering. 
\item [{\tt cb\_nodes}] (decimal integer): specifies the number of target threads or I/O nodes to
be used for collective buffering. 
\item [{\tt file\_perm}] (string): specifies the file permissions to use for file
creation. The set of allowed values for this key is implementation defined.

\item [{\tt io\_node\_list}] (comma separated list of strings): specifies the list of I/O
devices that should be used to store the file and is only relevant when the
file is created. 
\item [{\tt nb\_proc}] (decimal integer): specifies the number of threads that will typically be
used to run programs that access this file and is only relevant when the
file is created.
\item[{\tt striping\_factor}] (decimal integer): specifies the number of I/O devices that the
file should be striped across and is relevant only when the file is created.
\item[{\tt start\_io\_device}] (decimal integer): specifies the number of the first I/O device
from which to start striping the file and is relevant only when the file is
created.
\item[{\tt striping\_unit}] (decimal integer): specifies the striping unit to be used for the
file. The striping unit is the amount of consecutive data assigned to one
I/O device before progressing to the next device, when striping across a
number of devices. It is expressed in bytes. This hint is relevant only when
the file is created.
\end{description}

\np A file on the storage device is in the \textit{open} state from the
beginning of a successful open call to the end of the matching successful close call
on the file handle. It is
erroneous to have the same file \textit{open} simultaneously with two
{\tt upc\_all\_fopen} calls, or with a {\tt upc\_all\_fopen} call and a POSIX/C {\tt open} or
{\tt fopen} call.

\np The user is responsible for ensuring that the file referenced by the {\tt fname}
argument refers to a single UPC-IO file. The actual argument passed on each thread
may be different because the file name spaces may be different on different
threads, but they must all refer to the same logical UPC-IO file.

\np On success, the function returns a pointer to a file handle that can be
used to perform other operations on the file. 

\np {\tt upc\_all\_fopen} provides single-valued errors - if an error occurs, the
function returns {\tt NULL} on ALL threads, and sets {\tt errno} appropriately
to the same value on all threads.

\paragraph{The {\tt upc\_all\_fclose} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fclose}
\index{file close}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h> 
    #include <upc_io.h> 
    int upc_all_fclose (upc_file_t *fd); 
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fclose} executes an implicit {\tt upc\_all\_fsync} on {\tt fd} and then closes
the file associated with {\tt fd}.

\np The function returns 0 on success. If {\tt fd} is not valid or if an outstanding
asynchronous operation on {\tt fd} has not been completed, the function will return an error.

\np {\tt upc\_all\_fclose} provides single-valued errors - if an error occurs, the
function returns --1 on ALL threads, and sets {\tt errno} appropriately
to the same value on all threads. 

\np After a file has been closed with {\tt upc\_all\_fclose}, the file 
is allowed to be
opened and the data in it can be accessed by using regular C/POSIX I/O calls.

\paragraph{The {\tt upc\_all\_fsync} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fsync}
\index{file flush}

\npf\vspace{-2.5em}
 \begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    int upc_all_fsync(upc_file_t *fd);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fsync} ensures that any data that has been written to the
file associated with {\tt fd} but not yet transferred to the storage device is
transferred to the storage device. It also ensures that subsequent file
reads from any thread will see any previously written values (that have not
yet been overwritten).

\np There is an implied barrier immediately before {\tt upc\_all\_fsync} returns.

\np The function returns 0 on success. On error, it returns --1 and sets {\tt errno}
appropriately.

\paragraph{The {\tt upc\_all\_fseek} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fseek}
\index{file seek}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h> 
    upc_off_t upc_all_fseek(upc_file_t *fd, upc_off_t offset, 
         int origin);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fseek} sets the current position of the file pointer associated
with {\tt fd}.

\np This offset can be relative to the current position of the file pointer,
to the beginning of the file, or to the end of the file. The offset can be
negative, which allows seeking backwards.

\index{UPC\_SEEK\_SET}
\index{UPC\_SEEK\_CUR}
\index{UPC\_SEEK\_END}
\np The origin parameter can be specified as {\tt UPC\_SEEK\_SET}, {\tt UPC\_SEEK\_CUR},
or {\tt UPC\_SEEK\_END}, respectively, to indicate that the offset must be
computed from the beginning of the file, the current location of the file
pointer, or the end of the file.

\np In the case of a common file pointer, all threads must specify the same
offset and origin. In the case of an individual file pointer, each thread may
specify a different offset and origin.

\np It is allowed to seek past the end of file. It is erroneous to seek to a
negative position in the file. See the Common Constraints number 5 at the
beginning of Section \ref{upc-io-common} for more details.

\np The current position of the file pointer can be determined by calling
{\tt upc\_all\_fseek(fd, 0, UPC\_SEEK\_CUR)}.

\np On success, the function returns the current location of the file pointer
in bytes. If there is an error, it returns --1 and sets {\tt errno} appropriately.

\paragraph{The {\tt upc\_all\_fset\_size} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fset\_size}
\index{file size}
\index{end of file}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    int upc_all_fset_size(upc_file_t *fd, upc_off_t size);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fset\_size} executes an implicit {\tt upc\_all\_fsync} on {\tt fd} and
resizes the file associated with {\tt fd}. The file handle must be open for writing.

\np {\tt size} is measured in bytes from the beginning of the file.

\np If {\tt size} is less than the current file size, the file is truncated at the
position defined by {\tt size}. The implementation is free to deallocate file
blocks located beyond this position.

\np If {\tt size} is greater than the current file size, the file size increases to
{\tt size}. Regions of the file that have been previously written are unaffected.
The values of data in the new regions in the file (between the old size and
size) are undefined.

\np If this function truncates a file, it is possible that the individual and
common file pointers may point beyond the end of file. This is allowed and is
equivalent to seeking past the end of file (see the Common Constraints in Section
\ref{upc-io-common} for the semantics of seeking past the end of file).

\np It is unspecified whether and under what conditions this function 
actually allocates file space on the storage device.
Use {\tt upc\_all\_fpreallocate} to force file space to be reserved on the storage device.

\np Calling this function does not affect the individual or common file pointers.

\np The function returns 0 on success. On error, it returns --1 and sets {\tt errno}
appropriately.

\paragraph{The {\tt upc\_all\_fget\_size} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fget\_size}
\index{file size}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fget_size(upc_file_t *fd);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fget\_size} returns the current size in bytes of the file
associated with {\tt fd} on success. On error, it returns --1 and sets {\tt errno}
appropriately.

\paragraph{The {\tt upc\_all\_fpreallocate} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fpreallocate}
\index{file size}

\npf\vspace{-2.5em}
 \begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    int upc_all_fpreallocate(upc_file_t *fd, upc_off_t size);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fpreallocate} ensures that storage space is allocated for the
first {\tt size} bytes of the file associated with {\tt fd}. The file handle must be open for
writing.

\np Regions of the file that have previously been written are unaffected. For
newly allocated regions of the file, {\tt upc\_all\_fpreallocate} has the
same effect as writing undefined data.

\np If {\tt size} is greater than the current file size, the file size increases to
{\tt size}. If {\tt size} is less than or equal to the current file size, the file size
is unchanged.

\np Calling this function does not affect the individual or common file pointers.

\np The function returns 0 on success. On error, it returns --1 and sets {\tt errno}
appropriately.

\paragraph{The {\tt upc\_all\_fcntl} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fcntl}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    int upc_all_fcntl(upc_file_t *fd,  int cmd, void *arg);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fcntl} performs one of various miscellaneous operations related
to the file specified by {\tt fd}, as determined by {\tt cmd}. The valid commands {\tt cmd}
and their associated argument {\tt arg} are explained below.

\index{UPC\_GET\_CA\_SEMANTICS}
\begin{description}
\item{\tt UPC\_GET\_CA\_SEMANTICS}
Get the current consistency and atomicity semantics for {\tt fd}. The 
argument {\tt arg} is ignored.
The return value is {\tt UPC\_STRONG\_CA} for strong consistency and atomicity 
semantics and 0 for the default weak consistency and atomicity semantics.
\index{UPC\_SET\_WEAK\_CA\_SEMANTICS}
\item{\tt UPC\_SET\_WEAK\_CA\_SEMANTICS}
Executes an implicit {\tt upc\_all\_fsync} on {\tt fd} and sets {\tt fd} to use the weak 
consistency and atomicity semantics (or leaves the mode unchanged if that mode is already selected).
The argument {\tt arg} is ignored.
The return value is 0 on success. On error, this function returns 
-1 and sets {\tt errno} appropriately.
\index{UPC\_SET\_STRONG\_CA\_SEMANTICS}
\item{\tt UPC\_SET\_STRONG\_CA\_SEMANTICS}
Executes an implicit {\tt upc\_all\_fsync} on {\tt fd} and sets {\tt fd} to use the strong 
consistency and atomicity semantics (or leaves the mode unchanged if that mode is already selected).
The argument {\tt arg} is ignored.
The return value is 0 on success. On error, this function returns 
-1 and sets {\tt errno} appropriately.
\index{file pointer}
\index{common file pointer}
\index{individual file pointer}
\index{UPC\_GET\_FP}
\item{\tt UPC\_GET\_FP}
Get the type of the current file pointer for {\tt fd}.
The argument {\tt arg} is ignored.
The return value is either {\tt UPC\_COMMON\_FP} in case of a common 
file pointer, or {\tt UPC\_INDIVIDUAL\_FP} for individual file pointers.
\index{UPC\_SET\_COMMON\_FP}
\item{\tt UPC\_SET\_COMMON\_FP}
Executes an implicit {\tt upc\_all\_fsync} on {\tt fd}, sets the current file
access pointer mechanism for {\tt fd} to a common file pointer (or leaves it
unchanged if that mode is already selected), and seeks 
to the beginning of the file.
The argument {\tt arg} is ignored.
The return value is 0 on success. On error, this function returns 
-1 and sets {\tt errno} appropriately.
\index{UPC\_SET\_INDIVIDUAL\_FP}
\item{\tt UPC\_SET\_INDIVIDUAL\_FP} 
Executes an implicit {\tt upc\_all\_fsync} on {\tt fd}, sets the current 
file access pointer mechanism for {\tt fd} to an individual file pointer (or
leaves the mode unchanged if that mode is already selected), and seeks to the
beginning of the file.
The argument {\tt arg} is ignored.
The return value is 0 on success. On error, this function returns 
-1 and sets {\tt errno} appropriately.
\index{UPC\_GET\_FL}
\item{\tt UPC\_GET\_FL}
Get all the flags specified during the {\tt upc\_all\_fopen} call for {\tt fd},
as modified by any subsequent mode changes using the {\tt upc\_all\_fcntl(UPC\_SET\_*)} commands. 
The argument {\tt arg} is ignored.
The return value has same format as the {\tt flags} parameter in {\tt upc\_all\_fopen}.
\index{UPC\_GET\_FN}
\item{\tt UPC\_GET\_FN}
Get the file name provided by each thread in the {\tt upc\_all\_fopen} 
call that created {\tt fd}.
The argument {\tt arg} is a valid ({\tt const char**}) pointing to a ({\tt const char*}) location 
in which a pointer to file name will be written.
Writes a ({\tt const char*}) into {\tt *arg} pointing to the filename in implementation-maintained 
read-only memory, which will remain valid until the file handle 
is closed or until the next {\tt upc\_all\_fcntl} call on that file 
handle.
\index{upc\_hint}
\index{file hints}
\index{UPC\_GET\_HINTS}
\item{\tt UPC\_GET\_HINTS}
Retrieve the hints applicable to {\tt fd}.
The argument {\tt arg} is a valid ({\tt const upc\_hint\_t**}) pointing to a ({\tt const upc\_hint\_t*}) 
location in which a pointer to the hints array will be written.
Writes a ({\tt const upc\_hint\_t*}) into {\tt *arg} pointing to an array of {\tt upc\_hint\_t}'s 
in implementation-maintained read-only memory, which will remain 
valid until the file handle is closed or until the next {\tt upc\_all\_fnctl} 
call on that file handle. The number of hints in the array is 
returned by the call.
The hints in the array may be a subset of those specified at 
file open time, if the implementation ignored some unrecognized 
or unsupported hints.
\index{UPC\_SET\_HINT}
\item{\tt UPC\_SET\_HINT}
Executes an implicit {\tt upc\_all\_fsync} on {\tt fd} and sets a new 
hint to {\tt fd}.
The argument {\tt arg} points to one single-valued {\tt upc\_hint\_t} hint 
to be applied. If the given hint key has already been applied to {\tt fd}, 
the current value for that hint is replaced with the provided value.
The return value is 0 on success. On error, this function returns 
-1 and sets {\tt errno} appropriately.
\item
\index{asynchronous I/O}
\index{UPC\_ASYNC\_OUTSTANDING} 
{\tt UPC\_ASYNC\_OUTSTANDING} 
Returns 1 if there is an asynchronous operation outstanding 
on {\tt fd}, or 0 otherwise.
\end{description}

\index{file consistency}
\index{file atomicity}

\np In case of a non valid {\tt fd}, {\tt upc\_all\_fcntl} returns -1 and sets {\tt errno}
appropriately.

\np It \emph{is} allowed to call {\tt upc\_all\_fcntl(UPC\_ASYNC\_OUTSTANDING)} when an
asynchronous operation is outstanding (but it is still disallowed to call
{\tt upc\_all\_fcntl} with any other argument when an asynchronous operation is
outstanding).

\subsubsection{Reading Data}
\label{io-func-read}
\index{file reading}
{\bf Common Constraints}

\npf No function in this section \ref{io-func-read} may be called while an asynchronous
operation is pending on the file handle.

\paragraph{The {\tt upc\_all\_fread\_local} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_local}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fread_local(upc_file_t *fd, void *buffer, 
         size_t size, size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_local} reads data from a file into a local buffer on
each thread\textit{.}

\np This function can be called only if the current file pointer type is an
individual file pointer, and the file handle is open for reading. 

\np {\tt buffer} is a pointer to an array into which data will be read, and each
thread may pass a different value for {\tt buffer}.

\np Each thread reads {\tt (size*nmemb)} bytes of data from the
file at the position indicated by its individual file pointer into the buffer.
Each thread may pass a different value for {\tt size} and {\tt nmemb}. If {\tt
size} or {\tt nmemb} is zero, the {\tt buffer} argument is ignored and that
thread performs no I/O.

\np On success, the function returns the number of bytes read into the local 
buffer of the calling thread, and the individual file pointer of the thread is
incremented by that amount. On error, it returns --1 and sets {\tt errno}
appropriately.

\paragraph{The {\tt upc\_all\_fread\_shared} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_shared}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fread_shared(upc_file_t *fd, 
         shared void *buffer, size_t blocksize, size_t size,
         size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_shared} reads data from a file into a shared buffer in
memory\textit{.}

\np The function can be called when the current file pointer type is either a
common file pointer or an individual file pointer. The file handle must be open
for reading. 

\np {\tt buffer} is a pointer to an array into which data will be read. It must be a
pointer to shared data and may have affinity to any thread. {\tt blocksize} is the
block size of the shared buffer in elements (of {\tt size} bytes each). A {\tt
blocksize} of 0 indicates an indefinite blocking factor.

\np In the case of individual file pointers, the following rules apply: Each
thread may pass a different address for the {\tt buffer} parameter. 
Each thread reads {\tt (size*nmemb)} bytes of data from the
file at the position indicated by its individual file pointer into its buffer.
Each thread may pass a different value for {\tt blocksize}, {\tt size} and {\tt
nmemb}. If {\tt size} or {\tt nmemb} is zero, the {\tt buffer} argument is
ignored and that thread performs no I/O.  On success, the function returns the
number of bytes read by the calling thread, and the individual file pointer of
the thread is incremented by that amount.

\np In the case of a common file pointer, the following rules apply: All
threads must pass the same address for the {\tt buffer} parameter, and the 
same value for {\tt blocksize}, {\tt size} and {\tt nmemb}. The effect is that
{\tt (size*nmemb)} bytes of data are read from the file at the position
indicated by the common file pointer into the buffer.  If {\tt size} or {\tt
nmemb} is zero, the {\tt buffer} argument is ignored and the operation has no
effect.  On success, the function returns the total number of bytes read by all threads,
and the common file pointer is incremented by that amount.

\np If reading with individual file pointers results in overlapping reads into the
shared buffer, the result is determined by whether the file was opened with
the {\tt UPC\_STRONG\_CA} flag or not (see Section \ref{io-func-open}).

\np The function returns --1 on error and sets {\tt errno} appropriately.

\subsubsection{Writing Data}
\label{io-func-write}
\index{file writing}
{\bf Common Constraints}

\npf No function in this section \ref{io-func-write} may be called while an asynchronous
operation is pending on the file handle.

\paragraph{The {\tt upc\_all\_fwrite\_local} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_local}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fwrite_local(upc_file_t *fd, void *buffer,
         size_t size, size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_local} writes data from a local buffer on each thread
into a file\textit{.}

\np This function can be called only if the current file pointer type is an
individual file pointer, and the file handle is open for writing. 

\np {\tt buffer} is a pointer to an array from which data will be written, and each
thread may pass a different value for {\tt buffer}.

\np Each thread writes {\tt (size*nmemb)} bytes of data from the
buffer to the file at the position indicated by its individual file pointer.
Each thread may pass a different value for {\tt size} and {\tt nmemb}. If {\tt
size} or {\tt nmemb} is zero, the {\tt buffer} argument is ignored and that
thread performs no I/O. 

\np If any of the writes result in overlapping accesses in the file, the
result is determined by the current consistency and atomicity semantics mode in
effect for {\tt fd} (see \ref{io-func-open}).

\np On success, the function returns the number of bytes written by the
calling thread, and the individual file pointer of the thread is incremented by
that amount. On error, it returns --1 and sets {\tt errno} appropriately.

\paragraph{The {\tt upc\_all\_fwrite\_shared} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_shared}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fwrite_shared(upc_file_t *fd, 
         shared void *buffer, size_t blocksize,  size_t size,
         size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_shared} writes data from a shared buffer in memory to a
file.

\np The function can be called if the current file pointer type is either a
common file pointer or an individual file pointer. The file handle must be open
for writing. 

\np {\tt buffer} is a pointer to an array from which data will be written. It must
be a pointer to shared data and may have affinity to any thread. {\tt blocksize}
is the block size of the shared buffer in elements (of {\tt size} bytes each).
A {\tt blocksize} of 0 indicates an indefinite blocking factor.

\np In the case of individual file pointers, the following rules apply: Each
thread may pass a different address for the {\tt buffer} parameter. 
Each thread writes {\tt (size*nmemb)} bytes of data from its buffer to the
file at the position indicated by its individual file pointer.
Each thread may pass a different value for {\tt blocksize}, {\tt size} and {\tt 
nmemb}. If {\tt size} or {\tt nmemb} is zero, the {\tt buffer} argument is
ignored and that thread performs no I/O.  On success, the function returns the
number of bytes written by the calling thread, and the individual file pointer of
the thread is incremented by that amount.

\np In the case of a common file pointer, the following rules apply: All
threads must pass the same address for the {\tt buffer} parameter, and the 
same value for {\tt blocksize}, {\tt size} and {\tt nmemb}. The effect is that 
{\tt (size*nmemb)} bytes of data are written from the buffer to the file at
the position indicated by the common file pointer.  If {\tt size} or {\tt
nmemb} is zero, the {\tt buffer} argument is ignored and the operation has no
effect.  On success, the function returns the total number of bytes written by all
threads, and the common file pointer is incremented by that amount.

\np If writing with individual file pointers results in overlapping accesses in
the file, the result is determined by the current consistency and atomicity
semantics mode in effect for {\tt fd} (see Section \ref{io-func-open}).

\np The function returns --1 on error and sets {\tt errno} appropriately.

\subsubsection{List I/O}
\label{io-func-list}
\index{list I/O}

{\bf Common Constraints}

\npf List I/O functions take a list of addresses/offsets and corresponding
lengths in memory and file to read from or write to.

\np List I/O functions can be called regardless of whether the current file pointer
type is individual or common.

\np File pointers are not updated as a result of a list I/O read/write
operation.

\index{upc\_local\_memvec}
\index{upc\_shared\_memvec}
\index{upc\_filevec}
\np Types declared in \verb=<upc_io.h>= are

\begin{verbatim}
    struct upc_local_memvec
\end{verbatim}

which contains at least the initial members, in this order:

\begin{verbatim}
    void *baseaddr;
    size_t len;
\end{verbatim}

and is a memory vector element pointing to a contiguous region of
local memory.

\np\vspace{-2.5em}
\begin{verbatim}
    struct upc_shared_memvec
\end{verbatim}

which  contains at least the initial members, in this order:

\begin{verbatim}
    shared void *baseaddr;
    size_t blocksize;
    size_t len;
\end{verbatim}

and is a memory vector element pointing to a blocked region of
shared memory.

\np\vspace{-2.5em}
\begin{verbatim}
    struct upc_filevec
\end{verbatim}

which contains at least the initial members, in this order: 

\begin{verbatim}
    upc_off_t offset;
    size_t len;
\end{verbatim}

and is a  file vector element pointing to a contiguous region of
a file.

For all cases these vector element types specify regions
which are  {\tt len} bytes long.  If {\tt len} is zero, the entry is ignored.
{\tt blocksize} is the block size of the shared buffer in bytes. A {\tt blocksize} of 0
indicates an indefinite blocking factor.

\np The {\tt memvec} argument passed to any list I/O \textit{read} function by a
single thread must not specify overlapping regions in memory.

\np The base addresses passed to {\tt memvec} can be in any order.

\np The {\tt filevec} argument passed to any list I/O \textit{write} function by a
single thread must not specify overlapping regions in the file.

\np The offsets passed in {\tt filevec} must be in monotonically non-decreasing
order.

\np No function in this section (\ref{io-func-list}) may be called while an asynchronous
operation is pending on the file handle.

\np No function in this section (\ref{io-func-list}) implies the presence of barriers at
entry or exit. However, the programmer is advised to use a barrier after
calling {\tt upc\_all\_fread\_list\_shared} to ensure that the entire shared buffer
has been filled up, and similarly, use a barrier before calling
{\tt upc\_all\_fwrite\_list\_shared} to ensure that the entire shared buffer is
up-to-date before being written to the file.

\np For all the list I/O functions, each thread passes an
independent set of memory and file vectors. Passing the same vectors on two
or more threads specifies redundant work.  The file pointer is a single-valued
argument, all other arguments to the list I/O functions are NOT single-valued.

\np EXAMPLE 1:  a collective list I/O read operation. 
The list I/O functions allow the user to specify noncontiguous accesses both
in memory and file in the form of lists of explicit offsets and lengths in
the file and explicit address and lengths in memory. None of the file
pointers are used or updated in this case. 

\begin{verbatim}
#include <upc.h>
#include <upc_io.h>
char buffer[12];
struct upc_local_memvec memvec[2] = {(&buffer[0],4},{&buffer[7],3}};
struct upc_filevec filevec[2];
upc_file_t *fd; 

fd = upc_all_fopen( "file", UPC_RDONLY | UPC_INDIVIDUAL_FP, 0, NULL );
filevec[0].offset = MYTHREAD*5;
filevec[0].len = 2;
filevec[1].offset = 10+MYTHREAD*5; 
filevec[1].len = 5;

upc_all_fread_list_local( fd, 2, &memvec, 2, &filevec, 
                                    UPC_IN_ALLSYNC | UPC_OUT_ALLSYNC);
\end{verbatim}

%\begin{figure}[h]
%\includegraphics[bb=0 0 678 247, width=1\textwidth]{figure4.eps}
%\includegraphics[width=1\textwidth]{figure4}
%\caption{List I/O read of noncontiguous parts of a file to private noncontiguous buffers}
%\end{figure}



\paragraph{The {\tt upc\_all\_fread\_list\_local} function}\ \\

{\bf Synopsis}
\index{file reading}
\index{upc\_all\_fread\_list\_local}


\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fread_list_local(upc_file_t *fd,
         size_t memvec_entries, struct upc_local_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_list\_local} reads data from a file into local
buffers in memory. The file handle must be open for reading.

\np {\tt memvec\_entries} indicates the number of entries in the array {\tt memvec} and
{\tt filevec\_entries} indicates the number of entries in the array {\tt filevec}. The
values may be 0, in which case the {\tt memvec} or {\tt filevec} argument is ignored and
no locations are specified for I/O.

\np The result is as if data were read in order from the list of locations
specified by {\tt filevec} and placed in memory in the order specified by the list
of locations in {\tt memvec}. The total amount of data specified by {\tt memvec} must
equal the total amount of data specified by {\tt filevec}.

\np On success, the function returns the number of bytes read by the 
calling
thread. On error, it returns --1 and sets {\tt errno} appropriately.

\paragraph{The {\tt upc\_all\_fread\_list\_shared} function}\ \\

{\bf Synopsis}
\index{file reading}
\index{upc\_all\_fread\_list\_shared}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fread_list_shared(upc_file_t *fd,
         size_t memvec_entries, struct upc_shared_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_list\_shared} reads data from a file
into various locations of a shared buffer in memory. The file handle must be open for reading.

\np {\tt memvec\_entries} indicates the number of entries in the array {\tt memvec} and
{\tt filevec\_entries} indicates the number of entries in the array {\tt filevec}. The
values may be 0, in which case the {\tt memvec} or {\tt filevec} argument is ignored and
no locations are specified for I/O.

\np The result is as if data were read in order from the list of locations
specified by {\tt filevec} and placed in memory in the order specified by the list
of locations in {\tt memvec}. The total amount of data specified by {\tt memvec} must
equal the total amount of data specified by {\tt filevec}.

\np If any of the reads from different threads result in overlapping regions
in memory, the result is determined by the current consistency and atomicity
semantics mode in effect for {\tt fd} (see Section \ref{io-func-open}).

\np On success, the function returns the number of bytes read by the calling
thread. On error, it returns --1 and sets {\tt errno} appropriately.

\paragraph{The {\tt upc\_all\_fwrite\_list\_local} function}\ \\

{\bf Synopsis}
\index{file writing}
\index{upc\_all\_fwrite\_list\_local}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fwrite_list_local(upc_file_t *fd,
         size_t memvec_entries, struct upc_local_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec, 
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_list\_local} writes data from local buffers in memory to
a file. The file handle must be open for writing.

\np {\tt memvec\_entries} indicates the number of entries in the array {\tt memvec} and
{\tt filevec\_entries} indicates the number of entries in the array {\tt filevec}. The
values may be 0, in which case the {\tt memvec} or {\tt filevec} argument is ignored and
no locations are specified for I/O.

\np The result is as if data were written from memory locations in the order
specified by the list of locations in {\tt memvec} to locations in the file in the
order specified by the list in {\tt filevec}. The total amount of data specified
by {\tt memvec} must equal the total amount of data specified by {\tt filevec}.

\np If any of the writes from different threads result in overlapping accesses
in the file, the result is determined by the current consistency and atomicity
semantics mode in effect for {\tt fd} (see Section \ref{io-func-open}).

\np On success, the function returns the number of bytes written by the
calling thread. On error, it returns --1 and sets {\tt errno} appropriately.

\paragraph{The {\tt upc\_all\_fwrite\_list\_shared} function}\ \\

{\bf Synopsis}
\index{file writing}
\index{upc\_all\_fwrite\_list\_shared}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fwrite_list_shared(upc_file_t *fd,
         size_t memvec_entries, struct upc_shared_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_list\_shared} writes data from various locations of a
shared buffer in memory to a file. The file handle must be open for writing.

\np {\tt memvec\_entries} indicates the number of entries in the array {\tt memvec} and
{\tt filevec\_entries} indicates the number of entries in the array {\tt filevec}. The
values may be 0, in which case the {\tt memvec} or {\tt filevec} argument is ignored and
no locations are specified for I/O.

\np The result is as if data were written from memory locations in the order
specified by the list of locations in {\tt memvec} to locations in the file in the
order specified by the list in {\tt filevec}. The total amount of data specified
by {\tt memvec} must equal the total amount of data specified by {\tt filevec}.

\np If any of the writes from different threads result in overlapping accesses
in the file, the result is determined by the current consistency and atomicity
semantics mode in effect for {\tt fd} (see Section \ref{io-func-open}).

\np On success, the function returns the number of bytes written by the
calling thread. On error, it returns --1 and sets {\tt errno} appropriately.

\subsubsection{Asynchronous I/O}
\index{asynchronous I/O}
\index{file reading}
\index{file writing}

{\bf Common Constraints}

\npf Only one asynchronous I/O operation can be outstanding on a UPC-IO file
handle at any time. If an application attempts to initiate a second
asynchronous I/O operation while one is still outstanding on the same file
handle the behavior is undefined -- however, high-quality implementations will
issue a fatal error.

\index{upc\_all\_fwait\_async}
\index{upc\_all\_ftest\_async}
\np For asynchronous read operations, the contents of the destination memory
are undefined until after a successful {\tt upc\_all\_fwait\_async} or \linebreak
{\tt upc\_all\_ftest\_async} on the file handle. For asynchronous write operations,
the source memory may not be safely modified until after a successful
{\tt upc\_all\_fwait\_async} or {\tt upc\_all\_ftest\_async} on the file handle.

\np An implementation is free to block for completion of an operation in the
asynchronous initiation call or in the {\tt upc\_all\_ftest\_async} call (or both).
High-quality implementations are recommended to minimize the amount of time
spent within the asynchronous initiation or {\tt upc\_all\_ftest\_async} call.

\np In the case of list I/O functions, the user may modify or free the lists
after the asynchronous I/O operation has been initiated.

\np The semantics of the flags of type {\tt upc\_flag\_t} when applied
    to the async variants of the fread/fwrite functions should be
    interpreted as follows: constraints that reference entry to a
    function call correspond to entering the fread\_async-
    /fwrite\_async call that initiates the asynchronous operation, and
    constraints that reference returning from a function call
    correspond to returning from the {\tt upc\_all\_fwait\_async()} or
    successful {\tt upc\_all\_ftest\_async()} call that completes the
    asynchronous operation. Also, note that the flags
    which govern an asynchronous operation are passed to the library
    during the asynchronous initiation call.

\paragraph{The {\tt upc\_all\_fread\_local\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_local\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h> 
    void upc_all_fread_local_async(upc_file_t *fd, void *buffer,
         size_t size, size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_local\_async} initiates an asynchronous read from a file
into a local buffer on each thread.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fread\_local}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fread\_shared\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_shared\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fread_shared_async(upc_file_t *fd,
         shared void *buffer, size_t blocksize, size_t size,
         size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_shared\_async} initiates an asynchronous read from a file
into a shared buffer.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fread\_shared}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fwrite\_local\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_local\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fwrite_local_async(upc_file_t *fd, void *buffer,
         size_t size, size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_local\_async} initiates an asynchronous write from a
local buffer on each thread to a file.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fwrite\_local}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fwrite\_shared\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_shared\_async}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fwrite_shared_async(upc_file_t *fd,
         shared void *buffer, size_t blocksize,size_t size,
         size_t nmemb, upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_shared\_async} initiates an asynchronous write from a
shared buffer to a file.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fwrite\_shared}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fread\_list\_local\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_list\_local\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h> 
    void upc_all_fread_list_local_async(upc_file_t *fd,
         size_t memvec_entries, struct upc_local_memvec const *memvec,
         size_t filevec_entries,  struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_list\_local\_async} initiates an asynchronous read of
data from a file into local buffers in memory.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fread\_list\_local}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fread\_list\_shared\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fread\_list\_shared\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fread_list_shared_async(upc_file_t *fd, 
         size_t memvec_entries, struct upc_shared_memvec const *memvec,
         size_t filevec_entries,  struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fread\_list\_shared\_async} initiates an asynchronous read of data from a
file into various locations of a shared buffer in memory.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fread\_list\_shared}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fwrite\_list\_local\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_list\_local\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fwrite_list_local_async(upc_file_t *fd,
         size_t memvec_entries, struct upc_local_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_list\_local\_async} initiates an asynchronous write of
data from local buffers in memory to a file.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fwrite\_list\_local}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fwrite\_list\_shared\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwrite\_list\_shared\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    void upc_all_fwrite_list_shared_async(upc_file_t *fd,
         size_t memvec_entries, struct upc_shared_memvec const *memvec,
         size_t filevec_entries, struct upc_filevec const *filevec,
         upc_flag_t flags);
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwrite\_list\_shared\_async} initiates an asynchronous write of
data from various locations of a shared buffer in memory to a file.

\np The meaning of the parameters and restrictions are the same as for the
blocking function, {\tt upc\_all\_fwrite\_list\_shared}.

\np The status of the initiated asynchronous I/O operation can be retrieved by calling
{\tt upc\_all\_ftest\_async} or {\tt upc\_all\_fwait\_async}.

\paragraph{The {\tt upc\_all\_fwait\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_fwait\_async}

\npf\vspace{-2.5em}
\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_fwait_async(upc_file_t *fd)
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_fwait\_async} completes the previously issued asynchronous I/O
operation on the file handle {\tt fd}, blocking if necessary.

\np It is erroneous to call this function if there is no outstanding
asynchronous I/O operation associated with {\tt fd}.

\np On success, the function returns the number of bytes read or written by the
asynchronous I/O operation as specified by the blocking variant of the
function used to initiate the asynchronous operation. On error, it returns
--1 and sets {\tt errno} appropriately, and the outstanding asynchronous operation
(if any) becomes no longer outstanding.

\paragraph{The {\tt upc\_all\_ftest\_async} function}\ \\

{\bf Synopsis}
\index{upc\_all\_ftest\_async}

\npf\vspace{-2.5em} 

\begin{verbatim}
    #include <upc.h>
    #include <upc_io.h>
    upc_off_t upc_all_ftest_async(upc_file_t *fd, int *flag)
\end{verbatim}

{\bf Description}

\np {\tt upc\_all\_ftest\_async} tests whether the outstanding asynchronous I/O
operation associated with {\tt fd} has completed.

\np If the operation has completed, the function sets {\tt flag=1} and the
asynchronous operation becomes no longer outstanding;\footnote{%
This implies it is disallowed to call {\tt upc\_all\_fwait\_async} or
{\tt upc\_all\_ftest\_async} immediately after a successful {\tt upc\_all\_ftest\_async}
on that file handle.} otherwise it sets {\tt flag=0}. The same value of {\tt flag} is
set on all threads.

\np If the operation was completed, the function returns the number of bytes
that were read or written as specified by the blocking variant of the
function used to initiate the asynchronous operation. On error, it returns
--1 and sets {\tt errno} appropriately, and sets the {\tt flag=1}, and the outstanding
asynchronous operation (if any) becomes no longer outstanding.

\np It is erroneous to call this function if there is no outstanding
asynchronous I/O operation associated with {\tt fd}.

\pagebreak
\section{Formal UPC Memory Consistency Semantics}
\label{mem-semantics}
\index{memory consistency}
\npf The memory consistency model in a language defines the order in 
which the results of write operations may be observed through read operations.  
The behavior of a UPC program may depend on the timing of accesses to shared
variables, so in general a program defines a set of possible executions,
rather than a single execution.  The memory consistency model
constrains the set of possible executions for a given program;
the user may then rely on properties that are true of all
of those executions.  

\np The memory consistency model is defined in terms of the read and 
write operations issued by each thread in a na\"{\i}ve translation
of the program, i.e., without any program transformations during
translation, where each thread issues operations as defined by 
the abstract machine defined in [ISO/IEC00 Sec. 5.1.2.3].  
[ISO/IEC00 Sec. 5.1.2.3] allows a UPC implementation to perform
various program transformations to improve performance, provided they are not visible 
to the programmer - specifically, provided those transformations do not affect 
the external behavior of the program.
UPC extends this constraint, requiring the set of externally-visible behaviors
(the input/output dynamics and volatile behavior defined in [ISO/IEC00 Sec. 5.1.2.3])
from any execution of the transformed program be indistinguishable from those
of the original program executing on the abstract machine 
and adhering to the memory consistency model as defined in this appendix.

\np This appendix assumes some familiarity with memory consistency
models, partial orders, and basic set theory.

\subsection{Definitions}
\npf A UPC program execution is specified by a program text and a
number of threads, $T$.  An \emph{execution} is a set of operations $O$,
each operation being an instance of some instruction in the program 
text.  The set of operations issued by a thread $t$ is denoted 
$O_t$.  The program executes memory operations on a set of 
variables (or locations) $L$.  The set $V$ is the set of 
possible values that can be stored in the program variables.
%\footnote{This is the point that we could add an atomicity 
%constraint on what types of values are the fundamental unit
%of a read or write, possibly using something like ISO C's sig\_atomic\_t.
%There are actually two separate issues here, namely atomicity
%and clobbering a.k.a. word tearing.}

\index{shared access}
\index{strict shared read}
\index{strict shared write}
\index{relaxed shared read}
\index{relaxed shared write}
\np A \emph{memory operation} in such an execution is given by a location $l \in
L$ to be written or read and a value $v \in V$, which is the value to
be written or the value returned by the read.  A memory operation $m$
in a UPC program has one of the following forms, as defined in Section~\ref{def-access}:
\begin{list}{ $\bullet$ }{\setlength{\itemsep}{0pt}}
\item a strict shared read, denoted SR(l,v)
\item a strict shared write, denoted SW(l,v)
\item a relaxed shared read, denoted RR(l,v)
\item a relaxed shared write, denoted RW(l,v)
\item a local read, denoted LR(l,v)
\item a local write, denoted LW(l,v)
\end{list}
%(Here shared vs local is determined by the sharing type qualification on the
%expression used to perform the access, and for shared accesses, 
%strict vs relaxed is determined as described in UPC Spec 6.4.2).

\np In addition, each memory operation $m$ is associated with exactly one 
of the $T$ threads, denoted $Thread(m)$, and the accessor $Location(m)$ 
is defined to return the location $l$ accessed by $m$.
%and a non-negative integer 
%$SourcePoint(m)$, which uniquely determines the point in the 
%program text from which the operation was issued.  (Note: we
%may not need this.)

\np Given a UPC program execution with $T$ threads, let $M \subseteq O$ be
the set of memory operations in the execution and $M_t$ be the
set of memory operations issued by a given thread $t$.  Each operation
in $M$ is one of the above six types, so the set $M$ is 
partitioned into the following six disjoint subsets:
\begin{list}{ $\bullet$ }{\setlength{\itemsep}{0pt}}
\item $SR(M)$ is the set of strict shared reads in $M$
\item $SW(M)$ is the set of strict shared writes in $M$
\item $RR(M)$ is the set of relaxed shared reads in $M$
\item $RW(M)$ is the set of relaxed shared writes in $M$
\item $LR(M)$ is the set of local reads in $M$
\item $LW(M)$ is the set of local writes in $M$
\end{list}

\np The set of all writes in $M$ is denoted as $W(M)$:
\begin{eqnarray*}
W(M)\ {def \atop =}\ SW(M)\ \cup\ RW(M)\ \cup\ LW(M)
\end{eqnarray*}
and the set of all strict accesses in $M$ is denoted as $Strict(M)$:
\begin{eqnarray*}
Strict(M)\ {def \atop =}\ SR(M)\ \cup\ SW(M)
\end{eqnarray*}

\subsection{Memory Access Model}
\label{MemoryAccessModel}
\index{StrictPairs}
\index{StrictOnThreads}
\index{AllStrict}
\npf Let $StrictPairs(M)$, $StrictOnThreads(M)$, and $AllStrict(M)$
be unordered pairs of memory operations defined as:
\[
StrictPairs(M) {def \atop =} \left\{\ (m_1, m_2)\ \left|\ 
\begin{array}{l} m_1 \neq m_2\ \land\ m_1 \in Strict(M)\ \land \\
                 m_2 \in Strict(M)\ \end{array} \right. \right\} 
\]
\[
StrictOnThreads(M) {def \atop =} \left\{\ (m_1, m_2)\ \left|\ 
\begin{array}{l} m_1 \neq m_2\ \land\ \\ Thread(m_1) = Thread(m_2)\ \land \\ 
                 (\ m_1 \in Strict(M)\ \lor\ m_2 \in Strict(M)\ ) \end{array} \right. \right\} 
\]
\[
AllStrict(M) {def \atop =} StrictPairs(M)\ \cup\ StrictOnThreads(M)
\]

\np Thus, $StrictPairs(M)$ is the set of all pairs of strict memory 
accesses, including those between threads, and $StrictOnThreads(M)$ is
the set of all pairs of memory accesses from the same thread in which at least 
one is strict.  $AllStrict(M)$ is their union, which intuitively is the set of
operation pairs for which all threads must agree upon a unique ordering
(i.e. all threads must agree on the directionality of each pair).
In general, the determination of that ordering will depend on the resolution of 
race conditions at runtime.  
%We later define an {\it ordering} of 
%$AllStrict(M)$ -- a set of ordered pairs that contains all 
%pairs in $AllStrict(M)$ but with an orientation for each pair.  

\index{Conflicting}
\index{DependsOnThreads}
\np UPC programs must preserve the serial dependencies within each thread, 
defined by the set of ordered pairs $DependOnThreads(M_t)$:
\[
Conflicting(M) {def \atop =} \left\{\ (m_1, m_2)\ \left|\ 
\begin{array}{lc} Location(m_1) = Location(m_2)\ \land \\
             (\ m_1 \in W(M)\ \lor\ m_2 \in W(M)\ ) \end{array} \right. \right\} 
\]
\[
\begin{array}{l}
DependOnThreads(M)\ {def \atop =}
\left\{ \langle m_1, m_2\rangle  \left|\ \begin{array}{l} 
 m_1 \neq m_2\ \land\ \\ Thread(m_1) = Thread(m_2)\ \land \\ 
 Precedes(m_1, m_2)\ \land \\
 \left( \begin{array}{l} (m_1, m_2) \in Conflicting(M)\ \lor \\ 
                         (m_1,m_2) \in StrictOnThreads(M) \end{array}\right)\ \end{array} \right. \right\} 
\end{array}
\]
% An alternate formatting possibility:
%\[
%\begin{array}{l}
%DependOnThreads(M) {def \atop =} \vspace{1em} \\
%\left\{ \langle m_1, m_2\rangle \left|\ \begin{array}{l} 
%  m_1 \neq m_2\ \land\ Thread(m_1) = Thread(m_2)\ \land\ Precedes(m_1, m_2) \land \\
%  (\ (m_1, m_2) \in Conflicting(M)\ \lor\ (m_1,m_2) \in StrictOnThreads(M)\ ) \end{array} \right. \right\} 
%\end{array}
%\]

\np $DependOnThreads(M_t)$ establishes an ordering between operations issued 
by a given thread $t$ that involve a data dependence (i.e. those operations in $Conflicting(M_t)$)
-- this ordering is the one maintained by serial compilers and hardware.  
$DependOnThreads(M_t)$ additionally establishes an ordering between 
operations appearing in $StrictOnThreads(M_t)$.
In both cases, the ordering imposed is the one dictated by $Precedes(m_1, m_2)$,
a predicate which intuitively is an ordering relationship defined by serial program order.% 
\footnote{The formal definition of $Precedes$ is given in Section~\ref{MemModelPrecedes}.}
It's important to note that $DependOnThreads(M_t)$ intentionally avoids introducing
ordering constraints between non-conflicting, non-strict operations executed by a single thread 
(i.e. it does not impose ordering between a thread's relaxed/local operations to independent
memory locations, or between relaxed/local reads to any location). As demonstrated in Section~\ref{MemModelExamples},
this allows implementations to freely reorder any consecutive relaxed/local operations issued 
by a single thread, except for pairs of operations accessing the same location where 
at least one is a write; by design this is exactly the condition that is 
enforced by serial compilers and hardware
to maintain sequential data dependences -- requiring any stronger ordering property 
would complicate implementations and likely degrade the performance of relaxed/local accesses.
The reason this flexibility must be directly exposed in the model (unlike
other program transformation optimizations which are implicitly permitted by [ISO/IEC00 Sec. 5.1.2.3]) is because the results of
this reordering may be ``visible" to other threads in the UPC program (as demonstrated in Section~\ref{MemModelExamples})
and therefore could impact the program's ``input/output dynamics".

\np A UPC program execution on $T$ threads with memory accesses $M$ is 
considered {\it UPC consistent} if there exists a partial order 
$<_{Strict}$ that provides an orientation for each pair in $AllStrict(M)$ and for 
each thread $t$, there 
exists a total order $<_t$ on $O_t\ \cup\ W(M)\ \cup\ SR(M)$ 
(i.e. all operations issued by thread $t$ and all writes and strict reads issued by any thread) such that:
\begin{enumerate}
\item $<_t$ defines a correct serial execution.  
In particular:
\begin{itemize}
\item Each read operation returns the value of the ``most recent" 
preceding write to the same location, where ``most recent" is defined by $<_t$.
If there is no prior write of the location in question, the read returns the
initial value of the referenced object as defined by [ISO/IEC00 Sec. 6.7.8/7.2.0.3].%
\footnote{i.e. the initial value of an object declared with an initializer
is the value given by the initializer. Objects with static storage duration 
lacking an initializer have an initial value of zero. 
Objects with automatic storage duration lacking an initializer
have an indeterminate (but fixed) initial value.
The initial value for a dynamically allocated object is described by the 
memory allocation function used to create the object.
}

\item The order of operations in $O_t$ is consistent with the 
ordering dependencies in $DependOnThreads(M_t)$. \label{localDepend}
\end{itemize}

\item $<_t$ is consistent with $<_{Strict}$.  In particular, this implies that all threads 
agree on a total order over the strict operations ($Strict(M)$), and the relative ordering 
of all pairs of operations issued by a single thread where at least one is strict ($StrictOnThreads(M)$).
\end{enumerate}

\np The set of $<_{t}$ orderings that satisfy the above constraints are said to be the 
{\it enabling orderings} for the execution.  An execution is UPC consistent if
each UPC thread has at least one such enabling ordering in this set.
Conformant UPC implementations shall only produce UPC consistent executions.

\np The definitions of $DependOnThreads(M)$ and $<_t$ provide well-defined consistency 
semantics for local accesses to shared objects, making them behave similarly to relaxed shared accesses.
Note that private objects by definition may only be accessed by a single thread, 
and therefore local accesses to private objects trivially satisfy the constraints of the model --
provided the serial data dependencies across sequence points mandated by [ISO/IEC00 Sec. 5.1.2.3] are preserved
for the accesses to private objects on each thread.

\subsection{Consistency Semantics of Standard Libraries and Language Operations}

\subsubsection{Consistency Semantics of Synchronization Operations}
\index{memory consistency, locks}
\index{memory consistency, barriers}
\index{memory consistency, fence}

\npf UPC provides several synchronization operations 
in the language and standard library that can be 
used to strengthen the consistency requirements of a program.
Sections \ref{upc_lock} and \ref{upc_barrier} define the consistency
effects of these operations in terms of a ``null strict reference''.
The formal definition presented here is operationally equivalent to that
normative definition, but is more explicit and therefore included here for completeness.

%Under the alternative asymmetric ordering semantics, this formulation would 
%represent a slight relaxation to the current language semantics, (which state
%that {\it upc\_lock}, {\it upc\_unlock}, {\it upc\_notify} and {\it upc\_wait}
%all imply a full {\it upc\_fence}) because it permits more aggressive movement
%of memory operations past synchronization operations, as allowed by many
%architectural memory models, such as release consistency.

\np The memory consistency semantics of the 
synchronization operations are defined in terms of equivalent accesses
to a fresh variable $l_{synch} \in L$
that does not appear elsewhere in the program.%
\footnote{
Note: These definitions do not give the synchronization operations
their synchronizing effects -- they only define the memory 
model behavior.}

\begin{itemize}
\item A $upc\_fence$ statement implies a strict write followed
by a strict read: $SW(l_{synch}, 0)\ ;\ SR(l_{synch}, 0)$  

\item A $upc\_notify$ statement implies a strict write: $SW(l_{synch}, 0)$
immediately after evaluation of the optional argument (if any) and
before the notification operation has been posted.

\item A $upc\_wait$ statement implies a strict read: $SR(l_{synch}, 0)$ 
immediately after the completion of the statement.

\item A $upc\_lock()$ call or a successful $upc\_lock\-\_attempt()$ call 
implies a strict read: $SR(l_{synch}, 0)$ immediately before return.

\item A $upc\_unlock$ call implies a strict write: $SW(l_{synch}, 0)$
immediately upon entry to the function.

\end{itemize}

\np The actual data values involved in these implied strict accesses
is irrelevant.  The strict operations implied by the synchronization operations 
are present only to serve as a consistency point, introducing orderings in 
$<_{Strict}$ that restrict the relative motion in each $<_t$ of any
surrounding non-strict accesses to shared objects issued by the calling thread.

\subsubsection{Consistency Semantics of Standard Library Calls}

\npf Many of the functions in the UPC standard library can be used to 
access and modify data in shared objects, either non-collectively 
(e.g. $upc\_mem\-\{put,get,cpy\}$) or collectively (e.g. $upc\_all\_broadcast$, etc).
This section defines the consistency semantics of the accesses 
to shared objects which are implied to take place within the 
implementation of these library functions, to provide well-defined
semantics in the presence of concurrent explicit reads and writes of the same shared objects.
For example, an application which calls a function such as $upc\_memcpy$ 
may need to know whether surrounding explicit relaxed operations on
non-conflicting shared objects could possibly be reordered relative to the
accesses that take place inside the library call.  This is a subtle but
unavoidable aspect to the library interface which needs to be explicitly
defined to ensure that applications can be written with portably deterministic
behavior across implementations. 

\np The following sections define the consistency semantics of shared accesses
implied by UPC standard library functions, in the absence of any explicit
consistency specification for the given function (which would always take
precedence in the case of conflict).

\paragraph{Non-Collective Standard Library Calls}\ \\
\index{memory consistency, non-collective library}

\npf  For {\it non-collective} functions in the UPC standard library (e.g. $upc\_mem\{put,get,cpy\}$),
any implied data accesses to shared objects behave as a set of relaxed shared
reads and relaxed shared writes of unspecified size and ordering, issued by the
calling thread. No strict operations or fences are implied by a non-collective
library function call, unless explicitly noted otherwise.

\np EXAMPLE 1:
\begin{verbatim}
        #include <upc_relaxed.h>

        shared int x, y;      // initial values are zero
        shared [] int z[2];   // initial values are zero
        int init_z[2] = { -3, -4 };
        ...
        if (MYTHREAD == 0) {
            x = 1;
 
            upc_memput(z, init_z, 2*sizeof(int)); 

            y = 2;
        } else {
            #pragma upc strict
            int local_y = y;  
            int local_z1 = z[1];
            int local_z0 = z[0];
            int local_x = x;
            ...
        }
\end{verbatim}

\noindent In this example, all of the writes to shared objects are relaxed 
(including the accesses implied by the library call), and thread 0 
executes no strict operations or fences which would inhibit reordering. 
Therefore, other
threads which are concurrently performing strict shared reads of the 
shared objects ($x, y, z[0]$ and $z[1]$) may observe the updates occurring
in any arbitrary order that need not correspond to thread 0's
program order. 
For example, thread 1 may observe a final result of 
$local\_y == 2$, $local\_z1 == -4$, $local\_z0 == 0$ and $local\_x == 0$,
or any other permutation of old and new values for the result of the strict shared reads.
Furthermore, because the shared writes implied by the library call have unspecified size,
thread 1 may even read intermediate values into $local\_z0$ and $local\_z1$ which 
correspond to neither the initial nor the final values for those shared objects.%
\footnote{This is a consequence of the byte-oriented nature of shared data movement
functions (which is assumed in the absence of further specification) and is
orthogonal to the issue of write atomicity.}
Finally, note that all of these observations remain true even if $z$ had instead been declared as:
\begin{verbatim}
        strict shared [] int z[2];
\end{verbatim}
because the consistency qualification used on the shared object declarator 
is irrelevant to the operation of the library call, whose implied shared 
accesses are specified to always behave as relaxed shared accesses.

\np If $upc\_fence$ operations were inserted in the blank lines immediately
preceding and following the $upc\_memput$ invocation in the example above, then
$<_{Strict}$ would imply that all reading threads would be guaranteed to observe
the shared writes according to thread 0's program order.  Specifically, any
thread reading a non-initial value into $local\_y$ would be guaranteed to read
the final values for all the other shared reads, and any thread reading the
initial zero value into $local\_x$ would be guaranteed to also have read the
initial zero values for all the other shared reads.%
\footnote{However, for threads reading the initial value into $local\_y$ and
the final value into $local\_x$, the writes to $z[0]$ and $z[1]$ could still
appear to have been arbitrarily reordered or segmented, leading to
indeterminate values in $local\_z0$ and $local\_z1$.}
Explicit use of $upc\_fence$ immediately preceding and following non-collective
library calls operating on shared objects is the recommended method for
ensuring ordering with respect to surrounding relaxed operations issued by the
calling thread, in cases where such ordering guarantees are required
for program correctness.

\paragraph{Collective Standard Library Calls}\ \\
\index{memory consistency, collective library}

\npf For {\it collective} functions in the UPC standard library, any implied data
accesses to shared objects behave as a set of relaxed shared reads and relaxed
shared writes of unspecified size and ordering, issued by one or more
unspecified threads (unless explicitly noted otherwise).

\np For {\it collective} functions in the UPC standard library
that take a $upc\_flag\_t$
argument (e.g. $upc\_all\_broadcast$), one or more $upc\_fence$ operations
may be implied upon entry and/or exit to the library call, 
based on the flags selected in the value of the $upc\_flag\_t$ argument, as follows:

\begin{itemize}
\item
{\tt UPC\_IN\_ALLSYNC} and {\tt UPC\_IN\_MYSYNC} imply a $upc\_fence$ operation on 
each calling thread, immediately upon entry to the library function call.

\item
{\tt UPC\_OUT\_ALLSYNC} and {\tt UPC\_OUT\_MYSYNC} imply a $upc\_fence$ operation on 
each calling thread, immediately before return from the library function call.

\item 
No fence operations are implied by {\tt UPC\_IN\_NOSYNC} or {\tt UPC\_OUT\_NOSYNC}.
\end{itemize}


\np The $upc\_fence$ operations implied by the rules above are sufficient to 
ensure the results one would naturally expect in the presence of 
relaxed or local accesses to shared objects issued immediately 
preceding or following an {\tt ALLSYNC} or {\tt MYSYNC} collective
library call that accesses the same shared objects. Without such fences, 
nothing would prevent prior or subsequent non-strict operations 
issued by the calling thread from being reordered relative 
to some of the accesses implied by the library call (which 
might not be issued by the current thread), potentially leading to 
very surprising and unintuitive results. The {\tt NOSYNC} flag
provides no synchronization guarantees between the execution stream of
the calling thread and the shared accesses implied by the collective library call,
therefore no additional fence operations are required.%
\footnote{Any deterministic program which makes use of {\tt NOSYNC} collective 
data movement functions is likely to be synchronizing access to shared objects 
via other means -- for example, through the use of explicit $upc\_barrier$ or
{\tt ALLSYNC}/{\tt MYSYNC} collective calls that already provide sufficient synchronization
and fences.}

\subsection{Properties Implied by the Specification}

\npf The memory model definition is rather subtle in some points, but
as described in Section 5.1.2.3, most programmers need not worry about these details.  There
are some simple properties that are helpful in understanding 
the semantics.% 
\footnote{Note the properties described in this section and in Section 5.1.2.3 apply only to 
programs which are ``conforming'' as defined by [ISO/IEC00 Sec. 4] -- 
namely, those where no thread performs an operation which is labelled as 
having undefined behavior (e.g. dereferencing an uninitialized pointer).}
\index{sequential consistency}
The first property is:
\begin{itemize}
\item A UPC program which accesses shared objects using only strict operations%
\footnote{i.e. no relaxed shared accesses, and no accesses to shared objects via pointers-to-local}
will be sequentially consistent.
\end{itemize}

\np This property is trivially true due to the global total order that $<_{Strict}$
imposes over strict operations (which is respected in every thread's $<_t$), but may
not very useful in practice -- because the exclusive use of strict operations
for accessing shared objects may incur a noticeable performance penalty.
Nevertheless, this property may still serve as a useful debugging mechanism, because even 
in the presence of data races a fully strict program is guaranteed
to only produce behaviors allowed under sequential consistency [Lam79],
which is generally considered the simplest parallel memory model to understand and the one which
na\"{\i}ve programmers typically assume.

\np Of more interest is that programs free of race conditions 
will also be sequentially consistent.  This requires a more
formal definition of race condition, because programmers
may believe their program is properly synchronized using
memory operations when it is not.  

\index{PotentialRaces}

\np $PotentialRaces(M)$ is defined as a set of unordered pairs $(m_1, m_2)$:
\[
PotentialRaces(M) {def \atop =} \left\{(m_1, m_2)\left|\ 
\begin{array}{l} Location(m_1) = Location(m_2)\ \land\\
                 Thread(m_1)\ \neq\ Thread(m_2)\ \land\\
                 (\ m_1 \in W(M)\ \lor\ m_2 \in W(M)\ )\end{array}\right.\right\}
\]

\np An execution is race-free if every $(m_1, m_2) \in PotentialRaces(M)$ is ordered by $<_{Strict}$.
 i.e. an execution is race-free if and only if:
\[
\forall (m_1, m_2) \in PotentialRaces(M) : (\ m_1 <_{Strict} m_2\ )\ \lor\ (\ m_2 <_{Strict} m_1\ )
\]

\np Note this implies that all threads $t$ and all enabling orderings $<_t$ agree upon the ordering of each $(m_1, m_2) \in PotentialRaces(M)$ (so there is no race).  
These definitions allow us to state a very useful property of UPC programs:

\begin{itemize}
\item A program that produces only race-free executions will be sequentially consistent.  
\end{itemize}

\np Note that UPC locks and barriers constrain $PotentialRaces$ as one would
expect, because these synchronization primitives imply 
strict operations which introduce orderings in $<_{Strict}$ for the operations in question.

%--------------------------------------------------------------------------
\subsection{Examples}
\label{MemModelExamples}
\index{memory consistency, examples}

\npf The subsequent examples demonstrate the semantics of the memory
model by presenting hypothetical execution traces and explaining how the memory
model either allows or disallows the behavior exhibited in each trace. The
examples labelled ``disallowed'' denote a trace which is not UPC consistent and
therefore represent a violation of the specified memory model. Such an
execution trace shall never be generated by a conforming UPC implementation.
The examples labelled ``allowed'' denote a trace which is UPC consistent and
therefore represent a permissible execution that satisfies the constraints of
the memory model. Such an execution trace \emph{may} be generated by a
conforming UPC implementation.%
\footnote{The memory model specifies guarantees
which must be true of any conformant UPC implementation and therefore may be
portably relied upon by users. A given UPC implementation may happen to provide
guarantees which are stronger than those required by the model, thus in general
the set of behaviors which can be generated by conformant implementation will
be a subset of those behaviors permitted by the model.} 

\np In the figures below, each execution is shown by the linear
graph which is the $Precedes()$ program order for each thread, generated
by an execution of the source program on the abstract machine.  Pairs of 
memory operations that are ordered by the global ordering
over memory operations in $AllStrict(M)$ (i.e. $m_1 <_{Strict} m_2$) are represented
as $m_1 \Rightarrow m_2$.  All threads must agree
upon the relative ordering imposed by these edges in their $<_t$ orderings.  
Pairs ordered by a thread $t$ as in 
$m_1 <_t m_2$ are represented by $m_1 \rightarrow m_2$.\\
Arcs that are implied by transitivity are omitted.  Assume
all variables are initialized to 0.


\np EXAMPLE 1: \textbf{Allowed behavior} 
that would not be allowed under
sequential consistency.  There are only relaxed operations,
so threads need not observe the program order of
other threads.  Because all operations are relaxed,
there are no $\Rightarrow$ orderings between operations.


\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RR(x,1); \> RW(x,2)\\
$T1$: \> RR(x,2); \> RW(x,1)\\
\end{tabbing}

\bigskip
$<_0$:\hspace{0.25in}
\xymatrix{
RR(x,1) \ar[r] & RW(x,2)  \\
 & RW(x,1) \ar[ul]
}\hspace{.5in}
\parbox[t]{3in}
{$T0$ observes $T1$'s write happening before its own read.}

\bigskip
$<_1:$\hspace{0.25in}
\xymatrix{
 & RW(x,2) \ar[dl] \\
RR(x,2) \ar[r] & RW(x,1) 
}\hspace{.5in}
\parbox[t]{3in}
{$T1$ must observe its own program order for conflicting operations,
but it sees $T0$'s write as the first operation.}

\bigskip
Note that relaxed reads issued by thread $t$ only appear in the $<_t$ of that thread.

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 2: \textbf{Disallowed behavior}
which is the same as 
the previous example, but with all accesses
made strict.  All edges in the graph below
must therefore be $\Rightarrow$ edges.
This also implies the program order edges must
be observed in $<_{Strict}$ and the two threads must agree on the
order of the races.  The use of unique values 
in the writes for this example forces an orientation
of the cross-thread edges, so an acyclic 
$<_{Strict}$ cannot be defined that satisfies the
write-to-read data flow requirements for a valid $<_t$.
\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> SR(x,1); \> SW(x,2)\\
$T1$: \> SR(x,2); \> SW(x,1)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{.2in}
\xymatrix{
SR(x,1) \ar@{=>}[r] & SW(x,2) \ar@{=>}[dl] \\
SR(x,2) \ar@{=>}[r] & SW(x,1) \ar@{=>}[ul]
}\hspace{.2in}
\parbox[t]{3.25in}
{All of the edges shown are required, but this \\
is not a valid $<_{Strict}$, since it contains a cycle.  }

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 3: \textbf{Allowed behavior} 
that would be disallowed (as in the first
example) if all of the accesses were
strict.  Again one thread may observe the other's 
operations happening out of program order. 
This is the pattern of memory operations 
that one might see with a spin lock, where $y$ is 
the lock protecting the variable $x$.  The implication
is that UPC programmers should not build synchronization
out of relaxed operations.

\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> RW(y,1)\\
$T1$: \> RR(y,1); \> RR(x,0)\\
\end{tabbing}

\bigskip
$<_0$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar[r] & RW(y,1)  \\
}\hspace{.5in}
\parbox[t]{3in}
{$T0$ observes only its own writes. \\
 The writes are non-conflicting, so either ordering constitutes a valid $<_0$.}

\bigskip
$<_1:$\hspace{0.25in}
\xymatrix{
RW(x,1) & RW(y,1) \ar[dl] \\
RR(y,1) \ar[r] & RR(x,0) \ar[ul]
}\hspace{.5in}
\parbox[t]{3in}
{To satisfy write-to-read data flow in $<_1$, 
RW(x,1) must follow RR(x,0) and
RR(y,1) must follow RW(y,1).
There are three other valid $<_1$ orderings 
which satisfy these constraints.}

\bigskip
%--------------------------------------------------------------------------
\np  EXAMPLE 4: \textbf{Allowed behavior} 
that would be disallowed
under sequential consistency.  This example is similar
to the previous ones, but involves a read-after-write
on each processor.  Neither thread sees the update by
the other, but in the $<_t$ orderings, each thread
conceptually observes the other thread's operations happening out
of order.

\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> RR(y,0)\\
$T1$: \> RW(y,1); \> RR(x,0)\\
\end{tabbing}

\bigskip
$<_0$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar[r] & RR(y,0) \ar[dl]  \\
RW(y,1)
}\hspace{.25in}
\parbox[t]{3in}
{The only constraint on $<_0$ is RW(y,1) must follow RR(y,0).
 Several other valid $<_0$ orderings are possible.}

\bigskip
$<_1:$\hspace{0.25in}
\xymatrix{
RW(x,1) \\
RW(y,1) \ar[r] & RR(x,0) \ar[ul]
}\hspace{.25in}
\parbox[t]{3in}
{Analogous situation with a write-after-read, this time on x.
 Several other valid $<_1$ orderings are possible.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 5: \textbf{Disallowed behavior} 
because with strict accesses,
one of the two writes must ``win'' the race condition.
Each thread observes the other thread's write happening
after its own write, which creates a cycle when one
attempts to construct $<_{Strict}$.
\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> SW(x,2); \> SR(x,1)\\
$T1$: \> SW(x,1); \> SR(x,2)\\
\end{tabbing}

$<_{Strict}$:\hspace{.5in}
\xymatrix{
SW(x,2) \ar@{<=>}[d] \ar@{=>}[r] & SR(x,1) \\
SW(x,1) \ar@{=>}[r] & SR(x,2)
}\hspace{.5in}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 6: \textbf{Allowed behavior} 
where a thread observes its own reads occurring out-of-order.
Reordering of reads is commonplace in serial compilers/hardware, but
in this case an intervening modification by a different thread makes
this reordering visible.
Strengthening the model to prohibit such reordering of 
relaxed reads to the same location would impose serious restrictions on the implementation 
of relaxed reads that would likely degrade performance - 
for example, under such a model an optimizer could not reorder the reads in this example
(or allow them to proceed as concurrent non-blocking operations if they
might be reordered in the network) unless it could statically prove
the reads were to different locations or no other thread was writing the 
location.
\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> SW(y,1); \> RW(x,2)\\
$T1$: \> RR(x,2); \> RR(x,1)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{0.1in}
\xymatrix{
RW(x,1) \ar@{=>}[r] & SW(y,1) \ar@{=>}[r] & RW(x,2)
}\hspace{0.25in}
\parbox[t]{2.5in}
{$DependOnThreads(M_0)$ implies this is the only valid $<_{Strict}$ ordering
over $StrictOnThreads(M)$}

\bigskip
$<_0$:\hspace{0.2in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & SW(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & RW(x,2)
}\hspace{0.25in}
\parbox[t]{2.5in}
{$<_0$ conforms to $<_{Strict}$}

\bigskip
$<_1$:\hspace{0.2in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar[dr] & SW(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & RW(x,2) \ar[dll] \\
RR(x,2) & RR(x,1) \ar[u]
}\hspace{0.25in}
\parbox[t]{2.5in}
{$<_1$ conforms to $<_{Strict}$.
T1's operations on x do not conflict because they are both reads, 
and hence may appear relatively reordered in $<_1$. 
One other $<_1$ ordering is possible.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 7: \textbf{Disallowed behavior} 
similar to the previous example, but in this case
the addition of a relaxed write on thread 1 introduces dependencies in 
$DependOnThreads(M_1)$, such that (all else being equal) the model requires T1's second read
to return the value 3. If T1's write were to any location other than x, 
the behavior shown would be allowed.
\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> SW(y,1); \> RW(x,2)\\
$T1$: \> RR(x,2); \> RW(x,3); \> RR(x,1)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{0.1in}
\xymatrix{
RW(x,1) \ar@{=>}[r] & SW(y,1) \ar@{=>}[r] & RW(x,2)
}\hspace{0.1in}
\parbox[t]{2.5in}
{$DependOnThreads(M_0)$ implies this is the only valid $<_{Strict}$ ordering
over $StrictOnThreads(M)$}

\bigskip
$<_0$:\hspace{0.1in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & SW(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & RW(x,2) \ar[dl] \\
 & RW(x,3)
}\hspace{0.25in}
\parbox[t]{2.5in}
{$<_0$ conforms to $<_{Strict}$. Other orderings are possible.}

\bigskip
$<_1$:\hspace{0.1in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & SW(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & RW(x,2) \ar[dll] \\
RR(x,2) \ar[r] & RW(x,3) \ar[r] & RR(x,?) 
}\hspace{0.25in}
\parbox[t]{2.5in}
{This is the only $<_1$ that conforms to $<_{Strict}$ and $DependOnThreads(M_1)$.
The second read of x cannot return 1 - it must return 3.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 8: \textbf{Disallowed behavior} 
demonstrating why strict reads appear in every $<_t$,
rather than just for the thread that issued them. If the strict reads were 
absent from $<_0$, this behavior would be allowed.

\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> RW(x,2)\\
$T1$: \> SR(x,2); \> SR(x,1)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{0.25in}
\xymatrix{
\\
SR(x,2) \ar@{=>}[r] & SR(x,1) 
}\hspace{0.4in}
\parbox[t]{2.5in}
{$DependOnThreads(M_1)$ implies this is the only valid $<_{Strict}$ ordering
over $StrictOnThreads(M)$}

\bigskip
$<_0$:\hspace{0.5in}
\xymatrix{
RW(x,1) \ar[r] & RW(x,2) \ar[dl] \\
SR(x,2) \ar@{=>}[r] \ar@/^1pc/[r] & SR(x,?) 
}\hspace{0.4in}
\parbox[t]{2.5in}
{This is the only $<_0$ that conforms to $<_{Strict}$ and $DependOnThreads(M_0)$.
The second read of x cannot return 1 - it must return 2.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 9: \textbf{Allowed behavior} 
similar to the previous example, but the writes are
no longer conflicting, and therefore not ordered by $DependOnThreads(M_0)$.

\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> RW(y,1)\\
$T1$: \> SR(y,1); \> SR(x,0)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{0.25in}
\xymatrix{
\\
SR(y,1) \ar@{=>}[r] & SR(x,0) 
}\hspace{0.4in}
\parbox[t]{2.5in}
{$DependOnThreads(M_1)$ implies this is the only valid $<_{Strict}$ ordering
over $StrictOnThreads(M)$}

\bigskip
$<_0,<_1$:\hspace{0.25in}
\xymatrix{
RW(x,1) & RW(y,1) \ar[dl] \\
SR(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & SR(x,0) \ar[ul]
}\hspace{0.25in}
\parbox[t]{2.5in}
{The writes are non-conflicting, therefore not ordered by $DependOnThreads(M_0)$.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 10: \textbf{Allowed behavior} 
Another example of a thread observing its own relaxed reads out of order, 
regardless of location accessed.

\begin{tabbing}WWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> SW(y,1)\\
$T1$: \> RR(y,1); \> RR(x,1); \> RR(x,0)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar@{=>}[r] & SW(y,1) 
}\hspace{0.4in}
\parbox[t]{2.5in}
{$DependOnThreads(M_0)$ implies this is the only valid $<_{Strict}$ ordering
over $StrictOnThreads(M)$}

\bigskip
$<_0$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & SW(y,1) 
}\hspace{0.6in}
\parbox[t]{2.5in}
{Relaxed reads from thread 1 do not appear in $<_0$}

\bigskip
$<_1$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & SW(y,1) \ar[dl] \\
RR(y,1) \ar[r] & RR(x,1) & RR(x,0) \ar[ull]
}\hspace{0.25in}
\parbox[t]{2in}
{Relaxed reads have been reordered. Other $<_1$ orders are possible.}

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 11: \textbf{Disallowed behavior} 
demonstrating that a barrier synchronization 
orders relaxed operations as one would expect.

\begin{tabbing}WWWWW\=WWWWW\=WWWWWWW\=WWWWWW\=\kill
$T0$: \> RW(x,1); \> upc\_notify; \> upc\_wait\\
$T1$: \> \> upc\_notify; \> upc\_wait; \> RR(x,0)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\\
\xymatrix{
RW(x,1) \ar@{=>}[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] \ar@{=>}[d] \ar@{=>}[dr] & *\txt{$upc\_wait$\\$(=SR*)$}\\
& *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] \ar@{=>}[ur] & *\txt{$upc\_wait$\\$(=SR*)$} \ar@{=>}[r] \ar@{=>}[u] & RR(x,0)
}\hspace{0.1in}
\parbox[t]{2.3in}
{$DependOnThreads(M)$ and the synchronization semantics of barrier imply
that $<_{Strict}$ must respect all the edges shown.\footnotemark}
\footnotetext{except for the 
edge between the $upc\_wait$ operations and the edge between the $upc\_notify$ operations,
both of which can point either way.}

\bigskip
There is no valid $<_1$ which respects $<_{Strict}$ -- write-to-read data flow
along the chain $RW(x,1) \Rightarrow upc\_notify \Rightarrow upc\_wait \Rightarrow RR(x,0)$
implies the read must return 1 (i.e. because $RW(x,1) <_{Strict} RR(x,0)$ and there are no 
intervening writes of x).

\bigskip
%--------------------------------------------------------------------------
\np EXAMPLE 12: \textbf{Disallowed behavior} 
$<_{Strict}$ is an ordering over the pairs in $AllStrict(M)$, which 
includes an edge between two $upc\_notify$ operations. Every $<_t$ must conform
to a single $<_{Strict}$ ordering -- all threads agree on a single total
order over $SR(M)\ \cup\ SW(M)$ in general, and in particular they all agree
on the order of $upc\_notify$ operations. Therefore, at least one of the
read operations must return 1.

\begin{tabbing}WWWWW\=WWWWW\=WWWWWWW\=WWWWW\=WWWWWW\=WWWWW\=\kill
$T0$: \> RW(x,1); \> upc\_notify; \> RR(y,0); \> (upc\_wait not shown)\\
$T1$: \> RW(y,1); \> upc\_notify; \> RR(x,0); \> (upc\_wait not shown)\\
\end{tabbing}

\bigskip
$<_{Strict}$:\\
\xymatrix{
RW(x,1) \ar@{=>}[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] \ar@{=>}[d] & RR(y,0) \\
RW(y,1) \ar@{=>}[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] & RR(x,0) 
}\hspace{0.1in}
\parbox[t]{3in}
{$DependOnThreads(M_0)$ implies these edges in $StrictOnThreads(M)$ must be 
respected by $<_{Strict}$.\footnotemark}
\footnotetext{except the edge between the $upc\_notify$ operations, which can point either way.}

\bigskip
$<_0$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar@{=>}[r] \ar@/^1pc/[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] \ar@{=>}[d] \ar@/^1pc/[r] & RR(y,0) \ar[dll] \\
RW(y,1) \ar@{=>}[r] \ar@/^1pc/[r] & *\txt{$upc\_notify$\\$(=SW*)$}  
}\hspace{0.4in}
\parbox[t]{2.5in}
{}

\bigskip
$<_1$:\hspace{0.25in}
\xymatrix{
RW(x,1) \ar@{=>}[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[d]  \\
RW(y,1) \ar@{=>}[r] & *\txt{$upc\_notify$\\$(=SW*)$} \ar@{=>}[r] & RR(x,0) 
}\hspace{0.25in}
\parbox[t]{2in}
{ \vspace{0.5in} Read cannot return 0. }

\bigskip
There is no valid $<_1$ which respects $<_{Strict}$ -- write-to-read data flow
along the chain $RW(x,1) \Rightarrow upc\_notify \Rightarrow upc\_notify \Rightarrow RR(x,0)$
implies the read must return 1 (i.e. because $RW(x,1) <_{Strict} RR(x,0)$ and there are no
intervening writes of x). Reversing the edge between the $upc\_notify$ operations in $<_{Strict}$
causes an analogous problem for y in $<_0$.

%Note that under the alternate asymmetric semantics proposed in section~\ref{asymmetric},
%this behavior would be allowed (because one or both of the relaxed reads could be moved earlier 
%than the upc\_notify's).%
%\footnote{
%CW: The individual
%upc\_notify's in a single collective synchronization operation are totally
%ordered.  I think this is undesirable, as it enforces synchronization
%``too early".  Consider the following example:
%
%\begin{tabbing}WWWWW\=WWWWW\=WWWWWW\=WWWWW\=WWWWW\=WWWWW\=\kill
%$T0$: \> RW(x,1); \> upc\_notify; \> RW(x,2); RR(x,3) \\
%$T1$: \> RW(x,3); \> upc\_notify; \> RW(x,4); RR(x,1) 
%\end{tabbing}
%
%I think this should be allowed, since upc\_notify by itself doesn't imply
%any synchronization; there's no need for T0 to be aware of T1's write,
%and vice versa..  But if the upc\_notify's are ordered, one of the two
%reads will be disallowed. 
%(DOB: again, this is not a problem under the 
%alternate asymmetric semantics.)
%}
\subsection{Formal Definition of Precedes}
\label{MemModelPrecedes}
\index{Precedes}
\index{program order}
\npf This section outlines a formal definition for the $Precedes(m_1,m_2)$
partial order, a predicate which inspects two memory operations in the
execution trace that were issued by the same thread and returns true if and
only if $m_1$ is required to precede $m_2$, according to the sequential
abstract machine semantics of [ISO/IEC00 Sec. 5.1.2.3], applied to the given
thread. Intuitively, this partial order serves to constrain legal serial
program behavior based on the order of the statements a programmer wrote in the
source program. For most purposes, it is sufficient to rely upon an intuitive
understanding of sequential program order when interpreting the behavior of
$Precedes()$ in the memory model - this section provides a more concrete
definition which may be useful to compiler writers.

\np In general, the memory model affects the instructions which are issued (and
therefore, the illusory ``program order", if we were endeavoring to construct a
total order on memory operations given only a static program). Luckily,
providing a functional definition for $Precedes()$ does not require us to
embark on the problematic exercise of defining a totally-ordered ``program
order" of legal executions based only on the static program. All that's
required is a way to determine after-the-fact (i.e. given an execution trace)
whether two memory operations that \emph{did} execute on a single thread were
generated by source-level operations that are required to have a given ordering
by the sequential abstract machine semantics. Finally, note that $Precedes()$
is a partial order and not a total order - two accesses from a given thread
which are not separated by a sequence point in the abstract machine semantics
will not be ordered by $Precedes()$ (and by extension, their relative order
will not be constrained by the memory model).

\np Given any memory access in the trace, it is assumed that we can decide
uniquely which source-level operation generated the access. One mechanism for
providing this mapping would be to attach an abstract ``source line number" tag
to every memory access indicating the source-level operation that generated it.%
\footnote{Compiler optimizations which coalesce accesses or remove them
entirely are orthogonal to this discussion - specifically, the correctness of
such optimizations are defined in terms of a behavioral equivalence to the
unoptimized version. Therefore, as far as the memory model is concerned, every
operation in the execution trace is guaranteed to map to a unique operation at
the source level.} 

In practice, this abstract numbering needs to be slightly different from actual
source line number because the user may have broken a line in the middle of an
expression where the abstract machine guarantees no ordering - but we can
conceptually add or remove line breaks as necessary to make the line numbers
match up with abstract machine sequence points without changing the meaning of
the program (ie whitespace is not significant). Also, without lack of
generality we can assume the program consists only of a single UPC source file,
and therefore the numbering within this file covers every access the program
could potentially execute.%
\footnote{Multi-file programs are easily accomodated by
stating the source files are all concatenated together into a single master
source file for the purposes of defining $Precedes$. }

\np Now, notice that given the numbering and mapping above, we could
immediately define an adequate $Precedes()$ relation if our program consisted
of only straight-line code (ie a single basic block in CFG terminology).
Specifically, in the absence of branches there is no ambiguity about how to
define $Precedes()$ - a simple integer less-than ($<$) comparison of the line
number tags is sufficient. 

Additionally, notice that a program containing only straight-line code and
forward branches can also easily be incorporated in this approach (ie the CFG
for our program is a DAG). In this case, the basic blocks can be arranged such
that abstract machine execution always proceeds through line numbers in
monotonically non-decreasing order, so a simple integer less-than ($<$)
comparison of the line number tags attached to the dynamic operations is still
a sufficient definition for $Precedes$.  

\np Obviously we want to also describe the behavior of programs with backward
branches. We handle them by defining a sequence of abstract rewriting
operations on the original program that generate a new, simplified
representation of the program with equivalent abstract machine semantics but
without any backward branches (so we reduce to the case above).  Here are the
rewriting steps on the original program:

\textbf{Step 1}. Translate all the high-level control-flow constructs in the
program into straight-line code with simple conditional or unconditional
branches. Lower all compound expressions into ``simple expressions" with
equivalent semantics, introducing private temporary variables as necessary.
Each ``simple expression" should involve at most one memory access to a
location in the original program. Order the simple expressions such that the
abstract machine semantics of the original program are preserved, placing line
breaks as required to respect sequence point boundaries. In cases where the
abstract machine semantics leave evaluation order unspecified, place the
relevant simple expressions on the same line.

At this point rewritten program code consists solely of memory operations,
arithmetic expressions, built-in operations (like $upc\_notify$), and
conditional or unconditional goto operations.  For example this program:
\begin{verbatim}
1: i = 0;
2: while ( i < 10 ) {
3:   A[i] = i;
4:   i = i + 1;
5: }
6: A[10] = -1;
\end{verbatim}
Conceptually becomes:
\begin{verbatim}
1: i = 0;
2: if ( i >= 10 ) goto 6;
3: tmp_1 = i; A[i] = tmp_1;
4: tmp_2 = i; i = tmp_2 + 1;
5: goto 2;
6: A[10] = -1;
\end{verbatim}
The translation for the other control-flow statements is similarly
straightforward and well-documented in the literature of assembly code
generation techniques for C-like languages. All control flow (including
function call/return, setjmp/longjmp, etc) can be represented as
(un)conditional branches in this manner. Call this rewritten representation the
\textit{step-1 program}.

\textbf{Step 2}. Compute the maximum line number ($MLN$) of the step-1 program
($MLN=6$ in the example). Clone the step-1 program an infinite number of times
and concatenate the copies together, adjusting the line numbering for the 2nd
and subsequent copies appropriately (note, this is an abstract transformation,
so the infinite length of the result is not a practical issue). While cloning,
rewrite all the goto operations as follows: 

For a goto operation in copy $C$ of the step-1 program (zero-based numbering),
which is a copy of line number $N$ in the step-1 program and targeting
original line number $T$: 
\begin{verbatim}
if (T > N) set goto target = C*MLN + T  // step-1 forward branch 
else       set goto target = (C+1)*MLN + T // step-1 backward branch 
\end{verbatim}
In other words, step-1 forward branches branch to the same relative place in
the current copy of the step-1 program, and backward branches become forward
branches to the \emph{next} copy of the step-1 program.  So our example above
conceptually becomes:
\begin{verbatim}
1: i = 0;
2: if ( i >= 10 ) goto 6;
3: tmp_1 = i; A[i] = tmp_1;
4: tmp_2 = i; i = tmp_2 + 1;
5: goto 8;                     // rewritten backward goto 
6: A[10] = -1;

7:  i = 0;
8:  if ( i >= 10 ) goto 12;    // rewritten forward goto 
9:  tmp_1 = i; A[i] = tmp_1;
10: tmp_2 = i; i = tmp_2 + 1;
11: goto 14;                   // rewritten backward goto 
12: A[10] = -1;

13: i = 0;
...
\end{verbatim}

After this transformation, all branches are forward branches. Now, the memory
model describes behavior of the step-2 rewritten program, and $Precedes()$ is
defined as a simple integer less-than ($<$) comparison of the step-2 program's
line number tags attached to any two given memory accesses in the execution
trace.

\pagebreak
\section{UPC versus C Standard Section Numbering}

\begin{center}
\begin{tabular}{|c|c|}
\hline
UPC specifications subsection &   C Standard specifications subsection \\
\hline
1   &   1 \\
2   &   2 \\
3   &   3 \\
4   &   4 \\
5   &   5 \\
6   &  6 \\
6.1 &   6.1 \\
6.2 &   6.4.2.2 \\
6.3 &   6.5 \\
6.3.6 & 6.5.3.1 \\
6.4 &   6.7 \\
6.4.1 & 6.7.3 \\
6.4.3 & 6.7.5 \\
6.5 &   6.8 \\
6.6 &   6.10 \\
7   &   7 \\
7.1 &   7.1.2 \\ 
\hline
\end{tabular}                                                  

Table A1. Mapping UPC subsections to C Standard specifications subsections  
\end{center}

\pagebreak
\section*{References}
\addcontentsline{toc}{section}{References}

[CAG93]  David E. Culler, Andrea C. Arpaci-Dusseau, Seth Copen Goldstein, Arvind Krishnamurthy, 
  Steven Lumetta, Thorsten von Eicken, Katherine A. Yelick. {\em Parallel programming in Split-C},  
  Proceedings of Supercomputing 1993, p. 262-273.

[CDC99] W. W. Carlson, J. M. Draper, D.E. Culler, K. Yelick,
   E. Brooks, and K.  Warren.  Introduction to UPC and Language
   Specification.  CCS-TR-99-157. IDA/CCS, Bowie, Maryland.  May,
   1999.

[ISO/IEC00] ISO/IEC.  Programming Languages-C. ISO/IEC 9899. May, 2000.

[Lam79] L. Lamport. {\em How to make a Multicomputer that Correctly Executes
  Multiprocess Programs.} IEEE Transactions on Computers, C-28(9):690-69,
  September 1979.
  
[MPI2] MPI-2: Extensions to the Message-Passing Interface, Message Passing Interface Forum, July 18, 1997.

\pagebreak
\printindex
\end {document}

